\section{Theory}
\subsection{The Quantum Boltzmann Machine}
The Quantum Boltzmann Machine detailed here is based on the work in \textit{Quantum Boltzmann Machine} by Amin et al.~\cite{amin_2018}.
In this section we use spin eigenvalues \( +1 \) and \( -1 \) rather than binary values \( 0 \) and \( 1 \), respectively, in order to maintain consistency with the language of quantum mechanics.
We start with the Hamiltonian
\begin{align}
    H = -\sum_i \Gamma_i \sigma_i^x -\sum_i b_i \sigma_i^z - \sum_{i,j} w_{ij} \sigma_i^z \sigma_j^z
\end{align}
where
\begin{align}
\begin{split}
    \sigma_i^x
        &= I^{\otimes i-1} \otimes \sigma_x \otimes I^{\otimes n-i} \\
    \sigma_i^z
        &= I^{\otimes i-1} \otimes \sigma_z \otimes I^{\otimes n-i}
\end{split}
\end{align}
with \( \sigma_x \) and \( \sigma_z \) being the Pauli \( x \) and \( z \) matrices, and \( I \) being the \( 2 \times 2 \) identity matrix.
We denote the first \( n_v \) qubits as the visible units and the last \( n_h \) qubits as the hidden units, thus we have a total of \( n_v + n_h = n \) qubits.

The system's distribution is modeled by the density matrix
\begin{align}
    \rho = \frac{1}{Z} e^{-H}
\label{eq:density_operator}
\end{align}
where \( e^{-H} = \sum_n \frac{1}{n!} (-H)^n \) is the matrix exponential, and \( Z = \tr(e^{-H}) \) is the partition function.
The probability to observe the system in state \( \ket{\vec{v},\vec{h}} \) is given by
\begin{align}
    p(\vec{v},\vec{h})
        &= \tr(\ket{\vec{v},\vec{h}}\bra{\vec{v},\vec{h}} \rho)
\end{align}
and if we define the projection operator
\begin{align}
    \Lambda_\vec{v} = \ket{\vec{v}}\bra{\vec{v}} \otimes I^{\otimes n_h}
\end{align}
then the marginal probability to measure the visible units in state \( \ket{\vec{v}} \) is given by
\begin{align}
    p(\vec{v}) = \tr(\Lambda_{\vec{v}}\rho)
\end{align}

Using the probabilities above we can obtain an average log-likelihood, which for data set distribution \( p_\text{data} \) and parameters \( \theta = (\mat{W}, \vec{a}, \vec{b}) \) is
\begin{align}
    \ell(\theta) = \sum_{\vec{v}} p_{\text{data}}(\vec{v}) \log \tr(\Lambda_\vec{v}\rho)
\end{align}

\subsection{Optimizing a QBM}
When optimizing a QBM, it is preferable to maximize the lower bound of the log-likelihood rather than maximizing the log-likelihood itself.
The reason for this is that the partial derivative of the log-likelihood with respect to the parameters has a term which is computationally expensive to compute, as discussed in \cref{app:qbm_log_likelihood_derivation}.
The lower bound of the log-likelihood is given by (see \cref{app:qbm_log_likelihood_lower_bound} for derivation)
\begin{align}
    \tilde{\ell}(\theta) = \sum_{\vec{v}} \pdata(\vec{v}) \log \tr(\rho_\vec{v})
\end{align}
where we have what is referred to as the \textit{clamped} Hamiltonian, which for a given visible vector \( \vec{v} \) is
\begin{align}
    H_\vec{v}
        &= \braket{\vec{v}|H|\vec{v}}
\end{align}
with corresponding clamped density matrix
\begin{align}
    \rho_\vec{v}
        &= \frac{1}{Z_\vec{v}} e^{-H_\vec{v}}
\end{align}
and \( Z_\vec{v} = \tr(e^{-H_\vec{v}}) \).

The associated derivatives with respect to the parameters of the lower bound are given by (see \cref{app:qbm_log_likelihood_lower_bound_derivative} for derivation)
\begin{align}
\begin{split}
    \partial_{w_{ij}} \tilde{\ell}(\theta)
        &= \langle \sigma_i^z \sigma_j^z \rangle_\text{data} - \langle \sigma_i^z \sigma_j^z \rangle_\text{model} \\
    \partial_{b_i} \tilde{\ell}(\theta)
        &= \langle \sigma_i^z \rangle_\text{data} - \langle \sigma_i^z \rangle_\text{model}
\end{split}
\end{align}
where \( \langle \ \cdot \ \rangle_\text{data} \) is the data set-averaged expectation value with respect to the clamped density matrix, and \( \langle \ \cdot \ \rangle_\text{model} \) is the expectation value with respect to the original density matrix.

If connections are restricted within the hidden layer, then the hidden unit probabilities are independent in the positive phase and can be computed easily, as shown in \cref{app:qbm_log_likelihood_lower_bound_derivative}.
This leads to positive phase expectation values of
\begin{align}
\begin{split}
    \langle \sigma_i^z \rangle_\text{data}
        &= \sum_\vec{v} \pdata(\vec{v}) v_i,
        \ i \in \mathcal{I}_v \\
    \langle \sigma_i^z \sigma_j^z \rangle_\text{data}
        &= \sum_\vec{v} \pdata(\vec{v}) v_i v_j,
        \ i, j \in \mathcal{I}_v \\
    \langle \sigma_i^z \rangle_\text{data}
        &= \sum_\vec{v} \pdata(\vec{v}) \frac{b_i'(\vec{v})}{D_i(\vec{v})} \tanh\big(D_i(\vec{v})\big),
        \ i \in \mathcal{I}_h \\
    \langle \sigma_i^z \sigma_j^z \rangle_\text{data}
        &= \sum_\vec{v} \pdata(\vec{v}) v_i \frac{b_j'(\vec{v})}{D_j(\vec{v})} \tanh\big(D_j(\vec{v})\big),
        \ i \in \mathcal{I}_v, \ j \in \mathcal{I}_h
\end{split}
\end{align}
where \( b_i'(\vec{v}) = b_i + (\mat{W}^\intercal\vec{v})_i \), \( D_i(\vec{v}) = \sqrt{\Gamma_i^2 + b_i'(\vec{v})^2} \), \( \mathcal{I}_v = \{1, \dots, n_v\} \) represents the visible qubit indices, and \( \mathcal{I}_h = \{n_v + 1, \dots, n\} \) represents the hidden qubit indices.

\subsection{Quantum Annealing}\label{sec:quantum_annealing}
Quantum annealing, also known as adiabatic quantum computing, is a branch of quantum computing that is based on the adiabatic theorem, which in the (translated) words of Born and Fock~\cite{born_fock_1928}:
"A physical system remains in its instantaneous eigenstate if a given perturbation is acting on it slowly enough and if there is a gap between the eigenvalue and the rest of the Hamiltonian's spectrum."
This can be achieved by implementing a Hamiltonian of the form~\cite{qc_lecture_notes}
\begin{align}
    H(s) = A(s) H_{\text{initial}} + B(s) H_{\text{final}}
\end{align}
where \( s \in [0, 1] \).
For a linear anneal schedule \( s = t / t_a \), with \( t_a \) being the total duration the system is annealed for.
\( H_{\text{initial}} \) is the initial Hamiltonian which describes the system at \( s = 0 \) and is responsible for introducing quantum fluctuations.
\( H_{\text{final}} \) is the final Hamiltonian which describes the system at \( s = 1 \) and is responsible for encoding the problem defined by the user.

The functions \( A(s) \) and \( B(s) \) must be such that they satisfy the relations
\begin{align}
\begin{split}
    A(0) &\gg B(0) \\
    A(1) &\ll B(1)
\end{split}
\end{align}

In essence, a quantum annealer starts in the ground state of the initial Hamiltonian, then slowly evolves the system over time so that the it remains in the instantaneous ground state.
By the time the annealing process is completed, the Hamiltonian is just that of the problem, and if the system evolved adiabatically, then it should have remained in the instantaneous ground state.
Therefore, when the qubits are measured they should correspond to an optimal solution to the problem defined by the \( h_i \) and \( J_{ij} \) values.

\subsubsection{D-Wave Quantum Annealer}
D-Wave quantum annealers implement a time-dependent Hamiltonian of the form~\cite{dwave_qa}
\begin{align}
    H(s) = A(s) \bigg( -\sum_i \sigma_i^x \bigg) + B(s) \bigg( \sum_i h_i \sigma_i^z + \sum_{i,j} J_{ij} \sigma_i^z \sigma_j^z \bigg)
\end{align}
From this we see the initial Hamiltonian has a ground state where all of the qubits are aligned in the \( x \)-direction, i.e., \( \ket{+}^{\otimes n} \), which corresponds to an equal superposition of all possible states in the computational basis.
The final Hamiltonian corresponds to the Ising model described by the \( h_i \) and \( J_{ij} \) values.

The quantum processing unit (QPU) is made up of superconducting qubits under the influence of external magnetic fluxes~\cite{qc_lecture_notes} which change the Hamiltonian from the initial to the final over the duration of the annealing process.
These qubits are arranged in a graph structure similar to that seen in~\cref{fig:p4_unitcells}.
The default anneal schedule for the D-Wave Advantage 4.1 is shown in~\cref{fig:anneal_schedule_default}
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=0.7\linewidth]{p4_unitcells.png}
    \end{center}
    \caption{A lattice with \( 4 \times 4 \) Pegasus unit cells (\( P_4 \)). The D-Wave Advantage QPU is based on a lattice with \( 16 \times 16 \) Pegasus unit cells (\( P_{16} \))~\cite{dwave_topologies}.}
    \label{fig:p4_unitcells}
\end{figure}
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/anneal_schedules/Advantage_system4.1-s_pause=1.00-pause_duration=0.png}
    \end{center}
    \caption{Default anneal schedule for the D-Wave Advantage 4.1~\cite{dwave_anneal_schedules}.}
    \label{fig:anneal_schedule_default}
\end{figure}

\subsubsection{Mapping the QBM to the D-Wave Quantum Annealer}
As stated in~\cite{amin_2018}, in order get a quantum annealer to sample from a quantum Boltzmann distribution, one would need to freeze the evolution at some point \( s^* \) during the annealing process and then perform the measurements.
It goes on to say that this can be done in practice using a nonuniform \( s(t) \) that anneals slowly in the beginning, then quenches the system (completes the annealing as fast as possible) at the freeze out point \( s^* \), if \( s^* \) is in the quasistatic regime.
In an earlier paper~\cite{amin_2015}, Amin showed that the quasistatic regime begins around 1 \si{\micro\second} for the D-Wave 2000Q, so it shouldn't be an issue to reach the quasistatic regime for annealing times longer than 5 \si{\micro\second}.

Since a quantum annealer is a real-world physical device, samples generated with it have an associated temperature called the effective temperature.
To be more specific, the corresponding density operator is of the form
\begin{align}
    \rho(s, T) = \frac{1}{Z} e^{-\beta H(s)}
\label{eq:effective_density_operator}
\end{align}
where \( \beta = \frac{1}{k_B T} \) is the effective inverse temperature.
In principle, \( \beta \) is an unknown quantity and must be determined in order to effectively use the annealer to generate samples from a quantum Boltzmann distribution.

Comparing the density operator of the QBM in~\cref{eq:density_operator} to the one in~\cref{eq:effective_density_operator} at the freeze-out point \( s^* \), we find
\begin{align}
\begin{split}
    \Gamma_i
        &= \beta A(s^*) \\
    b_i
        &= -\beta B(s^*) h_i \\
    w_{ij}
        &= -\beta B(s^*) J_{ij}
    \label{eq:qbm_scaling}
\end{split}
\end{align}
thus we can map the QBM to the annealer if \( \beta \) can be determined to some reasonable degree of accuracy.

\subsubsection{Learning the Effective Inverse Temperature}\label{sec:learning_beta}
There is the possibility to treat \( \beta \) as a learnable parameter rather than having to choose a value empirically, as detailed by Xu and Oates in~\cite{xu_2021}.
Their methodology is based on a log-likelihood maximization approach, and leads to iterative updates of the form (see \cref{app:learning_beta} for how one arrives at this result)
\begin{align}
    \betahat^{(t)}
        &= \betahat^{(t-1)} + \frac{\eta}{\big(\betahat^{(t-1)}\big)^2}\big(\langle E \rangle_\text{data} - \langle E \rangle_\text{model}\big)
\end{align}
where \( \betahat = \frac{1}{k_B\hat{T}} \) is the estimator of the effective inverse temperature.
We forego the factor of \( \betahat^2 \) downstairs in practice for simplicity and to keep a similar form to the other gradient updates.
We must note though that this approach is only valid for classical Boltzmann distributions, but this fits our current use case as we will see later.

\subsubsection{D-Wave Ocean SDK}
D-Wave offers an easy to use Python package called Ocean SDK~\cite{dwave_ocean} to interact with their Leap~\cite{dwave_leap} cloud-based quantum annealing platform, which allows users to access various quantum annealers and other solvers around the globe.

One of the most important steps in solving a problem using a D-Wave annealer is finding an embedding, i.e., a mapping of the logical qubits to the physical qubits, and the SDK offers a heuristic method to do so.
If the problem cannot be directly embedded (1:1 logical:physical qubits), then a cluster of physical qubits called a chain is created to represent one logical qubit.
Chains introduce added complexity into the problem, because one then needs to tune the chain strength, i.e., the coupling constant between the qubits in the chains.
If the measured values of the qubits in a chain differ, this is called a chain break, and the system will report back the majority vote of the measured values in the chain.
Therefore, it is best to avoid chains if possible, but they are often a necessary evil for larger problems due to connectivity limitations.

Samples can be easily generated by the annealer using the \texttt{sample\_ising(h, J)} function which takes in the user-defined \( h_i \) and \( J_{ij} \) values and returns a sample set of specified size (maximum \( 10^4 \)).
The returned sample set contains the sampled state vectors (an array of shape \( (n_\text{samples}, n) \) with values \( \pm 1 \) corresponding to the qubit measurements), their energies, and other information about the run.

It must be noted that for the purposes of using a D-Wave annealer for quantum Boltzmann sampling, one must disable autoscaling to accurately estimate the effective temperature, as per~\cref{eq:qbm_scaling}.
The \texttt{sample\_ising(h, J)} function has the keyword argument \texttt{autoscale=True}, which rescales the \( h_i \) and \( J_{ij} \) values by the factor~\cite{dwave_solver_parameters}
\begin{align}
\begin{split}
    r_\text{autoscale}
        = \max\Bigg\{
            &\max\bigg\{\frac{\max\{h_i\}}{\max\{h_\text{range}\}},0\bigg\},
            \max\bigg\{\frac{\min\{h_i\}}{\min\{h_\text{range}\}},0\bigg\}, \\
            &\max\bigg\{\frac{\max\{J_{ij}\}}{\max\{J_\text{range}\}},0\bigg\},
            \max\bigg\{\frac{\min\{J_{ij}\}}{\min\{J_\text{range}\}},0\bigg\}
        \Bigg\}
\end{split}
\end{align}
This is because the main use case of D-Wave annealers is to maximize the probability of measuring the ground state, thus the problem is rescaled so that the \( h_i \) and \( J_{ij} \) values fully utilize the allowed range of values, essentially decreasing the effective temperature.
For the Advantage 4.1 system the allowed value ranges are \( h_\text{range} = [-4, 4] \) and \( J_\text{range} = [-1, 1] \)~\cite{dwave_solver_properties}.

\subsubsection{Generating More Robust Statistics}\label{sec:gauge}
QPUs aren't perfect, and sometimes specific qubits or parts of the chip might have readout biases.
One can perform a gauge transformation on the problem to mitigate such issues.
If we have an \( n \)-qubit problem, then we can generate a random vector \( \vec{r} \in \{+1, -1\}^n \) which allows us to change the submission to the solver without actually changing the underlying problem.
This is done by taking
\begin{align}
\begin{split}
    h_i
        &\rightarrow r_i h_i \\
    J_{ij}
        &\rightarrow r_i r_j J_{ij} \\
    (s_1, \dots, s_n)
        &\rightarrow (r_1 s_1, \dots, r_n s_n)
\end{split}
\end{align}
then transforming the results back using the third relation above, where \( s_i \) is the measured value of qubit \( i \).

\subsubsection{Previous Work in This Field}
In recent years a number of researchers have dabbled in using D-Wave quantum annealers to train Boltzmann machines~\cite{adachi_2015,benedetti_2016,anschuetz_2019,wiebe_2019,rocutto_2020,dixit_2021,ilmo_2021,wilson_2021,xu_2021}.
The most common approach is to train a classical RBM with quantum assistance, i.e., using the annealer to generate the samples in the negative phase rather than using Gibbs sampling.
This isn't necessarily a fully quantum Boltzmann machine as per~\cite{amin_2018}, but the case where \( s^* = 1 \) reduces it to a classical RBM, as \( \lim_{s\rightarrow 1} \Gamma_i = 0 \) in~\cref{eq:qbm_scaling}.

One thing that stands out the most about some of the previous research is that very few discuss embeddings and anneal schedules, which as we will see in the next section are important for getting the best possible performance out of the annealer.
Therefore, we aim to create a basic framework with which one can use to approach the problem of using a D-Wave annealer to sample from a (quantum) Boltzmann distribution.

\section{12-Qubit Problem}
In order to get a better understanding of how the QBM works, we turned our attention toward a small 12-qubit problem we could solve exactly.
For this purpose we took a QBM with restrictions in both the visible and hidden layers trained using the log-likelihood lower bound maximization approach; we call this a bound-based quantum restricted Boltzmann machine, or BQRBM for short.
The model was configured with 8 visible and 4 hidden units to act as a regularized autoencoder.

\subsection{Sampling From a Quantum Boltzmann Distribution}
Before beginning to train models, we first needed to assess the D-Wave Advantage 4.1's ability to sample from quantum Boltzmann distributions.
To this end we randomly generated the values of \( h_i \) and \( J_{ij} \) from a normal distribution with \( \mu = 0 \) and \( \sigma = 0.1 \), then used the KL divergence to compare samples generated by the annealer to the theoretical distributions.

\subsubsection{Anneal Schedule Format}
The \( A(s) \) and \( B(s) \) values for a D-Wave annealer are fixed and depend on the specific system~\cite{dwave_anneal_schedules}, but the Ocean SDK allows us to define a nonuniform \( s(t) \) using a list of \( (t, s) \) tuples, which then determine the \( A(s(t)) \) and \( B(s(t)) \) curves.
In this section we used what we call pause-and-quench anneal schedules that
\begin{enumerate}
    \item Started at \( (t = 0, s = 0) \).
    \item Paused the system at \( (\tpause, \spause) \) for a duration of \( \Deltapause \).
    \item Quenched the system at \( (\tquench, \squench) \) over a duration of \( \Deltaquench \).
\end{enumerate}
thus the anneal schedules provided to the solver were of the form
\begin{align}
    [
        (0, 0),
        (\tpause, \spause),
        (\tquench, \squench),
        (\tquench + \Deltaquench, 1)
    ]
\end{align}
where
\begin{align}
\begin{split}
    \squench &\equiv \spause \\
    \tpause &= \spause \cdot \trelative \\
    \tquench &= \tpause + \Deltapause
\end{split}
\end{align}
An annotated example of a custom pause-and-quench anneal schedule with \( \squench = 0.55 \), \( \trelative = 20 \ \si{\micro\second} \), and \( \Deltapause = 10 \ \si{\micro\second} \) is given in~\cref{fig:anneal_schedule_annotated}.
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/anneal_schedules/Advantage_system4.1-s_pause=0.55-pause_duration=10.png}
    \end{center}
    \caption{
        Example of a custom pause-and-quench anneal schedule for the D-Wave Advantage 4.1~\cite{dwave_anneal_schedules}.
        Annotations indicate the points \( (t, B(s(t))) \), as well as the periods over which the annealing is paused and quenched.
    }
    \label{fig:anneal_schedule_annotated}
\end{figure}

The minimum quench duration \( \Deltaquench \) is a function of \( \squench \) and is limited by the system's fastest anneal rate \( \alphaquench \)
\begin{align}
    \Deltaquench(\squench) = \frac{1 - \squench}{\alphaquench}
\end{align}
The Advantage 4.1 system allows a maximum of \( \alphaquench = 2 \ \si{\micro\second}^{-1} \)~\cite{dwave_solver_parameters}.

\subsubsection{Verifying the Distribution}
We used the KL divergence \( \DKL{\ptheory}{\psamples} \) to compare the probabilities of the energies computed from the samples returned by the annealer to the theoretical energy distributions for \( s = 0.01, 0.02, \dots, 1 \) and \( T = 10^{-3}, 2, 4, \dots, 200 \ \si{\milli\kelvin} \), which we visualized as heatmaps in~\cref{fig:dkl_min_heatmap}.
More information on how the KL divergence was computed can be found in~\cref{app:kl_divergence_in_practice}.
In the right heatmap, where \( \squench = 0.55 \), we observed a narrow band at which the annealer sampled close to a quantum Boltzmann distribution, and in fact it approximated multiple distributions, depending on the effective temperature.
Similar results were obtained by Marshall et al.~\cite{marshall_2019} using a D-Wave 2000Q, in which they discussed how if the distribution returned by the annealer fits that of a quantum Boltzmann distribution late in the anneal process when \( A(s^*) / B(s^*) \ll 1 \), then the distribution at \( s^* \) should be close to a classical Boltzmann distribution, i.e.,
\begin{align}
    e^{-\beta H(s^*)} \approx e^{-\beta B(s^*) H_\text{final}}
\end{align}
This in turn means that not only is there one optimal \( s^* \) and effective temperature which models the distribution, but rather a set of them corresponding to a family of distributions for which \( \beta B(s^*) \) is constant.
Therefore, this explains the streak pattern in the heatmaps.

Furthermore, we observed that the left heatmap, where \( \squench = 0.25 \), is quite similar to the right one where \( \squench = 0.55 \), but with higher KL divergence values and temperatures.
This indicated that quenching at \( \squench = 0.25 \) produced samples that were distributed more as a classical Boltzmann distribution, and that we could not generate samples from quantum Boltzmann distributions with \( s^* \lessapprox 0.45 \).

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/8x4/embedding_comparison/config_05/dkl_min_heatmap-embedding=10.png}
    \end{center}
    \caption{
        Heatmaps of \( \DKL{\ptheory}{\psamples} \) comparing the distribution produced by samples from the Advantage 4.1 to a set of theoretical QBM distributions for two different quench points using embedding 10.
        The dashed lines represent the optimal values of \( B(s) / T = \text{constant} \), computed by taking the value of \( T \) which produced the lowest KL divergence for each \( s \ge 0.5 \).
        Data represents an ensemble average over 10 random gauges with \( 10^4 \) samples each.
    }
    \label{fig:dkl_min_heatmap}
\end{figure}

It must also be noted that the effective temperature corresponding to the classical Boltzmann distribution \( (s^* = 1) \) was significantly higher than that of the D-Wave temperature of \( T_\text{DW} = 15.4 \pm 0.1 \ \si{\milli\kelvin} \)~\cite{dwave_leap}\footnote{Temperature obtained from the system properties in the Leap interface.}.
It is not entirely clear exactly why the effective temperature of the distribution was observed to be so much higher than the device temperature, but in~\cite{marshall_2019} they give several possible reasons, including the discrepancy between the temperature of the device and the qubits, fluctuations in the temperature while annealing, and control errors masquerading as higher temperatures.
In principle, higher effective temperatures are unwanted because they shrink the range of allowed values for the weights and biases as per~\cref{eq:qbm_scaling}, but there is not much one can do about this.

From analysis of the heatmaps and the fact that we could not produce distributions with \( s^* \lessapprox 0.45 \), we concluded that nontrivial dynamics were occurring while the system was quenching, i.e., the system could not quench fast enough.
It is difficult to compare directly since the D-Wave 2000Q is a different system than the Advantage 4.1 studied here, but in~\cite{marshall_2019} they alluded to this as well.
The 2000Q allowed for quenching with \( \alphaquench = 1 \), which is only a factor of two smaller than that allowed by the Advantage 4.1.
Therefore, if as supposed in~\cite{marshall_2019} that the quench isn't fast enough, then likely such a small difference in how fast the system can be quenched wouldn't drastically change the results.

If we take a second to think about it, the qubits are oscillating at a frequency in terms of GHz.
This means that a quench duration of a few hundred nanoseconds still allows for a number of oscillations in the qubits, which is likely enough time for nontrivial dynamics to occur.
It would be interesting to verify via simulation how fast a quench must be in order to freeze out the distribution at the desired point \( s^* \).

We concluded that we were unable to reliably generate quantum Boltzmann distributed samples using the Advantage 4.1 system.
Therefore, the rest of this thesis focused on training models with \( s^* = 1 \) using classical Boltzmann distributed samples generated from the annealer, which also enabled us to use the aforementioned method of learning the effective temperature.

\subsubsection{Choosing an Embedding}
We compared 10 different heuristically generated embeddings based on how well they approximated the desired distribution.
This embedding comparison used only direct embeddings (no chains), and pause-and-quench anneal schedules with \( \trelative = 20 \ \si{\micro\second} \) and \( \Deltapause = 0 \ \si{\micro\second} \).

It was difficult to compare the heatmaps of all embeddings and quench points due to the higher dimensionality of the data, so we took the minimum KL divergence over \( s \) and \( T \), and plotted it as a function of \( \squench \) in~\cref{fig:dkl_mins_embeddings}.
We immediately saw how varied the results were depending on the embedding and quench point, highlighting the importance of choosing a good embedding and anneal schedule.

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/8x4/embedding_comparison/config_05/kl_divergence_mins.png}
    \end{center}
    \caption{
        Comparison of \( \min\limits_{s,T}\big\{\DKL{\ptheory}{\psamples}\big\} \) for different embeddings and \( \squench \) values.
        Data represents an ensemble average over 10 random gauges with \( 10^4 \) samples each.
        Shaded regions represent one standard deviation.
    }
    \label{fig:dkl_mins_embeddings}
\end{figure}

Our findings indicated that embedding 10 was likely a good choice because it produced the best results at \( \squench = 0.55 \).
The rest of the results in this subsection were obtained using embedding 10.

\subsubsection{Choosing an Anneal Schedule}\label{sec:choosing_an_anneal_schedule}
With the chosen embedding we wanted to see if there was a way in which we could alter the anneal schedule to further reduce the KL divergence.
We started with the same anneal schedule formula as before, except we introduced pausing before initiating the quench for durations \( \Deltapause = 0, 10, 100 \ \si{\micro\second} \), as well as the addition of \( \trelative = 100 \ \si{\micro\second} \).

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/8x4/exact_analysis/config_05/embedding_10/kl_divergence_mins.png}
    \end{center}
    \caption{
        Comparison of \( \min\limits_{s,T}\big\{\DKL{\ptheory}{\psamples}\big\} \) for various pause-and-quench anneal schedules using embedding 10.
        Data represents an ensemble average over 10 random gauges with \( 10^4 \) samples each.
        Shaded regions represent one standard deviation.
        Some of the sample sets with longer annealing times and pause durations had less than \( 10^4 \) samples as to satisfy the maximum run time allowed by the Advantage 4.1 system.
    }
    \label{fig:dkl_mins_embedding_05}
\end{figure}

\cref{fig:dkl_mins_embedding_05} illustrates that pausing and longer annealing times had little effect, and that quenching in the range of \( \squench \in [0.55, 0.6] \) produced the best results.
With this information, we opted to use an anneal schedule with \( \squench = 0.55 \), \( \trelative = 20 \ \si{\micro\second} \), and \( \Deltapause = 0 \ \si{\micro\second} \), as it offered a good balance between performance and QPU usage time.

\subsection{Training Data}
Having verified that the annealer can indeed produce Boltzmann distributed samples to some degree of accuracy, we proceeded with training models using both a simulation and the Advantage 4.1.
The training data set consisted of 1500 examples, 1000 from a \( \mathcal{N}(-2, 1) \) distribution and 500 from a \( \mathcal{N}(3, 1) \) distribution, visualized in~\cref{fig:hist_data}.
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/8x4/Advantage_system4.1/hist_data.png}
    \end{center}
    \caption{Histogram of the training data set used in the 12-qubit problem.}
    \label{fig:hist_data}
\end{figure}

\subsection{Simulation-based Model}
The first step was training a model using a simulation in which the samples were generated using the probabilities obtained from computing \( \rho \) exactly.
\cref{app:exact_rho_computation} contains more information on how the density matrix was computed in the simulation.

Here we used a mini-batch size of 10, \( s^* = 1 \), and an initial learning rate of \( \eta = 0.1 \) with a schedule that exponentially decayed the learning rate every 10 epochs by a factor of 2 beginning at epoch 50 as defined in~\cref{app:lr_exp_decay}.
The learning rate \( \eta_{\hat{\beta}} \) for the parameter \( \betahat \) followed a similar schedule, except it had a decay period of 20 as opposed to 10, to allow for more range of motion in the \( \betahat \) parameter later in the training process if the estimate needed to adapt more quickly to a new effective \( \beta \).

\subsubsection{Results}
\cref{fig:train_results_exact} shows the results of training the simulation-based model on the aforementioned data set.
We chose to use the KL divergence \( \DKL{\pdata}{\pmodel} \) as a way to track the progress of the training and get a read on how well the model was learning the data set distribution, as minimizing the KL divergence is equivalent to maximizing the log-likelihood~\cite{murphy_2012}.
The KL divergence was computed at the end of every epoch using a sample set of size \( 10^4 \).
In the left plot of \cref{fig:train_results_exact}, we observed a clear trend of the KL divergence being minimized.
The learning curve reached an optimal value after about 80 epochs, then stayed steady for the next 20 epochs until the end of training.

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/8x4/Advantage_system4.1/train_results_exact.png}
    \end{center}
    \caption{
        Training results of the 12-qubit model using samples generated via simulation.
        On the left is the KL divergence \( \DKL{\pdata}{\pmodel} \) plotted against the epochs; each data point was generated using \( 10^4 \) samples at the end of every epoch.
        On the right is the learned temperature estimator \( \hat{T} \) plotted against the epochs, as well as the effective temperature that the simulator was configured to generate samples at.
    }
    \label{fig:train_results_exact}
\end{figure}

We designed the simulation such that we could set the effective \( \beta \) to any value we desired.
To verify that the model could learn an accurate value for the estimator \( \betahat \), we configured the simulation to generate samples at an effective value of \( \beta = 0.5 \ \si{\giga\hertz}^{-1} \ (T \approx 96 \ \si{\milli\kelvin}) \) and initialized the model with a value of \( \betahat = 1 \ \si{\giga\hertz}^{-1} \ (\hat{T} \approx 48 \ \si{\milli\kelvin}) \).
The results in the right plot of~\cref{fig:train_results_exact} confirm that it was able to learn a value of \( \betahat \) close to the actual effective \( \beta \).

Overall, the results show that the model learned to generate samples similar to the training distribution reasonably well when trained using the simulation, i.e., the best case scenario.
Additionally, we were able to verify that the model can accurately learn an estimate of the effective temperature.
We used the results of this model as a baseline to compare the models trained using the annealer in the next subsection.

\subsection{D-Wave Advantage 4.1-based Model}
Having shown that the BQRBM model worked when trained using samples generated via exact simulation, we then moved to switching the sample generation part to the annealer.
We took the same hyperparameters as the simulation, and an anneal schedule using \( \squench = 0.55 \), \( \trelative = 20 \ \si{\micro\second} \), and \( \Deltapause = 0 \ \si{\micro\second} \).
We saw in~\cref{fig:dkl_min_heatmap} that \( \squench = 0.55 \) had an optimal temperature of around 90 \si{\milli\kelvin} for \( s^* = 1 \), thus we took \( \betahat = 0.5 \ \si{\giga\hertz}^{-1} \ (\hat{T} \approx 96 \ \si{\milli\kelvin}) \) as our initial guess for the effective \( \beta \), and let the model learn from there.

\subsubsection{Results}
\cref{fig:train_results_annealer} shows the model trained using the annealer was able to learn the training distribution to some extent, but still underperformed when compared to the simulation and the classically trained RBM.
This is possibly due to the information loss associated with using the D-Wave to approximate the distribution, which likely arose due to noise and errors (see~\cref{sec:challenges}), because after all real-world systems governed by quantum mechanics are highly sensitive to their environment.
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/8x4/Advantage_system4.1/train_results_annealer.png}
    \end{center}
    \caption{
        Training results of the 12-qubit model trained using samples generated with the D-Wave Advantage 4.1 compared to that of the simulation and the final results of a classical RBM.
        On the left is the KL divergence \( \DKL{\pdata}{\pmodel} \) plotted against the epochs; each data point was generated using \( 10^4 \) samples at the end of every epoch.
        On the right is the learned temperature estimator \( \hat{T} \) plotted against the epochs.
    }
    \label{fig:train_results_annealer}
\end{figure}

We noticed that the Advantage 4.1-based model struggled most with learning the trough between the two Gaussian peaks in the training distribution based on the QQ plots in~\cref{fig:qq_comparison}.
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/8x4/Advantage_system4.1/qq_comparison.png}
    \end{center}
    \caption{QQ plots of the 12-qubit model trained using the simulation (left) and the D-Wave Advantage 4.1 (right).}
    \label{fig:qq_comparison}
\end{figure}

Although we couldn't track the true effective temperature throughout the training process, we were able to see how close the learned effective temperature estimate at the end matched that generated by samples using the final learned weights and biases.
\cref{fig:learned_effective_temperature} shows that the annealer-based model was able to learn an effective temperature estimate of \( 97.8 \ \si{\milli\kelvin} \), quite close to the \( 95.6 \ \si{\milli\kelvin} \) derived from the KL divergence heatmap.
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=0.8\linewidth]{qbm/8x4/Advantage_system4.1/effective_temperature.png}
    \end{center}
    \caption{
        Heatmap of \( \DKL{\ptheory}{\psamples} \) comparing the distributions produced by samples from the Advantage 4.1 to a set of theoretical QBM distributions, using the final \( h_i \) and \( J_{ij} \) values learned by the 12-qubit model trained using the annealer.
        The blue cross indicates the learned estimate of the effective temperature.
        The dashed line represents the optimal value of \( B(s) / T = \text{constant} \), computed by taking the value of \( T \) which produced the lowest KL divergence for each \( s \ge 0.5 \).
        Data represents an ensemble average over 10 random gauges with \( 10^4 \) samples each.
    }
    \label{fig:learned_effective_temperature}
\end{figure}

The results in this section showed that a BQRBM can indeed be trained using a D-Wave quantum annealer.
The 12-qubit problem played a crucial role in our understanding of how one can use a D-Wave quantum annealer to generate Boltzmann distributed samples.
Although the results aren't spectacular and underperform the simulation and classical model, they still show promise.
It will be interesting to rerun this analysis on the next generation of D-Wave quantum annealers to see how much they improve.

\clearpage
\section{The Quantum Market Generator}
Having gained a deeper insight into the workings of the BQRBM from the 12-qubit problem, we moved to the final stage of training a quantum market generator.
All results in this section used the same baseline data set (B) as used in the classical market generator~\cref{sec:classical_market_generator}.

\subsection{Setting the Annealer's Hyperparameters}\label{sec:qbm_hyperparameters}
Unlike the 12-qubit problem, the larger problem restricted our ability to perform an in-depth analysis to compare the sample distributions produced by the annealer to that of theory.
Therefore, we had to take a more practical approach when choosing some of the annealer hyperparameters such as the relative chain strength, quench point, and embedding.
To this end, we trained a number of models with various settings of these hyperparameters for 20 epochs to get a read on the trend direction, then chose their values empirically.
For this we used a mini-batch size of 10, \( s^* = 1 \), constant learning rates of \( \eta = 0.02 \) and \( \eta_{\hat{\beta}} = 0.01 \), and an initial value of \( \betahat = 0.25 \ \si{\giga\hertz}^{-1} \ (\hat{T} \approx 192 \ \si{\milli\kelvin}) \).

The reason models were only trained for 20 epochs is that the epoch duration was found to be quite high (10-25 minutes) due to latency and load on the annealer, ergo it wasn't very feasible to train every model for a higher number of epochs.
With an average epoch duration of around 15 minutes, a model trained for 20 epochs took roughly 5 hours, so training for 100 epochs would've taken around a day.

\subsubsection{Choosing a Relative Chain Strength}\label{sec:qbm_rcs}
The chain strength \( \gamma \) was computed using the relative chain strength \( \rcs \) as
\begin{align}
    \gamma
        &= \rcs \cdot \min\Big\{
            \max\{J_\text{range}\}, \max\big\{\{\abs{h_i}\} \cup \{\abs{J_{ij}}\}\big\}
        \Big\}
\end{align}

We trained models using various values of \( \rcs \in [0.3, 2] \), and a pause-and-quench anneal schedule with \( \squench = 0.55 \), \( \trelative = 20 \ \si{\micro\second} \), and \( \Deltapause = 0 \ \si{\micro\second} \).
The results are plotted in~\cref{fig:qbm_log_returns_rcs_comparison} (only a subset depicted).
We found too low values of \( \rcs \) led to more chain breaks early on in the training process, which then caused the model to learn a higher temperature, in turn shrinking the allowed range of weights and biases to the point where the model could no longer learn effectively.
Everything indicated that higher relative chain strengths produced better results.
After a number of epochs, we saw \( \max\big\{ \{\abs{h_i}\} \cup \{\abs{J_{ij}}\} \big\} \) grew to a value larger than 0.5, implying that values of \( \rcs \ge 2 \) would not change the results since \( \gamma \) was reaching its limit of \( \max\{J_\text{range}\} = 1 \).
Therefore, we chose a value of \( \rcs = 2 \).

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/log_returns/rcs_comparison.png}
    \end{center}
    \caption{
        Training results of the relative chain strength \( \rcs \) scan for embedding 1, trained for 20 epochs.
        On the left are the mean marginal \( \DKL{\pdata}{\pmodel} \) values, i.e., the average of the KL divergences of the individual currency pairs.
        On the right are the learned estimates of the effective temperature.
        Data plotted on a 5 epoch simple moving average basis to reduce visual noise.
    }
    \label{fig:qbm_log_returns_rcs_comparison}
\end{figure}

\subsubsection{Choosing an Anneal Schedule}
We decided to stick with \( \trelative = 20 \ \si{\micro\second} \) and \( \Deltapause = 0 \ \si{\micro\second} \), but wanted to see if a different value of \( \squench \) would produce improve performance.
We tried values of \( \squench = 0.5, 0.55, 0.6 \) plotted in~\cref{fig:qbm_log_returns_s_quench_comparison}, and found that \( \squench = 0.55 \) led to the best KL divergence curve, and thus chose that value going forward.

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/log_returns/s_quench_comparison.png}
    \end{center}
    \caption{
        Training results of the \( \squench \) scan for embedding 1, trained for 20 epochs.
        On the left are the mean marginal \( \DKL{\pdata}{\pmodel} \) values, i.e., the average of the KL divergences of the individual currency pairs.
        On the right are the learned estimates of the effective temperature.
        Data plotted on a 5 epoch simple moving average basis to reduce visual noise.
    }
    \label{fig:qbm_log_returns_s_quench_comparison}
\end{figure}

\subsubsection{Choosing an Embedding}
The final annealer hyperparamter we sought to tune was the embedding.
We tried 5 different heuristically generated embeddings each composed of around 400 physical qubits and maximum chain lengths of 7.
The comparison plotted in \cref{fig:qbm_log_returns_embedding_comparison} indicated to us that embedding 1 was likely a good choice to continue with.

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/log_returns/embedding_comparison.png}
    \end{center}
    \caption{
        Training results comparing 5 different embeddings, trained for 20 epochs.
        On the left are the mean marginal \( \DKL{\pdata}{\pmodel} \) values, i.e., the average of the KL divergences of the individual currency pairs.
        On the right are the learned estimates of the effective temperature.
        Data plotted on a 5 epoch simple moving average basis to reduce visual noise.
    }
    \label{fig:qbm_log_returns_embedding_comparison}
\end{figure}

\subsection{Results}
With annealer hyperparameters of \( \rcs = 2 \), \( \squench = 0.55 \), and embedding 1, we moved to training a full model over 100 epochs.
The training curves are depicted in~\cref{fig:qbm_log_returns_full_run}, where we observed the KL divergence decrease until around epoch 40 where it then oscillated for the remainder of the training process.
Unfortunately, the training results indicated that BQRBM model significantly underperformed that of the classical model.

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/log_returns/full_run.png}
    \end{center}
    \caption{
        Training results of the model trained using embedding 1 for 100 epochs, compared to the final results obtained with the classical RBM on the same data set.
        On the left is the mean marginal \( \DKL{\pdata}{\pmodel} \) value, i.e., the average of the KL divergences of the individual currency pairs.
        On the right is the learned estimate of the effective temperature.
    }
    \label{fig:qbm_log_returns_full_run}
\end{figure}

Poor model performance is further confirmed in the KL divergences~\cref{tbl:qbm_KL_divergences}.
We see the KL divergences of the BQRBM are about eight times higher than that of the classical RBM.
\begin{table}[!htb]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \input{../tables/qbm/kl_divergences.tbl}
    \end{adjustbox}
    \caption{
        KL divergences of the BQRBM model vs. the classical RBM.
        The values are shown in the format mean \(\pm\) one standard deviation from an ensemble of 100 sample sets with \( 10^4 \) samples each.
}
    \label{tbl:qbm_KL_divergences}
\end{table}

The QQ plots in~\cref{fig:qbm_log_returns_qq} show that the BQRBM model struggled the most with the USDCAD and USDJPY marginals.
\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=0.7\linewidth]{qbm/log_returns/qq.png}
    \end{center}
    \caption{QQ plots of the BQRBM and classical RBM models for each currency pair. Note that these plots only use the same number of samples as the size of the training data set (5165), and thus are not entirely representative of the models' performances.}
    \label{fig:qbm_log_returns_qq}
\end{figure}

\cref{tbl:qbm_correlation_coefficients} show that the BQRBM was able to reproduce the structure of the correlation coefficients, albeit to a lesser extent than the classical RBM.
\begin{table}[!htb]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \input{../tables/qbm/correlation_coefficients.tbl}
    \end{adjustbox}
    \caption{Correlation coefficients of the data set vs. samples generated by the BQRBM and classical RBM models. The BQRBM and RBM values are shown in the format mean \(\pm\) one standard deviation from an ensemble of 100 sample sets with \( 10^4 \) samples each.}
    \label{tbl:qbm_correlation_coefficients}
\end{table}

Surprisingly, the BQRBM was able to capture the volatilities for the most part except for USDJPY, as seen in~\cref{tbl:qbm_volatilities}.
\begin{table}[!htb]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \input{../tables/qbm/volatilities.tbl}
    \end{adjustbox}
    \caption{
        Historical volatilities of the data set vs. samples generated by the RBM models.
        The BQRBM and RBM values are shown in the format mean \(\pm\) one standard deviation from an ensemble of 100 sample sets with \( 10^4 \) samples each.
    }
    \label{tbl:qbm_volatilities}
\end{table}

\cref{tbl:qbm_tails} shows the quantum model struggled more on the tails, particularly with the USDJPY, as well as EURUSD.
The was further confirmed by the tail concentration functions in~\cref{fig:qbm_log_returns_tail_concentrations}.
\begin{table}[!htb]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \input{../tables/qbm/tails.tbl}
    \end{adjustbox}
    \caption{
        Lower and upper tails, i.e., 1st and 99th percentiles, of the data set vs. samples generated by the BQRBM and classical RBM models.
        The BQRBM and RBM values are shown in the format mean \(\pm\) one standard deviation from an ensemble of 100 sample sets with \( 10^4 \) samples each.
    }
    \label{tbl:qbm_tails}
\end{table}

\begin{figure}[!htb]
    \begin{center}
        \includegraphics[width=1\linewidth]{qbm/log_returns/tail_concentrations.png}
    \end{center}
    \caption{Tail concentration functions of the data set vs. samples generated by the BQRBM and classical RBM models for every combination of the currency pairs.}
    \label{fig:qbm_log_returns_tail_concentrations}
\end{figure}

\subsection{Summary}
Overall, the BQRBM model trained using the D-Wave Advantage 4.1 produced lackluster results when compared to the classical RBM, and did not motivate training additional models on the transformed and volatility indicator enhanced data sets.
This could possibly be due to hyperparameters, as our grid search of the space wasn't the most optimal due to training time requirements, but it wasn't really clear if there was a better way to do this.
This could also be due to the fact that the model was so large that it used a significant portion of the QPU and required chains with such lengths of up to 7, which added complexity.

In conclusion, it does not appear that the Advantage 4.1-trained BQRBM can produce results good enough to replace the classical RBM.
It will be interesting to see how much this improves with future generations of annealers, although it will likely take serious advances in the technology to outperform the classical RBM.

\clearpage
\section{Challenges of Using a D-Wave Annealer to Train QBMs}\label{sec:challenges}
Using a D-Wave quantum annealer to train quantum Boltzmann machines is a difficult task, and there are many challenges which need to be overcome in order to do so.
In this section we touch on some of these difficulties and discuss some possible methods to mitigate them.
Around the time this project was started, Pochart et al. released a paper~\cite{pochart_2021} in which they discuss some of the challenges associated with using a D-Wave annealer to sample Boltzmann random variables.

\subsection{Choosing an Embedding}
Mapping the logical qubits to physical qubits is a nontrivial task.
D-Wave provides a heuristic method to find embeddings, but in practice it can't be guaranteed that the returned embedding is optimal.
As we saw first hand, different embeddings can produce different results.
Therefore, it is recommended to generate multiple embeddings and compare them against each other, and choose the one that performs the best.
Additionally, it is worth noting that an optimal embedding on one QPU might not be optimal on another of the same generation.

\subsubsection{Chain Strength}
Depending on how large the problem is, one will likely need to use an embedding that is not direct, i.e., one that requires chains of physical qubits to represent single logical qubits due to limited connectivity.
This brings about an additional hyperparameter that needs to be tuned.
Rather than setting the chain strength directly though, it is recommended to use the relative chain strength as mentioned in~\cref{sec:qbm_rcs}.
It is best to do a comparison in the beginning to get an idea of what a good relative chain strength might be, as it is problem dependent.

\subsection{Sampling the Proper Distribution}
The most important thing when using a quantum annealer to train a Boltzmann machine is making sure the annealer is sampling from the proper distribution.
In the case of the quantum Boltzmann machine we need samples generated according to \( \rho = \frac{1}{Z} e^{-\beta H(s^*)} \).
For smaller problems it is easy to compare results obtained from the annealer to an exact computed distribution (as we did for the 12-qubit problem), but it is not so straight forward for larger problems.
For larger problems there is the possibility to use advanced methods, such as they did in~\cite{marshall_2019} with the use of an entropic sampling technique~\cite{barash_2019} based on population annealing to estimate the degeneracies, and in turn use those to compute a classical Boltzmann distribution to compare to, but that might not always be practical.
Alternatively, one can try a hyperparameter grid search as we did in~\cref{sec:qbm_hyperparameters}

\subsubsection{Effective Temperature}
One of the most important hyperparemeters is that of the effective inverse temperature \( \beta \).
In practice we divide our weights and biases by a factor of \( -\betahat B(s^*) \) (as per~\cref{eq:qbm_scaling}) in order to cancel out the effective temperature so that we can sample the problem we wish to, thus it is crucial for proper parameter scaling.
For the case of \( s^* = 1 \) we have the ability to treat the effective temperature as a learnable parameter (as in~\cref{sec:learning_beta}), for which we use \( \betahat \) as an estimator of.
This isn't so straight forward for \( s^* < 1 \) though, because of the initial Hamiltonian and the D-Wave's inability to measure the qubits in the \( x \)-direction.

\subsubsection{Anneal Schedules}
The ability to configure the anneal schedule as allowed by the D-Wave annealer means that there are a number of different ways one can tweak the annealing process such that the results returned minimize the KL divergence between the theoretical distribution one wishes to approximate and the samples returned by the annealer.
In an ideal world, the way to get the desired distribution is to anneal slowly at first, then quench the system at the point \( s^* \) and measure the qubits~\cite{amin_2018}.
Unfortunately, the research conducted in this thesis seems to indicate that the current generation of D-Wave annealers cannot quench fast enough to prevent any nontrivial dynamics occurring after \( s^* \), and all of the distributions returned are more similar to a classical Boltzmann distribution than a quantum one.
With that said, the annealer can still be used to assist in the training of a classical Boltzmann machine.

\subsection{QPU Limitations and Imperfections}
The properties of the QPU itself must also be taken into account.
There is no doubt that D-Wave is a top-notch manufacturer of quantum annealers, but even with all of their expertise the QPUs are still subject to imperfections and errors.
It is possible for some areas of the chip to perform better than others, or for some of the qubits to have readout biases (although biases can be mitigated by using gauge transforms as detailed in~\cref{sec:gauge}).

\subsubsection{Maximum Sample Set Size}
One of the main limitations of the D-Wave annealer for this purpose is that of the maximum sample set size.
When sampling the D-Wave one can only generate sample sets with a maximum size of \( 10^4 \) samples, which is adequate for the intended purpose of optimization, but can fall short when one wants to use it as a sampler for a QBM.
It is natural to think that one could just combine the results from multiple sample sets, but this isn't necessarily the case.
Due to the spin-bath polarization effect (see error sources below), one cannot combine sample sets because of the possibility of previous samples affecting future ones~\cite{pochart_2021}.

\subsubsection{Time Requirements}
Another issue is the time requirements.
Most models trained here required little QPU access time, around 5-10 minutes, but this can add up and get expensive if one is doing a hyperparameter grid search.
Additionally, there is the total training time, which as we saw can be quite substantial due the latency to the cloud platform combined with the load queue of the solver.

\subsubsection{Error Sources}
There are a number of sources from which errors can arise on a D-Wave quantum annealer.
The D-Wave documentation does an excellent job at detailing these errors in their documentation~\cite{dwave_ice_errors,dwave_other_errors}, so we will only briefly touch on them here with high-level information obtained from the aforementioned citations.
\begin{itemize}
    \item \textbf{Integrated Control Errors (ICE)} are errors due to the accuracy at which the \( h_i \) and \( J_{ij} \) values can be implemented.
        In mathematical terms this is because the problem the QPU solves is closer to
        \begin{align}
            H_{\text{Ising}}^\delta(s) = \sum_i (h_i + \delta_{h_i}) \sigma_i^z + \sum_{i,j} (J_{ij} + \delta_{J_{ij}}) \sigma_i^z \sigma_j^z
        \end{align}
    \item \textbf{Temperature} errors arise due to fluctuations in the physical temperature of the device, which can change depending on how frequently the QPU is programmed.
    \item \textbf{High-Energy Photon Flux} errors can occur in the presence of photons with energies higher than that expected at the effective temperature dependent equilibrium, which can lead to higher energy solutions. These photons originate from cryogenic filtering at higher temperature phases.
    \item \textbf{Readout Fidelity} errors occur when the bitstring returned by the annealer differs from that arrived at by the QPU by one or more bit flips.
        For reference, D-Wave annealers have a readout fidelity of >99\%.
    \item \textbf{Programming Errors} sometimes the problem implemented by the QPU suffers from programming issues which can result in the implemented problem's low-energy subspace not having an overlap with that of the desired problem.
    \item \textbf{Spin-Bath Polarization Effect} errors can arise when the current flowing through the qubits during the annealing process cause the spins to obtain a polarization which can bias the measurements.
\end{itemize}
