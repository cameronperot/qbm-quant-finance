{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444cdef5-48f1-49a6-9b96-9b63a8ab2663",
   "metadata": {},
   "source": [
    "# QBM: Log Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8e8b6a-56bd-4881-ab78-72322c441ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 s (started: 2022-03-23 23:34:28 +01:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dwave.system import DWaveSampler, FixedEmbeddingComposite\n",
    "from minorminer import find_embedding\n",
    "from numba import njit\n",
    "from scipy.constants import k as k_B, h as h_P\n",
    "\n",
    "k_B /= h_P * 1e9\n",
    "matplotlib.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "from qbm.models import BQRBM\n",
    "from qbm.plotting import plot_qq, plot_tail_concentrations_grid\n",
    "from qbm.metrics import compute_correlation_coefficients, compute_annualized_volatility\n",
    "from qbm.utils import (\n",
    "    binarize_df,\n",
    "    convert_bin_list_to_str,\n",
    "    get_binarization_params,\n",
    "    get_project_dir,\n",
    "    get_rng,\n",
    "    kl_divergence,\n",
    "    load_artifact,\n",
    "    load_log_returns,\n",
    "    lr_exp_decay,\n",
    "    prepare_training_data,\n",
    "    save_artifact,\n",
    "    unbinarize_df,\n",
    "    compute_stats_over_dfs,\n",
    ")\n",
    "\n",
    "project_dir = get_project_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fdfc1-7d3c-41f9-b789-d89c818172ec",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed29756b-778f-41ea-abce-cc876b1490b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 123 ms (started: 2022-03-23 23:34:29 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "model_name = \"baseline\"\n",
    "qpu_params = {\"region\": \"na-west-1\", \"solver\": \"Advantage_system4.1\"}\n",
    "artifacts_dir = project_dir / f\"artifacts/qbm/log_returns/{qpu_params['solver']}\"\n",
    "\n",
    "# load anneal schedule data\n",
    "if qpu_params[\"solver\"] == \"Advantage_system4.1\":\n",
    "    csv_name = \"09-1263A-A_Advantage_system4_1_annealing_schedule.csv\"\n",
    "elif qpu_params[\"solver\"] == \"Advantage_system5.1\":\n",
    "    csv_name = \"09-1265A-A_Advantage_system5_1_annealing_schedule.csv\"\n",
    "df_anneal = pd.read_csv(\n",
    "    project_dir / f\"data/anneal_schedules/csv/{csv_name}\", index_col=\"s\",\n",
    ")\n",
    "if 0.5 not in df_anneal.index:\n",
    "    df_anneal.loc[0.5] = (df_anneal.loc[0.499] + df_anneal.loc[0.501]) / 2\n",
    "df_anneal.sort_index(inplace=True)\n",
    "\n",
    "models_dir = artifacts_dir / f\"models/{model_name}\"\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True)\n",
    "samples_dir = artifacts_dir / f\"samples/{model_name}\"\n",
    "if not samples_dir.exists():\n",
    "    samples_dir.mkdir(parents=True)\n",
    "plots_dir = project_dir / \"results/plots/qbm/log_returns\"\n",
    "if not plots_dir.exists():\n",
    "    plots_dir.mkdir(parents=True)\n",
    "config_path = models_dir / f\"config.json\"\n",
    "config = load_artifact(config_path)\n",
    "model_params = config[\"model\"]\n",
    "data_params = config[\"data\"]\n",
    "\n",
    "\n",
    "rng = get_rng(model_params[\"seed\"])\n",
    "\n",
    "# data loading\n",
    "date_format = \"%Y-%m-%d\"\n",
    "start_date = datetime.strptime(data_params[\"start_date\"], date_format)\n",
    "end_date = datetime.strptime(data_params[\"end_date\"], date_format)\n",
    "if model_params[\"volatility_indicators\"]:\n",
    "    start_date -= timedelta(days=90)\n",
    "\n",
    "log_returns = load_log_returns(\n",
    "    data_params[\"data_source\"],\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    outlier_threshold=data_params[\"outlier_threshold\"],\n",
    ")\n",
    "log_returns_raw = log_returns.copy()\n",
    "\n",
    "# volatility indicators\n",
    "volatility_binarized = None\n",
    "if model_params[\"volatility_indicators\"]:\n",
    "    volatility_binarized = binarize_volatility(\n",
    "        compute_rolling_volatility(log_returns, timedelta(days=90))\n",
    "    )\n",
    "\n",
    "# data transformation\n",
    "transformer = None\n",
    "if model_params[\"transform\"].get(\"type\") is not None:\n",
    "    if model_params[\"transform\"][\"type\"] == \"quantile\":\n",
    "        transformer = QuantileTransformer(**model_params[\"transform\"][\"params\"])\n",
    "        log_returns = pd.DataFrame(\n",
    "            transformer.fit_transform(log_returns),\n",
    "            columns=log_returns.columns,\n",
    "            index=log_returns.index,\n",
    "        )\n",
    "    elif model_params[\"transform\"][\"type\"] == \"power\":\n",
    "        transformer = PowerTransformer(\n",
    "            log_returns, **model_params[\"transform\"][\"params\"]\n",
    "        )\n",
    "        log_returns = transformer.transform(log_returns)\n",
    "\n",
    "# binarization\n",
    "binarization_params = get_binarization_params(\n",
    "    log_returns, n_bits=model_params[\"n_bits\"]\n",
    ")\n",
    "log_returns_binarized = binarize_df(log_returns, binarization_params)\n",
    "model_params[\"binarization_params\"] = binarization_params\n",
    "\n",
    "# create the training set\n",
    "training_data = prepare_training_data(log_returns_binarized, volatility_binarized)\n",
    "X_train = training_data[\"X_train\"]\n",
    "rng.shuffle(X_train)\n",
    "model_params[\"X_train_shape\"] = X_train.shape\n",
    "model_params[\"columns\"] = training_data[\"columns\"]\n",
    "model_params[\"split_indices\"] = training_data[\"split_indices\"]\n",
    "\n",
    "# save the config\n",
    "model_params[\"n_visible\"] = X_train.shape[-1]\n",
    "model_params[\"n_qubits\"] = model_params[\"n_visible\"] + model_params[\"n_hidden\"]\n",
    "save_artifact(config, config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6533a-bff5-4559-beb4-8850f548d082",
   "metadata": {},
   "source": [
    "## Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d542e81e-a4c6-4114-b896-15dd05e20e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>n_qubits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1  2   3   4  5   6   7  n_qubits\n",
       "1   0  0  46  18  0  22   8       398\n",
       "2   0  0  46  18  0  21   9       399\n",
       "3   0  0  46  18  0  22   8       398\n",
       "4   0  0  44  20  0  22   8       400\n",
       "5   0  0  42  22  0  30   0       394\n",
       "6   0  0  46  18  0  22   8       398\n",
       "7   0  0  44  20  0  22   8       400\n",
       "8   0  0  46  18  0  20  10       400\n",
       "9   0  0  46  18  0  22   8       398\n",
       "10  0  0  46  18  0  20  10       400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.97 ms (started: 2022-03-23 23:34:29 +01:00)\n"
     ]
    }
   ],
   "source": [
    "generate_embeddings = False\n",
    "max_chain_length = 7\n",
    "max_qubits = 400\n",
    "embedding_ids = range(1, 11)\n",
    "embeddings_dir = (\n",
    "    artifacts_dir / f\"embeddings/{model_params['n_visible']}x{model_params['n_hidden']}\"\n",
    ")\n",
    "embeddings = {}\n",
    "if generate_embeddings:\n",
    "    # generate the underlying graphical structure to use for determining the embedding\n",
    "    qpu = DWaveSampler(**model_params[\"qpu\"])\n",
    "    source_edgelist = []\n",
    "    for i in range(model_params[\"n_visible\"]):\n",
    "        for j in range(model_params[\"n_visible\"], model_params[\"n_qubits\"]):\n",
    "            source_edgelist.append((i, j))\n",
    "    _, target_edgelist, target_rdjacency = qpu.structure\n",
    "\n",
    "    # generate embeddings which satisfy the max chain length\n",
    "    for embedding_id in embedding_ids:\n",
    "        max_chain_length_satisfied = False\n",
    "        while not max_chain_length_satisfied:\n",
    "            # generate embedding\n",
    "            embedding = find_embedding(source_edgelist, target_edgelist)\n",
    "\n",
    "            # check max chain length\n",
    "            for logical_qubit, physical_qubits in embedding.items():\n",
    "                if len(physical_qubits) > max_chain_length:\n",
    "                    break\n",
    "            else:\n",
    "                if np.sum([len(x) for x in embedding.values()]) <= max_qubits:\n",
    "                    max_chain_length_satisfied = True\n",
    "\n",
    "        embeddings[embedding_id] = embedding\n",
    "\n",
    "    # save embeddings\n",
    "    for embedding_id, embedding in embeddings.items():\n",
    "        save_artifact(embedding, embeddings_dir / f\"{embedding_id:02}.json\")\n",
    "else:\n",
    "    for embedding_path in sorted([x for x in embeddings_dir.iterdir()]):\n",
    "        embedding_id = int(embedding_path.stem)\n",
    "        embeddings[embedding_id] = {\n",
    "            int(k): v for k, v in load_artifact(embedding_path).items()\n",
    "        }\n",
    "\n",
    "chain_lengths = {}\n",
    "for embedding_id, embedding in embeddings.items():\n",
    "    chain_lengths[embedding_id] = {i: 0 for i in range(1, max_chain_length + 1)}\n",
    "    for logical_qubit, physical_qubits in embedding.items():\n",
    "        chain_length = len(physical_qubits)\n",
    "        chain_lengths[embedding_id][chain_length] += 1\n",
    "chain_lengths = pd.DataFrame.from_dict(chain_lengths, orient=\"index\")\n",
    "chain_lengths[\"n_qubits\"] = (chain_lengths * np.arange(1, max_chain_length + 1)).sum(\n",
    "    axis=1\n",
    ")\n",
    "chain_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7714c0-ff4c-40ef-80f6-c8e9ffb7bab4",
   "metadata": {},
   "source": [
    "## Callback Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04068be4-897b-46e1-be13-7644e5c7d7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.45 ms (started: 2022-03-23 23:34:29 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def convert_state_vectors_to_df(V):\n",
    "    split_indices = model_params[\"split_indices\"]\n",
    "    columns = model_params[\"columns\"]\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            np.stack(\n",
    "                [\"\".join(x) for x in np.array_split(V[i].astype(\"str\"), split_indices)]\n",
    "            )\n",
    "            for i in range(len(V))\n",
    "        ],\n",
    "        columns=columns,\n",
    "    )\n",
    "\n",
    "    return unbinarize_df(df, binarization_params)\n",
    "\n",
    "\n",
    "def callback(model, sample_state_vectors):\n",
    "    X_train = model.X_train\n",
    "    n_visible = model.X_train.shape[1]\n",
    "    combinations = list(itertools.combinations(model_params[\"columns\"], 2))\n",
    "\n",
    "    df_train = convert_state_vectors_to_df(model._eigen_to_binary(model.X_train))\n",
    "    df_sample = convert_state_vectors_to_df(\n",
    "        model._eigen_to_binary(sample_state_vectors[:, :n_visible])\n",
    "    )\n",
    "\n",
    "    dkls = {\n",
    "        column: kl_divergence(\n",
    "            df_train[column], df_sample[column], n_bins=32, smooth=1e-6\n",
    "        )\n",
    "        for column in df_train.columns\n",
    "    }\n",
    "    dkls = pd.DataFrame.from_dict(dkls, orient=\"index\", columns=[\"D_KL\"])\n",
    "\n",
    "    ccs_train = compute_correlation_coefficients(df_train, combinations)\n",
    "    ccs_sample = compute_correlation_coefficients(df_sample, combinations)\n",
    "    ccs = ccs_sample - ccs_train\n",
    "    ccs.columns = [\"\u0394 \" + x for x in ccs.columns]\n",
    "\n",
    "    h = model.h\n",
    "    J = model.J\n",
    "    hJ_stats = {\n",
    "        \"h\": [h.mean(), h.std(), h.min(), h.max()],\n",
    "        \"J\": [J.mean(), J.std(), J.min(), J.max()],\n",
    "    }\n",
    "    hJ_stats = pd.DataFrame.from_dict(\n",
    "        hJ_stats, orient=\"index\", columns=[\"mean\", \"std\", \"min\", \"max\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"value\": {\"dkls\": dkls, \"ccs\": ccs, \"hJ_stats\": hJ_stats},\n",
    "        \"print\": str(dkls) + \"\\n\" + str(ccs) + \"\\n\" + str(hJ_stats),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa23263-9e01-427d-bda1-605d511ef831",
   "metadata": {},
   "source": [
    "## Embedding 1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e723d8-2f37-48e7-944a-c8abf563c02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.7 ms (started: 2022-03-23 23:34:29 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# set the model params\n",
    "train_model = False\n",
    "beta_initial = 0.25\n",
    "beta_range = (0.01, 10)\n",
    "embedding_id = 1\n",
    "n_epochs = 20\n",
    "learning_rate = 2e-2\n",
    "learning_rate_beta = 1e-2\n",
    "mini_batch_size = 10\n",
    "s_freeze = 1.0\n",
    "\n",
    "for s_quench in [0.55]:\n",
    "    # set the anneal params\n",
    "    t_r = 20\n",
    "    \u03b1_quench = 2\n",
    "    t_quench = round(s_quench * t_r, 3)\n",
    "    \u0394_quench = round((1 - s_quench) / \u03b1_quench, 3)\n",
    "    if s_quench == 1:\n",
    "        anneal_schedule = [(0, 0), (t_quench, s_quench)]\n",
    "    else:\n",
    "        anneal_schedule = [\n",
    "            (0, 0),\n",
    "            (t_quench, s_quench),\n",
    "            (round(t_quench + \u0394_quench, 3), 1),\n",
    "        ]\n",
    "    anneal_params = {\n",
    "        \"s\": s_freeze,\n",
    "        \"A\": df_anneal.loc[s_freeze, \"A(s) (GHz)\"],\n",
    "        \"B\": df_anneal.loc[s_freeze, \"B(s) (GHz)\"],\n",
    "        \"schedule\": anneal_schedule,\n",
    "    }\n",
    "\n",
    "    # train the models\n",
    "    relative_chain_strengths = [0.4]\n",
    "    for relative_chain_strength in relative_chain_strengths:\n",
    "        anneal_params[\"relative_chain_strength\"] = relative_chain_strength\n",
    "\n",
    "        # set model name and path\n",
    "        if relative_chain_strength is not None:\n",
    "            model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength:.2f}\"\n",
    "        else:\n",
    "            model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength}\"\n",
    "        model_path = models_dir / f\"embedding_{embedding_id:02}/{model_name}.pkl\"\n",
    "        if train_model:\n",
    "            print(model_name)\n",
    "            if model_path.exists():\n",
    "                print(f\"Model already exists\")\n",
    "                continue\n",
    "\n",
    "            # model init\n",
    "            model = BQRBM(\n",
    "                X_train=X_train,\n",
    "                n_hidden=model_params[\"n_hidden\"],\n",
    "                embedding=embeddings[embedding_id],\n",
    "                anneal_params=anneal_params,\n",
    "                beta_initial=beta_initial,\n",
    "                beta_range=beta_range,\n",
    "                qpu_params=qpu_params,\n",
    "            )\n",
    "\n",
    "            # model train and save\n",
    "            model.train(\n",
    "                n_epochs=n_epochs,\n",
    "                learning_rate=learning_rate,\n",
    "                learning_rate_beta=learning_rate_beta,\n",
    "                mini_batch_size=mini_batch_size,\n",
    "                callback=callback,\n",
    "            )\n",
    "            model.save(model_path)\n",
    "\n",
    "            # save attributes as dict in case of error loading old pickled object\n",
    "            model_attributes = {\n",
    "                \"A\": model.A,\n",
    "                \"B\": model.B,\n",
    "                \"a\": model.a,\n",
    "                \"b\": model.b,\n",
    "                \"W\": model.W,\n",
    "                \"beta\": model.beta,\n",
    "                \"embedding\": model.embedding,\n",
    "                \"qpu_params\": model.qpu_params,\n",
    "                \"anneal_params\": model.anneal_params,\n",
    "                \"exact_params\": model.exact_params,\n",
    "                \"beta_history\": model.beta_history,\n",
    "                \"callback_outputs\": [x for x in model.callback_outputs],\n",
    "            }\n",
    "            save_artifact(\n",
    "                model_attributes,\n",
    "                Path(str(model_path).replace(\"model-\", \"model_attributes-\")),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57292bcb-2027-4212-bacb-d9a7158aab76",
   "metadata": {},
   "source": [
    "### RCS Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d743b9-5fd5-4233-9df1-1610a444841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.4 s (started: 2022-03-23 23:34:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "models_rcs = {}\n",
    "s_freeze = 1.0\n",
    "embedding_id = 1\n",
    "for s_quench in [0.55]:\n",
    "    for relative_chain_strength in [0.3, 0.8, 1.2, 1.6, 1.8, 2.0]:\n",
    "        if relative_chain_strength is not None:\n",
    "            model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength:.2f}\"\n",
    "        else:\n",
    "            model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength}\"\n",
    "        model_path = models_dir / f\"embedding_{embedding_id:02}/{model_name}.pkl\"\n",
    "        models_rcs[s_quench, relative_chain_strength] = BQRBM.load(model_path)\n",
    "\n",
    "dkls_rcs = {}\n",
    "ccs_rcs = {}\n",
    "beta_rcs = {}\n",
    "for (s_quench, relative_chain_strength), model in models_rcs.items():\n",
    "    dkls_rcs[s_quench, relative_chain_strength] = [\n",
    "        x[\"value\"][\"dkls\"].mean().mean() for x in model.callback_outputs\n",
    "    ][:20]\n",
    "    ccs_rcs[s_quench, relative_chain_strength] = [\n",
    "        x[\"value\"][\"ccs\"].abs().mean().mean() for x in model.callback_outputs\n",
    "    ][:20]\n",
    "    beta_rcs[s_quench, relative_chain_strength] = model.beta_history[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc366d9c-e831-4cf1-b0f3-d9bc548a0655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.06 s (started: 2022-03-23 23:34:40 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def smooth(x, k=5):\n",
    "    x_out = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        x_out[i] = np.mean(x[i - min((k - 1, i)) : i + 1])\n",
    "    return x_out\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "markers = [\"o\", \"^\", \"v\", \"<\", \">\", \"s\", \"p\", \"*\", \"P\", \"X\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "for i, ((s_quench, relative_chain_strength), dkl) in enumerate(dkls_rcs.items()):\n",
    "    ax[0].plot(\n",
    "        range(1, len(dkl) + 1),\n",
    "        smooth(dkl),\n",
    "        label=fr\"$\\gamma_{{relative}} = {relative_chain_strength}$\",\n",
    "        markersize=8,\n",
    "        marker=markers[i],\n",
    "        color=colors[i],\n",
    "    )\n",
    "for i, ((s_quench, relative_chain_strength), betas) in enumerate(beta_rcs.items()):\n",
    "    ax[1].plot(\n",
    "        range(len(betas)),\n",
    "        smooth(1 / k_B / np.array(betas) * 1000),\n",
    "        markersize=8,\n",
    "        marker=markers[i],\n",
    "        color=colors[i],\n",
    "    )\n",
    "# fig.suptitle(\"Embedding 1, $s_{quench}$ = 0.55, 5 Epoch Moving Average\")\n",
    "ax[0].set_ylabel(r\"Mean Marginal $D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax[1].set_ylabel(r\"$\\hat{T}$ [mK]\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[0].set_xticks(np.arange(0, 25, 5))\n",
    "ax[1].set_xticks(np.arange(0, 25, 5))\n",
    "ax[1].set_yticks(np.arange(140, 280, 20))\n",
    "ax[0].set_ylim((0, 0.30))\n",
    "ax[1].set_ylim((140, 270))\n",
    "ax[0].grid(alpha=0.7)\n",
    "ax[1].grid(alpha=0.7)\n",
    "ax[0].legend(ncol=1, loc=\"upper right\")\n",
    "fig.suptitle(r\"$s_{quench} = 0.55$, $t_{relative} = 20$ \u03bcs, $\\Delta_{pause} = 0$ \u03bcs\", y=0.92)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"rcs_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af4269-1b05-488c-a713-031ecbfbcf9b",
   "metadata": {},
   "source": [
    "### $s_{\\text{quench}}$ Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b20755-7dbe-420b-867a-5f4aee4b813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.3 s (started: 2022-03-23 23:34:41 +01:00)\n"
     ]
    }
   ],
   "source": [
    "models_s_quench = {}\n",
    "s_freeze = 1.0\n",
    "embedding_id = 1\n",
    "for s_quench in [0.5, 0.55, 0.6]:\n",
    "    for relative_chain_strength in [2.0]:\n",
    "        if relative_chain_strength is not None:\n",
    "            model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength:.2f}\"\n",
    "        else:\n",
    "            model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength}\"\n",
    "        model_path = models_dir / f\"embedding_{embedding_id:02}/{model_name}.pkl\"\n",
    "        models_s_quench[s_quench, relative_chain_strength] = BQRBM.load(model_path)\n",
    "\n",
    "dkls_s_quench = {}\n",
    "ccs_s_quench = {}\n",
    "beta_s_quench = {}\n",
    "for (s_quench, relative_chain_strength), model in models_s_quench.items():\n",
    "    dkls_s_quench[s_quench, relative_chain_strength] = [\n",
    "        x[\"value\"][\"dkls\"].mean().mean() for x in model.callback_outputs\n",
    "    ][:20]\n",
    "    ccs_s_quench[s_quench, relative_chain_strength] = [\n",
    "        x[\"value\"][\"ccs\"].abs().mean().mean() for x in model.callback_outputs\n",
    "    ][:20]\n",
    "    beta_s_quench[s_quench, relative_chain_strength] = model.beta_history[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b1a213-a45f-400d-bb5c-8a17b241e693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 664 ms (started: 2022-03-23 23:34:46 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def smooth(x, k=5):\n",
    "    x_out = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        x_out[i] = np.mean(x[i - min((k - 1, i)) : i + 1])\n",
    "    return x_out\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "markers = [\"o\", \"^\", \"v\", \"<\", \">\", \"s\", \"p\", \"*\", \"P\", \"X\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "for i, ((s_quench, relative_chain_strength), dkl) in enumerate(dkls_s_quench.items()):\n",
    "    ax[0].plot(\n",
    "        range(1, len(dkl) + 1),\n",
    "        smooth(dkl),\n",
    "        label=f\"$s_{{quench}}$ = {s_quench:.2f}\",\n",
    "        markersize=8,\n",
    "        marker=markers[i],\n",
    "        color=colors[i],\n",
    "    )\n",
    "for i, ((s_quench, relative_chain_strength), betas) in enumerate(beta_s_quench.items()):\n",
    "    ax[1].plot(\n",
    "        range(len(betas)),\n",
    "        smooth(1 / k_B / np.array(betas) * 1000),\n",
    "        markersize=8,\n",
    "        marker=markers[i],\n",
    "        color=colors[i],\n",
    "    )\n",
    "# fig.suptitle(\"Embedding 1, RCS = 2, 5 Epoch Moving Average\")\n",
    "ax[0].set_ylabel(r\"Mean Marginal $D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax[1].set_ylabel(r\"$\\hat{T}$ [mK]\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[0].set_xticks(np.arange(0, 25, 5))\n",
    "ax[1].set_xticks(np.arange(0, 25, 5))\n",
    "ax[1].set_yticks(np.arange(140, 210, 10))\n",
    "ax[0].set_ylim((0, 0.30))\n",
    "ax[0].grid(alpha=0.7)\n",
    "ax[1].grid(alpha=0.7)\n",
    "ax[0].legend()\n",
    "fig.suptitle(r\"$\\gamma_{relative} = 2$, $t_{relative} = 20$ \u03bcs, $\\Delta_{pause} = 0$ \u03bcs\", y=0.92)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"s_quench_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96974da9-777a-4e30-bbd0-789394d9872c",
   "metadata": {},
   "source": [
    "## Embedding Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef13b32-640e-47e8-8413-e1320af9f5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.78 ms (started: 2022-03-23 23:34:47 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# set the model params\n",
    "train_model = False\n",
    "beta_initial = 0.25\n",
    "beta_range = (0.01, 10)\n",
    "n_epochs = 20\n",
    "learning_rate = 2e-2\n",
    "learning_rate_beta = 1e-2\n",
    "mini_batch_size = 10\n",
    "s_freeze = 1.0\n",
    "s_quench = 0.55\n",
    "relative_chain_strength = 2.0\n",
    "\n",
    "# set the anneal params\n",
    "t_r = 20\n",
    "\u03b1_quench = 2\n",
    "t_quench = round(s_quench * t_r, 3)\n",
    "\u0394_quench = round((1 - s_quench) / \u03b1_quench, 3)\n",
    "if s_quench == 1:\n",
    "    anneal_schedule = [(0, 0), (t_quench, s_quench)]\n",
    "else:\n",
    "    anneal_schedule = [\n",
    "        (0, 0),\n",
    "        (t_quench, s_quench),\n",
    "        (round(t_quench + \u0394_quench, 3), 1),\n",
    "    ]\n",
    "anneal_params = {\n",
    "    \"s\": s_freeze,\n",
    "    \"A\": df_anneal.loc[s_freeze, \"A(s) (GHz)\"],\n",
    "    \"B\": df_anneal.loc[s_freeze, \"B(s) (GHz)\"],\n",
    "    \"schedule\": anneal_schedule,\n",
    "}\n",
    "\n",
    "# train the models\n",
    "anneal_params[\"relative_chain_strength\"] = relative_chain_strength\n",
    "\n",
    "for embedding_id in [1, 2, 3, 4, 5]:\n",
    "    # set model name and path\n",
    "    if relative_chain_strength is not None:\n",
    "        model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength:.2f}\"\n",
    "    else:\n",
    "        model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength}\"\n",
    "    model_path = models_dir / f\"embedding_{embedding_id:02}/{model_name}.pkl\"\n",
    "    if train_model:\n",
    "        print(model_path)\n",
    "        if model_path.exists():\n",
    "            print(f\"Model already exists\")\n",
    "            continue\n",
    "\n",
    "        # model init\n",
    "        model = BQRBM(\n",
    "            X_train=X_train,\n",
    "            n_hidden=model_params[\"n_hidden\"],\n",
    "            embedding=embeddings[embedding_id],\n",
    "            anneal_params=anneal_params,\n",
    "            beta_initial=beta_initial,\n",
    "            beta_range=beta_range,\n",
    "            qpu_params=qpu_params,\n",
    "        )\n",
    "\n",
    "        # model train and save\n",
    "        model.train(\n",
    "            n_epochs=n_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            learning_rate_beta=learning_rate_beta,\n",
    "            mini_batch_size=mini_batch_size,\n",
    "            callback=callback,\n",
    "        )\n",
    "        model.save(model_path)\n",
    "\n",
    "        # save attributes as dict in case of error loading old pickled object\n",
    "        model_attributes = {\n",
    "            \"A\": model.A,\n",
    "            \"B\": model.B,\n",
    "            \"a\": model.a,\n",
    "            \"b\": model.b,\n",
    "            \"W\": model.W,\n",
    "            \"beta\": model.beta,\n",
    "            \"embedding\": model.embedding,\n",
    "            \"qpu_params\": model.qpu_params,\n",
    "            \"anneal_params\": model.anneal_params,\n",
    "            \"exact_params\": model.exact_params,\n",
    "            \"beta_history\": model.beta_history,\n",
    "            \"callback_outputs\": [x for x in model.callback_outputs],\n",
    "        }\n",
    "        save_artifact(\n",
    "            model_attributes,\n",
    "            Path(str(model_path).replace(\"model-\", \"model_attributes-\")),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "090daec1-dd55-43de-af01-49242cc45578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.47 s (started: 2022-03-23 23:34:47 +01:00)\n"
     ]
    }
   ],
   "source": [
    "models_embeddings = {}\n",
    "s_freeze = 1.0\n",
    "s_quench = 0.55\n",
    "embedding_ids = [1, 2, 3, 4, 5]\n",
    "relative_chain_strength = 2.0\n",
    "for embedding_id in embedding_ids:\n",
    "    model_name = f\"model-s_freeze={s_freeze:.2f}-s_quench={s_quench:.2f}-rcs={relative_chain_strength:.2f}\"\n",
    "    model_path = models_dir / f\"embedding_{embedding_id:02}/{model_name}.pkl\"\n",
    "    models_embeddings[embedding_id] = BQRBM.load(model_path)\n",
    "\n",
    "dkls_embeddings = {}\n",
    "ccs_embeddings = {}\n",
    "beta_embeddings = {}\n",
    "for embedding_id, model in models_embeddings.items():\n",
    "    dkls_embeddings[embedding_id] = [\n",
    "        x[\"value\"][\"dkls\"].mean().mean() for x in model.callback_outputs\n",
    "    ][:20]\n",
    "    ccs_embeddings[embedding_id] = [\n",
    "        x[\"value\"][\"ccs\"].abs().mean().mean() for x in model.callback_outputs\n",
    "    ][:20]\n",
    "    beta_embeddings[embedding_id] = model.beta_history[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c9eb6e-e00a-4548-bd81-037ceb5e2899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 700 ms (started: 2022-03-23 23:34:56 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def smooth(x, k=5):\n",
    "    x_out = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        x_out[i] = np.mean(x[i - min((k - 1, i)) : i + 1])\n",
    "    return x_out\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "markers = [\"o\", \"^\", \"v\", \"<\", \">\", \"s\", \"p\", \"*\", \"P\", \"X\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "for i, (embedding_id, dkl) in enumerate(dkls_embeddings.items()):\n",
    "    ax[0].plot(\n",
    "        range(1, len(dkl) + 1),\n",
    "        smooth(dkl),\n",
    "        label=f\"Embedding {embedding_id:2}\",\n",
    "        markersize=8,\n",
    "        marker=markers[i],\n",
    "        color=colors[i],\n",
    "    )\n",
    "for i, (embedding_id, betas) in enumerate(beta_embeddings.items()):\n",
    "    ax[1].plot(\n",
    "        range(len(betas)),\n",
    "        smooth(1 / k_B / np.array(betas) * 1000),\n",
    "        markersize=8,\n",
    "        marker=markers[i],\n",
    "        color=colors[i],\n",
    "    )\n",
    "# fig.suptitle(\"$s_{quench}$ = 0.55, RCS = 2, 5 Epoch Moving Average\")\n",
    "ax[0].set_ylabel(r\"Mean Marginal $D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax[1].set_ylabel(r\"$\\hat{T}$ [mK]\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[0].set_xticks(np.arange(0, 25, 5))\n",
    "ax[1].set_xticks(np.arange(0, 25, 5))\n",
    "ax[1].set_yticks(np.arange(140, 210, 10))\n",
    "ax[0].set_ylim((0, 0.30))\n",
    "ax[0].grid(alpha=0.7)\n",
    "ax[1].grid(alpha=0.7)\n",
    "ax[0].legend()\n",
    "fig.suptitle(r\"$\\gamma_{relative} = 2$, $s_{quench} = 0.55$, $t_{relative} = 20$ \u03bcs, $\\Delta_{pause} = 0$ \u03bcs\", y=0.92)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"embedding_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e8029-e6d4-4024-b305-54e793152f27",
   "metadata": {},
   "source": [
    "## Train Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69986b62-e6f0-4579-b87b-a02eb6c957fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.92 s (started: 2022-03-23 23:34:56 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# set the model params\n",
    "train_model = False\n",
    "embedding_id = 1\n",
    "n_epochs = 100\n",
    "learning_rate = 1e-2\n",
    "learning_rates = learning_rate * lr_exp_decay(\n",
    "    range(1, n_epochs + 1), decay_epoch=50, period=10\n",
    ")\n",
    "learning_rates_beta = learning_rate * lr_exp_decay(\n",
    "    range(1, n_epochs + 1), decay_epoch=50, period=20\n",
    ")\n",
    "mini_batch_size = 10\n",
    "s_freeze = 1.0\n",
    "s_quench = 0.55\n",
    "relative_chain_strength = 2.0\n",
    "\n",
    "# anneal schedule\n",
    "t_r = 20\n",
    "\u03b1_quench = 2\n",
    "t_quench = round(s_quench * t_r, 3)\n",
    "\u0394_quench = round((1 - s_quench) / \u03b1_quench, 3)\n",
    "if s_quench == 1:\n",
    "    anneal_schedule = [(0, 0), (t_quench, s_quench)]\n",
    "else:\n",
    "    anneal_schedule = [\n",
    "        (0, 0),\n",
    "        (t_quench, s_quench),\n",
    "        (round(t_quench + \u0394_quench, 3), 1),\n",
    "    ]\n",
    "anneal_params = {\n",
    "    \"s\": s_freeze,\n",
    "    \"A\": df_anneal.loc[s_freeze, \"A(s) (GHz)\"],\n",
    "    \"B\": df_anneal.loc[s_freeze, \"B(s) (GHz)\"],\n",
    "    \"schedule\": anneal_schedule,\n",
    "}\n",
    "\n",
    "# set model name and path\n",
    "model_name = f\"model-final\"\n",
    "model_path = models_dir / f\"embedding_{embedding_id:02}/{model_name}.pkl\"\n",
    "if train_model:\n",
    "    # model train and save\n",
    "    model = BQRBM(\n",
    "        X_train=X_train,\n",
    "        n_hidden=model_params[\"n_hidden\"],\n",
    "        embedding=embeddings[embedding_id],\n",
    "        anneal_params=anneal_params,\n",
    "        beta_initial=beta_initial,\n",
    "        beta_range=beta_range,\n",
    "        qpu_params=qpu_params,\n",
    "    )\n",
    "    model.train(\n",
    "        n_epochs=n_epochs,\n",
    "        learning_rate=learning_rates,\n",
    "        learning_rate_beta=learning_rates_beta,\n",
    "        mini_batch_size=mini_batch_size,\n",
    "        callback=callback,\n",
    "    )\n",
    "    model.save(model_path)\n",
    "\n",
    "    # save attributes as dict in case of error loading old pickled object\n",
    "    model_attributes = {\n",
    "        \"A\": model.A,\n",
    "        \"B\": model.B,\n",
    "        \"a\": model.a,\n",
    "        \"b\": model.b,\n",
    "        \"W\": model.W,\n",
    "        \"beta\": model.beta,\n",
    "        \"embedding\": model.embedding,\n",
    "        \"qpu_params\": model.qpu_params,\n",
    "        \"anneal_params\": model.anneal_params,\n",
    "        \"exact_params\": model.exact_params,\n",
    "        \"beta_history\": model.beta_history,\n",
    "        \"callback_outputs\": [x for x in model.callback_outputs],\n",
    "    }\n",
    "    save_artifact(\n",
    "        model_attributes, Path(str(model_path).replace(\"model-\", \"model_attributes-\")),\n",
    "    )\n",
    "else:\n",
    "    model_final = BQRBM.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c04f2aff-db85-48e0-85ac-f4b82f97537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.72 s (started: 2022-03-23 23:34:58 +01:00)\n"
     ]
    }
   ],
   "source": [
    "embedding_id = 1\n",
    "model_name = f\"model-final\"\n",
    "model_path = models_dir / f\"embedding_{embedding_id:02}/{model_name}.pkl\"\n",
    "model_final = BQRBM.load(model_path)\n",
    "\n",
    "dkls_final = {}\n",
    "ccs_final = {}\n",
    "beta_final = {}\n",
    "dkls_final[embedding_id] = [\n",
    "    x[\"value\"][\"dkls\"].mean().mean() for x in model_final.callback_outputs\n",
    "]\n",
    "ccs_final[embedding_id] = [\n",
    "    x[\"value\"][\"ccs\"].abs().mean().mean() for x in model_final.callback_outputs\n",
    "]\n",
    "beta_final[embedding_id] = model_final.beta_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67b6f936-10e0-4bba-9805-097c20a870f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 635 ms (started: 2022-03-23 23:35:00 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def smooth(x, k=1):\n",
    "    x_out = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        x_out[i] = np.mean(x[i - min((k - 1, i)) : i + 1])\n",
    "    return x_out\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "markers = [\"o\", \"^\", \"v\", \"<\", \">\", \"s\", \"p\", \"*\", \"P\", \"X\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "for i, (embedding_id, dkl) in enumerate(dkls_final.items()):\n",
    "    ax[0].plot(\n",
    "        range(1, len(dkl) + 1),\n",
    "        smooth(dkl),\n",
    "        label=f\"BQRBM Advantage 4.1\",\n",
    "        color=colors[i],\n",
    "        linewidth=1.8,\n",
    "    )\n",
    "for i, (embedding_id, betas) in enumerate(beta_final.items()):\n",
    "    ax[1].plot(\n",
    "        range(len(betas)),\n",
    "        smooth(1 / k_B / np.array(betas) * 1000),\n",
    "        color=colors[i],\n",
    "        linewidth=1.8,\n",
    "    )\n",
    "ax[0].axhline(\n",
    "    0.01,\n",
    "    color=\"tab:gray\",\n",
    "    linewidth=2.5,\n",
    "    linestyle=\"dotted\",\n",
    "    label=\"RBM (Final Result)\",\n",
    ")\n",
    "# fig.suptitle(\"Embedding 1, $s_{quench}$ = 0.55, RCS = 2\")\n",
    "ax[0].set_ylabel(r\"Mean Marginal $D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax[1].set_ylabel(r\"$\\hat{T}$ [mK]\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[0].set_xticks(np.arange(0, 105, 20))\n",
    "ax[1].set_xticks(np.arange(0, 105, 20))\n",
    "ax[1].set_yticks(np.arange(140, 210, 10))\n",
    "ax[0].set_ylim((0, 0.30))\n",
    "ax[0].grid(alpha=0.7)\n",
    "ax[1].grid(alpha=0.7)\n",
    "ax[0].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"full_run.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "342986bd-1319-4579-b731-ef938cf8304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19196972293464884"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.11 ms (started: 2022-03-23 23:35:01 +01:00)\n"
     ]
    }
   ],
   "source": [
    "1 / 0.25 / k_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ea053-6c9a-4668-a6d2-ff1a5f933333",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d1c87dc-2e2f-4e57-a57e-c9cc5a083f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 54.7 s (started: 2022-03-23 23:35:01 +01:00)\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 100\n",
    "samples_ensemble = {}\n",
    "for i in range(1, ensemble_size + 1):\n",
    "    samples_path = samples_dir / f\"model-final/{i:02}.pkl\"\n",
    "    if samples_path.exists():\n",
    "        samples_ensemble[i] = load_artifact(samples_path)\n",
    "    else:\n",
    "        samples_ensemble[i] = model_final.sample(n_samples=10_000, binary=True)\n",
    "        save_artifact(samples_ensemble[i], samples_path)\n",
    "\n",
    "for i, samples in samples_ensemble.items():\n",
    "    samples_ensemble[i] = convert_state_vectors_to_df(\n",
    "        samples.record.sample[:, : model_final.n_visible]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e8a13-9292-4f60-a373-2a15294f1e28",
   "metadata": {},
   "source": [
    "### KL Divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a84aeddb-4123-48a4-b12b-c80c9858e5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.19 ms (started: 2022-03-23 23:35:55 +01:00)\n"
     ]
    }
   ],
   "source": [
    "rbm_artifacts_path = project_dir / \"artifacts/BernoulliRBM_20211115_111609\"\n",
    "rbm_data_path = rbm_artifacts_path / \"results/data\"\n",
    "tables_dir = project_dir / \"latex/tables/qbm\"\n",
    "if not tables_dir.exists():\n",
    "    tables_dir.mkdir(parents=True)\n",
    "\n",
    "\n",
    "def str_map(x, digits=2, factor=1):\n",
    "    return f\"{x * factor:0.{digits}f}\"\n",
    "\n",
    "\n",
    "def save_table(table, file_name):\n",
    "    with open(tables_dir / file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(table + \"\\n\")\n",
    "\n",
    "\n",
    "def textbf(x):\n",
    "    return \"\\\\textbf{%s}\" % x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c83152-96d5-41da-a5be-bbc0a79426d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bqrbm_means</th>\n",
       "      <th>bqrbm_medians</th>\n",
       "      <th>bqrbm_stds</th>\n",
       "      <th>rbm_means</th>\n",
       "      <th>rbm_medians</th>\n",
       "      <th>rbm_stds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_pair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EURUSD</th>\n",
       "      <td>0.086</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPUSD</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCAD</th>\n",
       "      <td>0.064</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDJPY</th>\n",
       "      <td>0.103</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bqrbm_means bqrbm_medians bqrbm_stds rbm_means rbm_medians  \\\n",
       "currency_pair                                                              \n",
       "EURUSD              0.086         0.075      0.044     0.010       0.009   \n",
       "GBPUSD              0.062         0.051      0.037     0.007       0.007   \n",
       "USDCAD              0.064         0.059      0.028     0.017       0.017   \n",
       "USDJPY              0.103         0.095      0.037     0.008       0.008   \n",
       "Mean                0.079         0.070      0.037     0.010       0.010   \n",
       "\n",
       "              rbm_stds  \n",
       "currency_pair           \n",
       "EURUSD           0.001  \n",
       "GBPUSD           0.001  \n",
       "USDCAD           0.002  \n",
       "USDJPY           0.001  \n",
       "Mean             0.001  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 338 ms (started: 2022-03-23 23:35:55 +01:00)\n"
     ]
    }
   ],
   "source": [
    "dkls_ensemble = []\n",
    "for i, df_sample in samples_ensemble.items():\n",
    "    dkls = {\n",
    "        column: kl_divergence(\n",
    "            log_returns[column], df_sample[column], n_bins=32, smooth=1e-6\n",
    "        )\n",
    "        for column in log_returns.columns\n",
    "    }\n",
    "    dkls = pd.DataFrame.from_dict(dkls, orient=\"index\", columns=[\"D_KL\"])\n",
    "    dkls_ensemble.append(dkls)\n",
    "dkls_bqrbm = compute_stats_over_dfs(dkls_ensemble)\n",
    "dkls_rbm = pd.read_csv(rbm_data_path / \"kl_divergences.csv\", index_col=\"currency_pair\")\n",
    "dkls = pd.DataFrame(\n",
    "    {\n",
    "        \"bqrbm_means\": dkls_bqrbm[\"means\"].to_numpy().flatten(),\n",
    "        \"bqrbm_medians\": dkls_bqrbm[\"medians\"].to_numpy().flatten(),\n",
    "        \"bqrbm_stds\": dkls_bqrbm[\"stds\"].to_numpy().flatten(),\n",
    "        \"rbm_means\": dkls_rbm[\"means\"].to_numpy().flatten(),\n",
    "        \"rbm_medians\": dkls_rbm[\"medians\"].to_numpy().flatten(),\n",
    "        \"rbm_stds\": dkls_rbm[\"stds\"].to_numpy().flatten(),\n",
    "    },\n",
    "    index=dkls_bqrbm[\"means\"].index,\n",
    ")\n",
    "dkls.index.set_names(\"currency_pair\", inplace=True)\n",
    "dkls.loc[\"Mean\"] = dkls.mean()\n",
    "dkls.loc[\"Mean\", \"bqrbm_stds\"] = np.sqrt(\n",
    "    np.sum(dkls_bqrbm[\"stds\"][\"D_KL\"] ** 2) / (len(dkls_bqrbm[\"stds\"][\"D_KL\"]))\n",
    ")\n",
    "dkls.loc[\"Mean\", \"rbm_stds\"] = np.sqrt(\n",
    "    np.sum(dkls_rbm[\"stds\"] ** 2) / (len(dkls_rbm[\"stds\"]))\n",
    ")\n",
    "dkls = dkls.applymap(str_map, digits=3)\n",
    "dkls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb8d2afe-9cf9-4879-9b5d-be6863e10fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.38 ms (started: 2022-03-23 23:35:56 +01:00)\n"
     ]
    }
   ],
   "source": [
    "prefixes = [\"bqrbm\", \"rbm\"]\n",
    "table = [\n",
    "    r\"\\begin{tabular}{l r r}\",\n",
    "    r\"\\multicolumn{3}{c}{\\(D_{\\text{KL}}(p_\\text{data} \\ || \\ p_\\text{model})\\)} \\\\\",\n",
    "    r\"\\toprule\",\n",
    "    r\"Currency Pair & \\textbf{BQRBM} & \\textbf{RBM}\\\\\",\n",
    "    r\"\\midrule\",\n",
    "]\n",
    "for i, pair in enumerate(dkls.index):\n",
    "    data = dkls.loc[pair]\n",
    "    row = [pair]\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        \u03bc = data[f\"{prefix}_means\"]\n",
    "        \u03c3 = data[f\"{prefix}_stds\"]\n",
    "        row.append(fr\"{\u03bc} $\\pm$ {\u03c3}\")\n",
    "\n",
    "    row = \" & \".join(row)\n",
    "    row += r\" \\\\\"\n",
    "    if i == len(dkls) - 1:\n",
    "        table.append(r\"\\midrule\")\n",
    "\n",
    "    table.append(row)\n",
    "\n",
    "table.append(r\"\\bottomrule\")\n",
    "table.append(r\"\\end{tabular}\")\n",
    "table = \"\\n\".join(table)\n",
    "save_table(table, \"kl_divergences.tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b74696-66fd-4a66-9a79-bfdcad0ead57",
   "metadata": {},
   "source": [
    "### QQ Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa1d0cc-8cdf-49fa-8cb4-0fe80ad6fb94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x3600 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.07 s (started: 2022-03-23 23:35:56 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def plot_qq_grid(data, sample, params):\n",
    "    \"\"\"\n",
    "    Plots a 2x2 grid of QQ plots.\n",
    "\n",
    "    :param data: A dataframe of shape (n_sample, 4).\n",
    "    :param sample: A dataframe with matching column names to the data and the same shape.\n",
    "    :param params: Additional parameter dictionary for ax configuration, required keys are\n",
    "        [\"xlims\", \"ylims\", \"xticks\", \"yticks\"].\n",
    "\n",
    "    :returns: Matplotlib figure and axes.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(9, 9), dpi=300, tight_layout=True)\n",
    "    for column, ax in zip(data.columns, axs.flatten()):\n",
    "        plot_qq(ax, data[column], sample[column], column, params)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "\n",
    "qq_plot_params = {\n",
    "    \"title\": \"test\",\n",
    "    \"xlims\": (-0.045, 0.045),\n",
    "    \"ylims\": (-0.045, 0.045),\n",
    "    \"xticks\": np.linspace(-0.04, 0.04, 5),\n",
    "    \"yticks\": np.linspace(-0.04, 0.04, 5),\n",
    "}\n",
    "fig, axs = plt.subplots(4, 2, figsize=(6, 12), dpi=300)\n",
    "matplotlib.rcParams.update({\"font.size\": 12})\n",
    "samples_bqrbm_ = samples_ensemble[1]\n",
    "samples_rbm_ = load_artifact(rbm_artifacts_path / f\"samples_ensemble/{1:03}.pkl\")\n",
    "samples_qq = [samples_bqrbm_, samples_rbm_]\n",
    "for j, samples_ in enumerate(samples_qq):\n",
    "    if j == 0:\n",
    "        title = \"BQRBM\"\n",
    "    else:\n",
    "        title = \"RBM\"\n",
    "    for i, column in enumerate(log_returns.columns):\n",
    "        if i == 0:\n",
    "            title += f\"\\n{column}\"\n",
    "        else:\n",
    "            title = column\n",
    "        plot_qq(\n",
    "            axs[i, j],\n",
    "            log_returns[column],\n",
    "            samples_[column][: len(log_returns[column])],\n",
    "            title,\n",
    "            qq_plot_params,\n",
    "        )\n",
    "        axs[i, j].ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0, 0))\n",
    "        axs[i, j].ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"qq.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6933dc-a86b-4c1a-909f-6f749c601348",
   "metadata": {},
   "source": [
    "### Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee386fdd-5017-4941-80e0-c17c9717b265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bqrbm_Pearson_mean</th>\n",
       "      <th>bqrbm_Spearman_mean</th>\n",
       "      <th>bqrbm_Kendall_mean</th>\n",
       "      <th>bqrbm_Pearson_std</th>\n",
       "      <th>bqrbm_Spearman_std</th>\n",
       "      <th>bqrbm_Kendall_std</th>\n",
       "      <th>Data_Pearson</th>\n",
       "      <th>Data_Spearman</th>\n",
       "      <th>Data_Kendall</th>\n",
       "      <th>rbm_Pearson_mean</th>\n",
       "      <th>rbm_Spearman_mean</th>\n",
       "      <th>rbm_Kendall_mean</th>\n",
       "      <th>rbm_Pearson_std</th>\n",
       "      <th>rbm_Spearman_std</th>\n",
       "      <th>rbm_Kendall_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_pairs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EURUSD/GBPUSD</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURUSD/USDCAD</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURUSD/USDJPY</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPUSD/USDCAD</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPUSD/USDJPY</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCAD/USDJPY</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bqrbm_Pearson_mean bqrbm_Spearman_mean bqrbm_Kendall_mean  \\\n",
       "currency_pairs                                                             \n",
       "EURUSD/GBPUSD                0.37                0.44               0.30   \n",
       "EURUSD/USDCAD               -0.25               -0.30              -0.20   \n",
       "EURUSD/USDJPY               -0.12               -0.16              -0.11   \n",
       "GBPUSD/USDCAD               -0.24               -0.28              -0.19   \n",
       "GBPUSD/USDJPY               -0.12               -0.15              -0.10   \n",
       "USDCAD/USDJPY                0.05                0.06               0.04   \n",
       "\n",
       "               bqrbm_Pearson_std bqrbm_Spearman_std bqrbm_Kendall_std  \\\n",
       "currency_pairs                                                          \n",
       "EURUSD/GBPUSD               0.04               0.05              0.04   \n",
       "EURUSD/USDCAD               0.03               0.04              0.03   \n",
       "EURUSD/USDJPY               0.03               0.04              0.02   \n",
       "GBPUSD/USDCAD               0.02               0.03              0.02   \n",
       "GBPUSD/USDJPY               0.02               0.03              0.02   \n",
       "USDCAD/USDJPY               0.02               0.02              0.01   \n",
       "\n",
       "               Data_Pearson Data_Spearman Data_Kendall rbm_Pearson_mean  \\\n",
       "currency_pairs                                                            \n",
       "EURUSD/GBPUSD          0.62          0.62         0.44             0.48   \n",
       "EURUSD/USDCAD         -0.44         -0.41        -0.29            -0.33   \n",
       "EURUSD/USDJPY         -0.26         -0.30        -0.21            -0.21   \n",
       "GBPUSD/USDCAD         -0.42         -0.37        -0.26            -0.31   \n",
       "GBPUSD/USDJPY         -0.14         -0.21        -0.15            -0.15   \n",
       "USDCAD/USDJPY          0.00          0.06         0.04             0.06   \n",
       "\n",
       "               rbm_Spearman_mean rbm_Kendall_mean rbm_Pearson_std  \\\n",
       "currency_pairs                                                      \n",
       "EURUSD/GBPUSD               0.53             0.38            0.01   \n",
       "EURUSD/USDCAD              -0.34            -0.24            0.01   \n",
       "EURUSD/USDJPY              -0.25            -0.17            0.01   \n",
       "GBPUSD/USDCAD              -0.33            -0.22            0.01   \n",
       "GBPUSD/USDJPY              -0.18            -0.13            0.01   \n",
       "USDCAD/USDJPY               0.07             0.05            0.01   \n",
       "\n",
       "               rbm_Spearman_std rbm_Kendall_std  \n",
       "currency_pairs                                   \n",
       "EURUSD/GBPUSD              0.01            0.01  \n",
       "EURUSD/USDCAD              0.01            0.01  \n",
       "EURUSD/USDJPY              0.01            0.01  \n",
       "GBPUSD/USDCAD              0.01            0.01  \n",
       "GBPUSD/USDJPY              0.01            0.01  \n",
       "USDCAD/USDJPY              0.01            0.01  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.37 s (started: 2022-03-23 23:35:58 +01:00)\n"
     ]
    }
   ],
   "source": [
    "ccs_ensemble = []\n",
    "combinations = list(itertools.combinations(model_params[\"columns\"], 2))\n",
    "for i, df_sample in samples_ensemble.items():\n",
    "    ccs_ensemble.append(compute_correlation_coefficients(df_sample, combinations))\n",
    "ccs_bqrbm = compute_stats_over_dfs(ccs_ensemble)\n",
    "ccs_bqrbm[\"means\"].index.set_names(\"currency_pairs\", inplace=True)\n",
    "ccs_bqrbm[\"medians\"].index.set_names(\"currency_pairs\", inplace=True)\n",
    "ccs_bqrbm[\"stds\"].index.set_names(\"currency_pairs\", inplace=True)\n",
    "ccs_bqrbm[\"means\"].rename(lambda x: f\"bqrbm_{x}_mean\", axis=1, inplace=True)\n",
    "ccs_bqrbm[\"stds\"].rename(lambda x: f\"bqrbm_{x}_std\", axis=1, inplace=True)\n",
    "\n",
    "ccs_data = pd.read_csv(\n",
    "    rbm_data_path / \"correlation_coefficients_data.csv\", index_col=\"currency_pairs\"\n",
    ")\n",
    "ccs_rbm_means = pd.read_csv(\n",
    "    rbm_data_path / \"correlation_coefficients_sample_means.csv\",\n",
    "    index_col=\"currency_pairs\",\n",
    ")\n",
    "ccs_rbm_stds = pd.read_csv(\n",
    "    rbm_data_path / \"correlation_coefficients_sample_stds.csv\",\n",
    "    index_col=\"currency_pairs\",\n",
    ")\n",
    "ccs_data.rename(lambda x: f\"Data_{x}\", axis=1, inplace=True)\n",
    "ccs_rbm_means.rename(lambda x: f\"rbm_{x}_mean\", axis=1, inplace=True)\n",
    "ccs_rbm_stds.rename(lambda x: f\"rbm_{x}_std\", axis=1, inplace=True)\n",
    "\n",
    "ccs = pd.concat(\n",
    "    [ccs_bqrbm[\"means\"], ccs_bqrbm[\"stds\"], ccs_data, ccs_rbm_means, ccs_rbm_stds],\n",
    "    axis=1,\n",
    ")\n",
    "ccs = ccs.applymap(str_map, digits=2)\n",
    "ccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "204e7108-4183-43c6-a58e-6ec3d0a8b2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.43 ms (started: 2022-03-23 23:36:00 +01:00)\n"
     ]
    }
   ],
   "source": [
    "prefixes = (\"bqrbm\",)\n",
    "cc_names = (\"Pearson\", \"Spearman\", \"Kendall\")\n",
    "table = [\n",
    "    r\"\\begin{tabular}{l r r r r r r}\"\n",
    "    r\"\\multicolumn{7}{c}{\\textbf{Correlation Coefficients}} \\\\\",\n",
    "    r\"\\toprule\",\n",
    "    r\"& \\multicolumn{3}{c}{\\textbf{Data}} & \\multicolumn{3}{c}{\\textbf{BQRBM}} \\\\\"\n",
    "    r\"\\cmidrule(lr){2-4}\",\n",
    "    r\"\\cmidrule(lr){5-7}\",\n",
    "    r\"Currency Pairs & %s & %s & %s & %s & %s & %s \\\\\" % (cc_names + cc_names),\n",
    "    r\"\\midrule\",\n",
    "]\n",
    "data_columns = [f\"Data_{cc_name}\" for cc_name in cc_names]\n",
    "for pair in ccs.index:\n",
    "    data = ccs.loc[pair]\n",
    "    row = [pair]\n",
    "    row += [data[column] for column in data_columns]\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        for cc_name in cc_names:\n",
    "            \u03bc = data[f\"{prefix}_{cc_name}_mean\"]\n",
    "            \u03c3 = data[f\"{prefix}_{cc_name}_std\"]\n",
    "            row.append(fr\"{\u03bc} $\\pm$ {\u03c3}\")\n",
    "\n",
    "    row = \" & \".join(row)\n",
    "    row += r\" \\\\\"\n",
    "    table.append(row)\n",
    "\n",
    "prefixes = (\"rbm\",)\n",
    "cc_names = (\"Pearson\", \"Spearman\", \"Kendall\")\n",
    "table += [\n",
    "    r\"\\midrule\",\n",
    "    r\"& \\multicolumn{3}{c}{\\textbf{RBM}} & \\\\\" r\"\\cmidrule(lr){2-4}\",\n",
    "    r\"Currency Pairs & %s & %s & %s & & & \\\\\" % cc_names,\n",
    "    r\"\\midrule\",\n",
    "]\n",
    "for pair in ccs.index:\n",
    "    data = ccs.loc[pair]\n",
    "    row = [pair]\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        for cc_name in cc_names:\n",
    "            \u03bc = data[f\"{prefix}_{cc_name}_mean\"]\n",
    "            \u03c3 = data[f\"{prefix}_{cc_name}_std\"]\n",
    "            row.append(fr\"{\u03bc} $\\pm$ {\u03c3}\")\n",
    "\n",
    "    for cc_name in cc_names:\n",
    "        row.append(\"\")\n",
    "\n",
    "    row = \" & \".join(row)\n",
    "    row += r\" \\\\\"\n",
    "    table.append(row)\n",
    "\n",
    "table.append(r\"\\bottomrule\")\n",
    "table.append(r\"\\end{tabular}\")\n",
    "table = \"\\n\".join(table)\n",
    "save_table(table, \"correlation_coefficients.tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42bb3d4-be32-4959-b115-1f0c75b9fac5",
   "metadata": {},
   "source": [
    "### Volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c2e3b51-4477-4595-9fb9-f30f4fd51c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>rbm_sample_mean</th>\n",
       "      <th>rbm_sample_std</th>\n",
       "      <th>bqrbm_sample_mean</th>\n",
       "      <th>bqrbm_sample_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_pair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EURUSD</th>\n",
       "      <td>9.78</td>\n",
       "      <td>9.98</td>\n",
       "      <td>0.11</td>\n",
       "      <td>10.17</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPUSD</th>\n",
       "      <td>8.98</td>\n",
       "      <td>9.34</td>\n",
       "      <td>0.11</td>\n",
       "      <td>8.86</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCAD</th>\n",
       "      <td>8.56</td>\n",
       "      <td>8.98</td>\n",
       "      <td>0.13</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDJPY</th>\n",
       "      <td>10.02</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0.13</td>\n",
       "      <td>11.58</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Data rbm_sample_mean rbm_sample_std bqrbm_sample_mean  \\\n",
       "currency_pair                                                           \n",
       "EURUSD          9.78            9.98           0.11             10.17   \n",
       "GBPUSD          8.98            9.34           0.11              8.86   \n",
       "USDCAD          8.56            8.98           0.13              8.44   \n",
       "USDJPY         10.02           10.26           0.13             11.58   \n",
       "\n",
       "              bqrbm_sample_std  \n",
       "currency_pair                   \n",
       "EURUSD                    0.79  \n",
       "GBPUSD                    0.47  \n",
       "USDCAD                    0.39  \n",
       "USDJPY                    1.44  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62.4 ms (started: 2022-03-23 23:36:00 +01:00)\n"
     ]
    }
   ],
   "source": [
    "volatilities = pd.read_csv(\n",
    "    rbm_data_path / \"volatilities.csv\", index_col=\"currency_pair\"\n",
    ")\n",
    "volatilities.rename(\n",
    "    columns={\"Sample Mean\": \"rbm_sample_mean\", \"Sample Std\": \"rbm_sample_std\"},\n",
    "    inplace=True,\n",
    ")\n",
    "volatilities_bqrbm = compute_stats_over_dfs(\n",
    "    [compute_annualized_volatility(samples) for samples in samples_ensemble.values()]\n",
    ")\n",
    "volatilities[\"bqrbm_sample_mean\"] = volatilities_bqrbm[\"means\"]\n",
    "volatilities[\"bqrbm_sample_std\"] = volatilities_bqrbm[\"stds\"]\n",
    "volatilities = volatilities.applymap(str_map, digits=2, factor=100)\n",
    "volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec196112-af99-4090-be64-2cf433cb5843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.26 ms (started: 2022-03-23 23:36:00 +01:00)\n"
     ]
    }
   ],
   "source": [
    "prefixes = (\"bqrbm\", \"rbm\")\n",
    "table = [\n",
    "    r\"\\begin{tabular}{l r r r}\",\n",
    "    r\"\\multicolumn{4}{c}{\\textbf{Historical Volatilities}} \\\\\",\n",
    "    r\"\\toprule\",\n",
    "    r\"Currency Pair & \\textbf{Data} & \\textbf{BQRBM} & \\textbf{RBM}\\\\\" r\"\\midrule\",\n",
    "]\n",
    "for pair in volatilities.index:\n",
    "    data = volatilities.loc[pair]\n",
    "    row = [pair, fr\"{data['Data']}\\%\"]\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        \u03bc = data[f\"{prefix}_sample_mean\"]\n",
    "        \u03c3 = data[f\"{prefix}_sample_std\"]\n",
    "        row.append(fr\"{\u03bc}\\% $\\pm$ {\u03c3}\\%\")\n",
    "\n",
    "    row = \" & \".join(row)\n",
    "    row += r\" \\\\\"\n",
    "    table.append(row)\n",
    "\n",
    "table.append(r\"\\bottomrule\")\n",
    "table.append(r\"\\end{tabular}\")\n",
    "table = \"\\n\".join(table)\n",
    "save_table(table, \"volatilities.tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d3d54-204c-44b3-94f8-d5367cc89898",
   "metadata": {},
   "source": [
    "### Tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd76911-50dd-4fc2-adb0-bd2813cda8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bqrbm_quantile_01_mean</th>\n",
       "      <th>bqrbm_quantile_99_mean</th>\n",
       "      <th>bqrbm_quantile_01_std</th>\n",
       "      <th>bqrbm_quantile_99_std</th>\n",
       "      <th>Data_quantile_01</th>\n",
       "      <th>Data_quantile_99</th>\n",
       "      <th>rbm_quantile_01_mean</th>\n",
       "      <th>rbm_quantile_99_mean</th>\n",
       "      <th>rbm_quantile_01_std</th>\n",
       "      <th>rbm_quantile_99_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_pair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EURUSD</th>\n",
       "      <td>-2.02</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBPUSD</th>\n",
       "      <td>-1.45</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>1.42</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDCAD</th>\n",
       "      <td>-1.43</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USDJPY</th>\n",
       "      <td>-2.32</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bqrbm_quantile_01_mean bqrbm_quantile_99_mean  \\\n",
       "currency_pair                                                 \n",
       "EURUSD                         -2.02                   1.70   \n",
       "GBPUSD                         -1.45                   1.49   \n",
       "USDCAD                         -1.43                   1.50   \n",
       "USDJPY                         -2.32                   2.13   \n",
       "\n",
       "              bqrbm_quantile_01_std bqrbm_quantile_99_std Data_quantile_01  \\\n",
       "currency_pair                                                                \n",
       "EURUSD                         0.24                  0.23            -1.64   \n",
       "GBPUSD                         0.12                  0.07            -1.47   \n",
       "USDCAD                         0.17                  0.12            -1.40   \n",
       "USDJPY                         0.38                  0.50            -1.70   \n",
       "\n",
       "              Data_quantile_99 rbm_quantile_01_mean rbm_quantile_99_mean  \\\n",
       "currency_pair                                                              \n",
       "EURUSD                    1.62                -1.80                 1.59   \n",
       "GBPUSD                    1.42                -1.59                 1.45   \n",
       "USDCAD                    1.51                -1.54                 1.61   \n",
       "USDJPY                    1.59                -2.03                 1.56   \n",
       "\n",
       "              rbm_quantile_01_std rbm_quantile_99_std  \n",
       "currency_pair                                          \n",
       "EURUSD                       0.04                0.04  \n",
       "GBPUSD                       0.04                0.04  \n",
       "USDCAD                       0.05                0.04  \n",
       "USDJPY                       0.07                0.04  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 218 ms (started: 2022-03-23 23:36:00 +01:00)\n"
     ]
    }
   ],
   "source": [
    "quantiles_bqrbm = []\n",
    "for samples in samples_ensemble.values():\n",
    "    quantiles_bqrbm.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"quantile_01\": samples.quantile(0.01),\n",
    "                \"quantile_99\": samples.quantile(0.99),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "tails_bqrbm = compute_stats_over_dfs(quantiles_bqrbm)\n",
    "tails_bqrbm_means = tails_bqrbm[\"means\"]\n",
    "tails_bqrbm_stds = tails_bqrbm[\"stds\"]\n",
    "tails_bqrbm_means.index.set_names(\"currency_pair\", inplace=True)\n",
    "tails_bqrbm_stds.index.set_names(\"currency_pair\", inplace=True)\n",
    "tails_bqrbm_means.rename(lambda x: f\"bqrbm_{x}_mean\", axis=1, inplace=True)\n",
    "tails_bqrbm_stds.rename(lambda x: f\"bqrbm_{x}_std\", axis=1, inplace=True)\n",
    "\n",
    "tails_data = pd.read_csv(rbm_data_path / \"tails_data.csv\", index_col=\"currency_pair\")\n",
    "tails_rbm_means = pd.read_csv(\n",
    "    rbm_data_path / \"tails_sample_means.csv\", index_col=\"currency_pair\"\n",
    ")\n",
    "tails_rbm_stds = pd.read_csv(\n",
    "    rbm_data_path / \"tails_sample_stds.csv\", index_col=\"currency_pair\"\n",
    ")\n",
    "tails_data.rename(lambda x: f\"Data_{x}\", axis=1, inplace=True)\n",
    "tails_rbm_means.rename(lambda x: f\"rbm_{x}_mean\", axis=1, inplace=True)\n",
    "tails_rbm_stds.rename(lambda x: f\"rbm_{x}_std\", axis=1, inplace=True)\n",
    "\n",
    "tails = pd.concat(\n",
    "    [tails_bqrbm_means, tails_bqrbm_stds, tails_data, tails_rbm_means, tails_rbm_stds],\n",
    "    axis=1,\n",
    ")\n",
    "tails = tails.applymap(str_map, digits=2, factor=100)\n",
    "tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55a520f7-5dda-4065-96d1-585562aebb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.02 ms (started: 2022-03-23 23:36:01 +01:00)\n"
     ]
    }
   ],
   "source": [
    "prefixes = (\"bqrbm\", \"rbm\")\n",
    "table = [\n",
    "    r\"\\begin{tabular}{l r r r}\",\n",
    "    r\"\\multicolumn{4}{c}{\\textbf{Lower Tails (1st Percentile)}} \\\\\",\n",
    "    r\"\\toprule\",\n",
    "    r\"Currency Pair & \\textbf{Data} & \\textbf{BQRBM} & \\textbf{RBM} \\\\\" r\"\\midrule\",\n",
    "]\n",
    "\n",
    "columns_low = [column for column in tails.columns if \"quantile_01\" in column]\n",
    "for pair in tails.index:\n",
    "    data = tails.loc[pair]\n",
    "    row = [pair, fr\"{data['Data_quantile_01']}\\%\"]\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        \u03bc = data[f\"{prefix}_quantile_01_mean\"]\n",
    "        \u03c3 = data[f\"{prefix}_quantile_01_std\"]\n",
    "        row.append(fr\"{\u03bc}\\% $\\pm$ {\u03c3}\\%\")\n",
    "\n",
    "    row = \" & \".join(row)\n",
    "    row += r\" \\\\\"\n",
    "    table.append(row)\n",
    "\n",
    "table += [\n",
    "    r\"\\bottomrule \\\\\",\n",
    "    r\"\\multicolumn{4}{c}{\\textbf{Upper Tails (99th Percentile)}} \\\\\",\n",
    "    r\"\\toprule\",\n",
    "    r\"Currency Pair & \\textbf{Data} & \\textbf{BQRBM} & \\textbf{RBM} \\\\\" r\"\\midrule\",\n",
    "]\n",
    "\n",
    "columns_high = [column for column in tails.columns if \"quantile_99\" in column]\n",
    "for pair in tails.index:\n",
    "    data = tails.loc[pair]\n",
    "    row = [pair, fr\"{data['Data_quantile_99']}\\%\"]\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        \u03bc = data[f\"{prefix}_quantile_99_mean\"]\n",
    "        \u03c3 = data[f\"{prefix}_quantile_99_std\"]\n",
    "        row.append(fr\"{\u03bc}\\% $\\pm$ {\u03c3}\\%\")\n",
    "\n",
    "    row = \" & \".join(row)\n",
    "    row += r\" \\\\\"\n",
    "    table.append(row)\n",
    "\n",
    "table.append(r\"\\bottomrule\")\n",
    "table.append(r\"\\end{tabular}\")\n",
    "table = \"\\n\".join(table)\n",
    "save_table(table, \"tails.tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723828a6-f87a-4aa9-b419-3714f819713b",
   "metadata": {},
   "source": [
    "### Tail Concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19ec7d97-c2cd-4ad2-bb88-86be4b571f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x3300 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.15 s (started: 2022-03-23 23:36:01 +01:00)\n"
     ]
    }
   ],
   "source": [
    "tail_concentration_dfs = {}\n",
    "tail_concentration_dfs[\"Data\"] = log_returns\n",
    "tail_concentration_dfs[\"BQRBM\"] = samples_ensemble[1]\n",
    "tail_concentration_dfs[\"RBM\"] = load_artifact(\n",
    "    rbm_artifacts_path / f\"samples_ensemble/{1:03}.pkl\"\n",
    ")\n",
    "\n",
    "combinations = list(itertools.combinations(log_returns.columns, 2))\n",
    "colors = {\n",
    "    \"Data\": \"tab:cyan\",\n",
    "    \"BQRBM\": \"tab:red\",\n",
    "    \"RBM\": \"tab:blue\",\n",
    "}\n",
    "matplotlib.rcParams.update({\"font.size\": 14})\n",
    "fig, axs = plot_tail_concentrations_grid(tail_concentration_dfs, combinations, colors)\n",
    "plt.savefig(plots_dir / \"tail_concentrations.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}