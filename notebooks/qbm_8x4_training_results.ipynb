{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444cdef5-48f1-49a6-9b96-9b63a8ab2663",
   "metadata": {},
   "source": [
    "# QBM Comparison Exact vs. Annealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8e8b6a-56bd-4881-ab78-72322c441ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.82 s (started: 2022-02-23 14:23:23 +01:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neptune.new as neptune\n",
    "from numba import njit\n",
    "from scipy.constants import k as k_B, h as h_P\n",
    "\n",
    "k_B /= h_P * 1e9\n",
    "\n",
    "from qbm.models import BQRBM\n",
    "from qbm.plotting import plot_qq\n",
    "from qbm.utils import (\n",
    "    binarize_df,\n",
    "    convert_bin_list_to_str,\n",
    "    get_binarization_params,\n",
    "    get_project_dir,\n",
    "    get_rng,\n",
    "    kl_divergence,\n",
    "    load_artifact,\n",
    "    lr_exp_decay,\n",
    "    prepare_training_data,\n",
    "    save_artifact,\n",
    "    unbinarize_df,\n",
    "    compute_stats_over_dfs\n",
    ")\n",
    "from qbm.utils.exact_qbm import get_pauli_kron, compute_H, compute_rho\n",
    "\n",
    "# configure directories\n",
    "project_dir = get_project_dir()\n",
    "artifact_dir = project_dir / \"artifacts/qbm/8x4\"\n",
    "if not artifact_dir.exists():\n",
    "    artifact_dir.mkdir(parents=True)\n",
    "plot_dir = project_dir / \"results/plots/qbm/8x4\"\n",
    "if not plot_dir.exists():\n",
    "    plot_dir.mkdir(parents=True)\n",
    "    \n",
    "# load anneal schedule\n",
    "df_anneal = pd.read_csv(\n",
    "    project_dir\n",
    "    / \"data/anneal_schedules/csv/09-1265A-A_Advantage_system5_1_annealing_schedule.csv\",\n",
    "    index_col=\"s\",\n",
    ")\n",
    "if 0.5 not in df_anneal.index:\n",
    "    df_anneal.loc[0.5] = (df_anneal.loc[0.499] + df_anneal.loc[0.501]) / 2\n",
    "df_anneal.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fdfc1-7d3c-41f9-b789-d89c818172ec",
   "metadata": {},
   "source": [
    "## Train Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f998341-610b-4900-ae94-c8cca34ec7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.95 ms (started: 2022-02-23 14:23:25 +01:00)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "n_visible = 8\n",
    "n_hidden = 4\n",
    "n_qubits = n_visible + n_hidden\n",
    "\n",
    "rng = get_rng(seed)\n",
    "n_samples = 1500\n",
    "\u03b1 = 2 / 3\n",
    "N_1 = rng.normal(-2, 1, int(round(n_samples * \u03b1, 0)))\n",
    "N_2 = rng.normal(3, 1, int(round(n_samples * (1 - \u03b1), 0)))\n",
    "x = np.concatenate((N_1, N_2))\n",
    "\n",
    "df = pd.DataFrame.from_dict({\"x\": x})\n",
    "binarization_params = get_binarization_params(df, n_bits=n_visible)\n",
    "df_binarized = binarize_df(df, binarization_params)\n",
    "X_train = prepare_training_data(df_binarized)[\"X_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da319a69-0e5c-4b89-847f-3716253893b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36 ms (started: 2022-02-23 14:23:25 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def callback(model, sample_state_vectors):\n",
    "    X_train = model.X_train\n",
    "    n_visible = model.X_train.shape[1]\n",
    "    train_states = (\n",
    "        model._eigen_to_binary(model.X_train) * 2.0 ** np.arange(n_visible - 1, -1, -1)\n",
    "    ).sum(axis=1)\n",
    "    sample_states = (\n",
    "        model._eigen_to_binary(sample_state_vectors[:, :n_visible])\n",
    "        * 2.0 ** np.arange(n_visible - 1, -1, -1)\n",
    "    ).sum(axis=1)\n",
    "\n",
    "    dkl = kl_divergence(train_states, sample_states, n_bins=32)\n",
    "\n",
    "    return {\"value\": dkl, \"print\": f\"D_KL = {dkl:.3f}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6216f-7998-42b0-ae52-78323311fc8a",
   "metadata": {},
   "source": [
    "## Model Analysis (Exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bca6d-4486-4312-b849-1de7cefbd647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = 1.0\n",
    "train_model = False\n",
    "if train_model:\n",
    "    # model params\n",
    "    embedding = None\n",
    "    beta_initial = 1\n",
    "    exact_params = {\"beta\": 0.5}\n",
    "\n",
    "    # training params\n",
    "    n_epochs = 100\n",
    "    n_samples = 10_000\n",
    "    learning_rate = 0.1\n",
    "    mini_batch_size = 10\n",
    "    decay_epoch = 50\n",
    "    decay_period = 10\n",
    "    epochs = np.arange(1, n_epochs + 1)\n",
    "    learning_rates = learning_rate * lr_exp_decay(epochs, decay_epoch=50, period=10)\n",
    "    learning_rates_beta = learning_rate * lr_exp_decay(epochs, decay_epoch=50, period=20)\n",
    "\n",
    "    anneal_params = {\n",
    "        \"s\": s,\n",
    "        \"A\": df_anneal.loc[s, \"A(s) (GHz)\"],\n",
    "        \"B\": df_anneal.loc[s, \"B(s) (GHz)\"],\n",
    "    }\n",
    "    # model init\n",
    "    model_exact = BQRBM(\n",
    "        X_train=X_train,\n",
    "        n_hidden=n_hidden,\n",
    "        embedding=embedding,\n",
    "        anneal_params=anneal_params,\n",
    "        beta_initial=beta_initial,\n",
    "        exact_params=exact_params,\n",
    "    )\n",
    "\n",
    "    # model train and save\n",
    "    model_exact.train(\n",
    "        n_epochs=n_epochs,\n",
    "        n_samples=n_samples,\n",
    "        learning_rate=learning_rates,\n",
    "        learning_rate_beta=learning_rates_beta,\n",
    "        mini_batch_size=mini_batch_size,\n",
    "        callback=callback,\n",
    "    )\n",
    "    model_exact.save(artifact_dir / f\"models/model_exact-s={s}.pkl\")\n",
    "    model_exact_metrics = {\n",
    "        \"A\": model_exact.A,\n",
    "        \"B\": model_exact.B,\n",
    "        \"a\": model_exact.a,\n",
    "        \"b\": model_exact.b,\n",
    "        \"W\": model_exact.W,\n",
    "        \"beta\": model_exact.beta,\n",
    "        \"embedding\": model_exact.embedding,\n",
    "        \"anneal_params\": model_exact.anneal_params,\n",
    "        \"exact_params\": model_exact.exact_params,\n",
    "        \"beta_history\": model_exact.beta_history,\n",
    "        \"callback_outputs\": [x for x in model_exact.callback_outputs],\n",
    "    }\n",
    "    save_artifact(\n",
    "        model_exact_metrics, artifact_dir / f\"models/model_exact-s={s}-attributes.pkl\"\n",
    "    )\n",
    "else:\n",
    "    model_exact = BQRBM.load(artifact_dir / f\"models/model_exact-s={s}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f7245-ce18-4845-9c30-a53084a34472",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_exact = model_exact.sample(10_000, binary=True)\n",
    "state_vectors_exact = samples_exact[\"state_vectors\"][:, :n_visible]\n",
    "df_samples_exact = pd.DataFrame({\"x\": [convert_bin_list_to_str(x) for x in state_vectors_exact]})\n",
    "samples_exact = unbinarize_df(df_samples_exact, binarization_params)\n",
    "data = unbinarize_df(df_binarized, binarization_params)\n",
    "\n",
    "n_bins = 32\n",
    "fig, ax = plt.subplots(dpi=144, figsize=(10, 6))\n",
    "_, bins, _ = ax.hist(data, bins=n_bins, density=True, label=\"Data\")\n",
    "ax.hist(samples_exact, bins=bins, density=True, alpha=0.5, color=\"tab:orange\", label=\"Model (Simulation)\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"hist_comparison_exact.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd5188-6e44-4db1-ac02-a0fb27d1fd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dkls = [x[\"value\"] for x in model_exact.callback_outputs]\n",
    "epochs = np.arange(1, len(dkls) + 1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "ax[0].plot(epochs, dkls)\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(r\"$D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax[0].set_ylim((0, 0.2))\n",
    "ax[0].set_yticks(np.arange(0, 22.5, 2.5) / 100)\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].plot(range(len(model_exact.beta_history)), model_exact.beta_history)\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(r\"$\\hat{\\beta}$\")\n",
    "ax[1].axhline(0.5, color=\"k\", linestyle=\"--\", label=r\"$\\beta_{effective}$\")\n",
    "ax[1].grid()\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"train_results_exact.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c845feb-ab7e-48e2-800f-e04df4430e53",
   "metadata": {},
   "source": [
    "## Model Analysis (Annealer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d90469-70eb-4a60-88ca-a35f4e49058d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 05, s_pause = 0.50\n",
      "Embedding 05, s_pause = 0.55\n",
      "Embedding 05, s_pause = 0.60\n",
      "Embedding 05, s_pause = 0.90\n",
      "Embedding 05, s_pause = 0.95\n",
      "Embedding 05, s_pause = 1.00\n",
      "time: 41.9 ms (started: 2022-02-23 14:23:25 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# set the model params\n",
    "s = 1.0\n",
    "train_model = False\n",
    "embedding_ids = [5]\n",
    "s_pauses = [0.5, 0.55, 0.6, 0.9, 0.95, 1.0]\n",
    "\n",
    "# train the models\n",
    "models_annealer = {}\n",
    "for embedding_id in embedding_ids:\n",
    "    # load embedding\n",
    "    embedding = load_artifact(\n",
    "        project_dir / f\"artifacts/qbm/8x4/embeddings/embedding_{embedding_id:02}.json\"\n",
    "    )\n",
    "    embedding = {int(k): v for k, v in embedding.items()}\n",
    "\n",
    "    for s_pause in s_pauses:\n",
    "        print(f\"Embedding {embedding_id:02}, s_pause = {s_pause:.2f}\")\n",
    "        # set anneal schedule\n",
    "        t_a = 20\n",
    "        \u03b1_quench = 2\n",
    "        t_pause = round(s_pause * t_a, 3)\n",
    "        \u0394_quench = round((1 - s_pause) / \u03b1_quench, 3)\n",
    "        if s_pause == 1:\n",
    "            anneal_schedule = [(0, 0), (t_pause, s_pause)]\n",
    "        else:\n",
    "            anneal_schedule = [\n",
    "                (0, 0),\n",
    "                (t_pause, s_pause),\n",
    "                (round(t_pause + \u0394_quench, 3), 1),\n",
    "            ]\n",
    "\n",
    "        # set model name and path\n",
    "        model_name = f\"model_annealer-s_pause={s_pause:.2f}-s={s:.2f}-embedding_{embedding_id:02}\"\n",
    "        model_path = artifact_dir / f\"models/{model_name}.pkl\"\n",
    "        if train_model:\n",
    "            # model_annealer params\n",
    "            beta_initial = 0.45\n",
    "            exact_params = None\n",
    "\n",
    "            # training params\n",
    "            n_epochs = 100\n",
    "            n_samples = 10_000\n",
    "            learning_rate = 0.1\n",
    "            mini_batch_size = 10\n",
    "            epochs = np.arange(1, n_epochs + 1)\n",
    "            learning_rates = learning_rate * lr_exp_decay(\n",
    "                epochs, decay_epoch=50, period=10\n",
    "            )\n",
    "            learning_rates_beta = learning_rate * lr_exp_decay(\n",
    "                epochs, decay_epoch=50, period=20\n",
    "            )\n",
    "\n",
    "            # set the anneal params\n",
    "            anneal_params = {\n",
    "                \"s\": s,\n",
    "                \"A\": df_anneal.loc[s, \"A(s) (GHz)\"],\n",
    "                \"B\": df_anneal.loc[s, \"B(s) (GHz)\"],\n",
    "                \"schedule\": anneal_schedule,\n",
    "            }\n",
    "\n",
    "            # skip if model already exists\n",
    "            if model_path.exists():\n",
    "                print(\"Model already exists\")\n",
    "                continue\n",
    "\n",
    "            # model init\n",
    "            model_annealer = BQRBM(\n",
    "                X_train=X_train,\n",
    "                n_hidden=n_hidden,\n",
    "                embedding=embedding,\n",
    "                anneal_params=anneal_params,\n",
    "                beta_initial=beta_initial,\n",
    "                exact_params=exact_params,\n",
    "            )\n",
    "\n",
    "            # model train and save\n",
    "            model_annealer.train(\n",
    "                n_epochs=n_epochs,\n",
    "                n_samples=n_samples,\n",
    "                learning_rate=learning_rates,\n",
    "                learning_rate_beta=learning_rates_beta,\n",
    "                mini_batch_size=mini_batch_size,\n",
    "                callback=callback,\n",
    "            )\n",
    "            models_annealer[embedding_id, s_pause] = model_annealer\n",
    "            model_annealer.save(model_path)\n",
    "\n",
    "            # save attributes as dict in case of error loading old pickled object\n",
    "            model_annealer_attributes = {\n",
    "                \"A\": model_annealer.A,\n",
    "                \"B\": model_annealer.B,\n",
    "                \"a\": model_annealer.a,\n",
    "                \"b\": model_annealer.b,\n",
    "                \"W\": model_annealer.W,\n",
    "                \"beta\": model_annealer.beta,\n",
    "                \"embedding\": model_annealer.embedding,\n",
    "                \"qpu_params\": model_annealer.qpu_params,\n",
    "                \"anneal_params\": model_annealer.anneal_params,\n",
    "                \"exact_params\": model_annealer.exact_params,\n",
    "                \"beta_history\": model_annealer.beta_history,\n",
    "                \"callback_outputs\": [x for x in model_annealer.callback_outputs],\n",
    "            }\n",
    "            save_artifact(\n",
    "                model_annealer_attributes,\n",
    "                artifact_dir / f\"models/{model_name}-attributes.pkl\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5907474f-bc03-4d7a-8184-2992c27f27be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {0.5: <qbm.models.BQRBM.BQRBM at 0x7f37173efeb0>,\n",
       "  0.55: <qbm.models.BQRBM.BQRBM at 0x7f37173ef760>,\n",
       "  0.6: <qbm.models.BQRBM.BQRBM at 0x7f373c718a00>,\n",
       "  0.9: <qbm.models.BQRBM.BQRBM at 0x7f37587d01f0>,\n",
       "  0.95: <qbm.models.BQRBM.BQRBM at 0x7f37173efe80>,\n",
       "  1.0: <qbm.models.BQRBM.BQRBM at 0x7f3717475850>}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.4 ms (started: 2022-02-23 14:23:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "model_dir = artifact_dir / f\"models\"\n",
    "samples_dir = artifact_dir / f\"samples\"\n",
    "models_annealer = {}\n",
    "samples_annealer = {}\n",
    "for embedding_id in embedding_ids:\n",
    "    models_s_pauses = {}\n",
    "    samples_s_pauses = {}\n",
    "    for s_pause in s_pauses:\n",
    "        model_name = f\"model_annealer-s_pause={s_pause:.2f}-s=1.00-embedding_{embedding_id:02}\"\n",
    "        model = BQRBM.load(model_dir / (model_name + \".pkl\"), initialize_qpu_sampler=False)\n",
    "        models_s_pauses[s_pause] = model\n",
    "        \n",
    "        samples_ids = range(1, 11)\n",
    "        samples_s_pauses[s_pause] = {}\n",
    "        for samples_id in samples_ids:\n",
    "            samples_path = samples_dir / model_name / f\"{samples_id:02}.pkl\"\n",
    "            if not samples_path.exists():\n",
    "                samples = model.sample(n_samples=10_000, binary=True)\n",
    "                save_artifact(samples, samples_path)\n",
    "            else:\n",
    "                samples = load_artifact(samples_path)\n",
    "            samples_s_pauses[s_pause][samples_id] = samples\n",
    "            \n",
    "        \n",
    "    models_annealer[embedding_id] = models_s_pauses\n",
    "    samples_annealer[embedding_id] = samples_s_pauses\n",
    "models_annealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017e63a-cf90-449e-9e54-49a9c26bcae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train a classical RBM for comparison purposes\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "rng = get_rng(42)\n",
    "model_RBM = BernoulliRBM(\n",
    "    n_components=n_hidden,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=10,\n",
    "    n_iter=10_000,\n",
    "    random_state=rng,\n",
    ")\n",
    "model_RBM.fit(X_train)\n",
    "\n",
    "samples_RBM = rng.choice([0, 1], (10 ** 6, n_visible))\n",
    "for i in range(1_000):\n",
    "    samples_RBM = model_RBM.gibbs(samples_RBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6d035-d9bf-4a53-b68a-7ebdcb50d171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_states = (X_train * 2.0 ** np.arange(n_visible - 1, -1, -1)).sum(axis=1)\n",
    "dkls_annealer = {}\n",
    "for embedding_id, samples_s_pauses in samples_annealer.items():\n",
    "    dkls_annealer[embedding_id] = {}\n",
    "    for s_pause, samples_dict in samples_s_pauses.items():\n",
    "        dkls = []\n",
    "        for sample_id, sample in samples_dict.items():\n",
    "            sample_states = (\n",
    "                sample.record.sample[:, :n_visible]\n",
    "                * 2.0 ** np.arange(n_visible - 1, -1, -1)\n",
    "            ).sum(axis=1)\n",
    "\n",
    "            dkls.append(kl_divergence(train_states, sample_states, n_bins=32))\n",
    "\n",
    "        dkls_annealer[embedding_id][s_pause] = {\n",
    "            \"mean\": np.mean(dkls),\n",
    "            \"std\": np.std(dkls),\n",
    "            \"min\": np.min(dkls),\n",
    "        }\n",
    "\n",
    "samples_exact_test = model_exact.sample(n_samples=10 ** 6, binary=True)[\"state_vectors\"][:, :n_visible]\n",
    "samples_exact_test = (samples_exact_test * 2.0 ** np.arange(n_visible - 1, -1, -1)).sum(axis=1)\n",
    "dkl_exact_test = kl_divergence(train_states, samples_exact_test, n_bins=32)\n",
    "\n",
    "samples_RBM_test = (samples_RBM * 2.0 ** np.arange(n_visible - 1, -1, -1)).sum(axis=1)\n",
    "dkl_RBM_test = kl_divergence(train_states, samples_RBM_test, n_bins=32)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "y_min = []\n",
    "y_err = []\n",
    "for s_pause, means_stds in dkls_annealer[embedding_id].items():\n",
    "    x.append(s_pause)\n",
    "    y.append(means_stds[\"mean\"])\n",
    "    y_min.append(means_stds[\"min\"])\n",
    "    y_err.append(means_stds[\"std\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "ax.errorbar(\n",
    "    x,\n",
    "    y,\n",
    "    yerr=y_err,\n",
    "    fmt=\"o\",\n",
    "    markersize=8,\n",
    "    linewidth=2,\n",
    "    capsize=8,\n",
    "    zorder=1,\n",
    "    label=\"BQRBM Advantage 5.1\",\n",
    ")\n",
    "ax.scatter(x, y_min, marker=\"x\", s=64, c=\"tab:blue\", label=\"BQRBM Advantage 5.1 Minimum\")\n",
    "ax.axhline(dkl_exact_test, linestyle=\"dashed\", color=\"tab:red\", label=\"BQRBM Simulation\", linewidth=1.8)\n",
    "ax.axhline(dkl_RBM_test, linestyle=\"dotted\", color=\"tab:green\", label=\"Classical RBM\", linewidth=1.8)\n",
    "ax.set_ylabel(r\"$D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax.set_xlabel(r\"$s_{quench}$\")\n",
    "ax.set_xticks(np.arange(45, 105, 5) / 100)\n",
    "ax.set_xticks(np.arange(45, 105, 5) / 100)\n",
    "ax.set_yticks(np.arange(0, 45, 5) / 1000)\n",
    "ax.set_ylim((0, 0.04))\n",
    "ax.grid(alpha=0.7)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"model_comparison_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8932bb-03f8-46a5-ad8b-91d663ecb803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_id = 5\n",
    "s_pause = 0.55\n",
    "model_annealer = models_annealer[embedding_id][s_pause]\n",
    "samples_annealer_ = samples_annealer[embedding_id][s_pause][1]\n",
    "state_vectors = samples_annealer_.record.sample[:, :n_visible]\n",
    "df_samples = pd.DataFrame({\"x\": [convert_bin_list_to_str(x) for x in state_vectors]})\n",
    "samples_annealer_df = unbinarize_df(df_samples, binarization_params)\n",
    "samples_annealer_df \n",
    "data = unbinarize_df(df_binarized, binarization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebf361-7b8d-41a2-a4ac-9aaebe5ebdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_bins = 32\n",
    "fig, ax = plt.subplots(dpi=144, figsize=(10, 6))\n",
    "_, bins, _ = ax.hist(data, bins=n_bins, density=True, label=\"Data\")\n",
    "ax.hist(samples_annealer_df, bins=bins, density=True, alpha=0.5, color=\"tab:orange\", label=\"Model (Advantage 5.1)\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"hist_comparison_annealer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8631a76-ec6b-45f6-b5ac-bb1d0d3e47c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qq_params = {\n",
    "    \"xlims\": (-6.5, 6.5),\n",
    "    \"ylims\": (-6.5, 6.5),\n",
    "    \"xticks\": np.arange(-6, 7, 1),\n",
    "    \"yticks\": np.arange(-6, 7, 1),\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, dpi=144, figsize=(10, 5))\n",
    "plot_qq(\n",
    "    axs[0],\n",
    "    data.to_numpy(),\n",
    "    samples_exact.to_numpy()[: len(data)],\n",
    "    title=r\"Simulation\",\n",
    "    params=qq_params,\n",
    ")\n",
    "plot_qq(\n",
    "    axs[1],\n",
    "    data.to_numpy(),\n",
    "    samples_annealer_df.to_numpy()[1000:1000+ len(data)],\n",
    "    title=\"Advantage 5.1\",\n",
    "    params=qq_params,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"qq_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155249c-3907-4a4e-9ec9-c3b70ffa4418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smooth(x, k=10):\n",
    "    x_out = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        x_out[i] = np.mean(x[i - min((k - 1, i)) : i + 1])\n",
    "    return x_out\n",
    "\n",
    "\n",
    "markers = [\"o\", \"^\", \"v\", \"<\", \">\", \"s\", \"p\", \"*\", \"P\", \"X\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "dkls_exact = [d[\"value\"] for d in model_exact.callback_outputs]\n",
    "ax[0].plot(\n",
    "    epochs, smooth(dkls_exact), label=r\"Simulation\", color=\"k\", linestyle=\"--\"\n",
    ")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(r\"$D_{KL}(p_{data} \\ || \\ p_{model})$ [10 Epoch Moving Average]\")\n",
    "ax[0].set_ylim((0, 0.2))\n",
    "ax[0].set_yticks(np.arange(0, 22.5, 2.5) / 100)\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(r\"$\\hat{\\beta}$ [10 Epoch Moving Average]\")\n",
    "i = 0\n",
    "for embedding_id in [5]:\n",
    "    for s_pause in s_pauses:\n",
    "        model_annealer = models_annealer[embedding_id][s_pause]\n",
    "        dkls_annealer = [d[\"value\"] for d in model_annealer.callback_outputs]\n",
    "\n",
    "        epochs = np.arange(1, len(dkls_exact) + 1)\n",
    "        ax[0].plot(\n",
    "            epochs,\n",
    "            smooth(dkls_annealer),\n",
    "            label=fr\"Advantage 5.1, $s_{{pause}} = {s_pause:.2f}$\",\n",
    "            color=colors[i],\n",
    "            marker=markers[i],\n",
    "            markersize=6,\n",
    "            markevery=3,\n",
    "        )\n",
    "\n",
    "        ax[1].plot(\n",
    "            range(len(model_annealer.beta_history)),\n",
    "            smooth(model_annealer.beta_history),\n",
    "            color=colors[i],\n",
    "            marker=markers[i],\n",
    "            markersize=6,\n",
    "            markevery=3,\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "ax[0].grid()\n",
    "ax[0].legend()\n",
    "ax[1].grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"train_results_annealer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a4984-23d2-47f8-b33b-3b0f22f75664",
   "metadata": {},
   "source": [
    "## Exact Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d0a2b6-c020-4bf1-9d97-5a5361c7b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.4 ms (started: 2022-02-23 14:23:38 +01:00)\n"
     ]
    }
   ],
   "source": [
    "@njit(boundscheck=True)\n",
    "def kl_divergence_exact(\n",
    "    p_exact,\n",
    "    E_exact,\n",
    "    E_samples,\n",
    "    counts_samples,\n",
    "    n_bins=32,\n",
    "    prob_sum_tol=1e-6,\n",
    "    \u03f5_smooth=1e-6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the KL divergence of the theory w.r.t. the samples, i.e., \n",
    "    D_KL(p_exact || p_samples).\n",
    "    \n",
    "    :param p_exact: Exact computed probability vector, i.e., the diagonal of \u03c1.\n",
    "    :param E_exact: Exact computed energy vector, i.e., the diagonal of H.\n",
    "    :param E_samples: Energies of the samples.\n",
    "    :param n_bins: Number of bins to compute over.\n",
    "    :param prob_sum_tol: The tolerance for the probabilities to sum up to approx 1.\n",
    "    :param \u03f5_smooth: Smoothing parameter for the samples distribution.\n",
    "    \n",
    "    :returns: D_KL(p_exact || p_samples).\n",
    "    \"\"\"\n",
    "    p = np.zeros(n_bins)\n",
    "    q = np.zeros(n_bins)\n",
    "\n",
    "    # compute the bin edges\n",
    "    buffer = np.abs(E_exact).max() * 1e-15\n",
    "    bin_edges = np.linspace(E_exact.min() - buffer, E_exact.max() + buffer, n_bins + 1)\n",
    "\n",
    "    # check that bin edges include all possible E values\n",
    "    assert bin_edges.min() <= E_exact.min()\n",
    "    assert bin_edges.max() >= E_exact.max()\n",
    "\n",
    "    # bin the probabilities\n",
    "    sum_counts = counts_samples.sum()\n",
    "    for i, (a, b) in enumerate(zip(bin_edges[:-1], bin_edges[1:])):\n",
    "        if i < n_bins - 1:\n",
    "            p[i] = p_exact[np.logical_and(E_exact >= a, E_exact < b)].sum()\n",
    "            q[i] = (\n",
    "                counts_samples[np.logical_and(E_samples >= a, E_samples < b)].sum()\n",
    "                / sum_counts\n",
    "            )\n",
    "        else:\n",
    "            p[i] = p_exact[E_exact >= a].sum()\n",
    "            q[i] = counts_samples[E_samples >= a].sum() / sum_counts\n",
    "\n",
    "    # smoothing of sample data\n",
    "    smooth_mask = np.logical_and(p > 0, q == 0)\n",
    "    not_smooth_mask = np.logical_not(smooth_mask)\n",
    "    q[smooth_mask] = p[smooth_mask] * \u03f5_smooth\n",
    "    q[not_smooth_mask] -= q[smooth_mask].sum() / not_smooth_mask.sum()\n",
    "\n",
    "    # check that p and q sum up to approx 1\n",
    "    assert np.abs(p.sum() - 1) < prob_sum_tol\n",
    "    assert np.abs(q.sum() - 1) < prob_sum_tol\n",
    "\n",
    "    # take intersection of supports to avoid div zero errors\n",
    "    support_intersection = np.logical_and(p > 0, q > 0)\n",
    "    p = p[support_intersection]\n",
    "    q = q[support_intersection]\n",
    "\n",
    "    return (p * np.log(p / q)).sum()\n",
    "\n",
    "\n",
    "@njit(boundscheck=True)\n",
    "def get_state_energies(states, E_exact):\n",
    "    \"\"\"\n",
    "    Returns the (quantum + classical) energies of the provided states corresponding\n",
    "    to the provided exact calculated energies.\n",
    "    \n",
    "    :param states: Array of states. Must be a value in 0, 1, ..., 2 ** n_qubits - 1.\n",
    "    :param E_exact: Array of exact computed energies, corresponds to the diagonal of H.\n",
    "    \n",
    "    :returns: Array where entry i is the energy of states[i].\n",
    "    \"\"\"\n",
    "    E_samples = np.zeros(len(states))\n",
    "    for i, state in enumerate(states):\n",
    "        E_samples[i] = E_exact[state]\n",
    "\n",
    "    return E_samples\n",
    "\n",
    "\n",
    "def convert_spin_vector_to_state_number(spins):\n",
    "    \"\"\"\n",
    "    Converts the spins vector (e.g. all values \u00b11) to an integer corresponding to the state.\n",
    "    For example, the spin vector [1, 1, 1, 1] corresponds to the state |0000\u27e9 which is the\n",
    "    0th state. The spin vector [-1, -1, -1, -1] corresponds to the state |1111\u27e9 which is the\n",
    "    15th state.\n",
    "    \n",
    "    :param spins: Vector of spin values (\u00b11).\n",
    "    \n",
    "    :returns: Integer corresponding to the state. \n",
    "    \"\"\"\n",
    "    bit_vector = ((1 - spins) / 2).astype(np.int64)\n",
    "\n",
    "    return (bit_vector * 2 ** np.arange(len(bit_vector) - 1, -1, -1)).sum()\n",
    "\n",
    "\n",
    "def kl_divergence_df(exact_data, samples):\n",
    "    \"\"\"\n",
    "    Compares each exact computed data distribution against the provided samples instance.\n",
    "    \n",
    "    :param exact_data: Dictionary with keys of the form (s, T) with s being the relative\n",
    "        anneal time at which H and \u03c1 were computed, and T being the effective temperature.\n",
    "        Values are of the form {\"E\": [...], \"p\": [...]}\n",
    "    :param samples: Instance of Ocean SDK SampleSet.\n",
    "    \n",
    "    :returns: Dataframe of KL divergences, with T values as index and s values as columns.\n",
    "    \"\"\"\n",
    "    # convert spin vectors to state numbers\n",
    "    states = np.array(\n",
    "        [convert_spin_vector_to_state_number(x) for x in samples.record.sample]\n",
    "    )\n",
    "\n",
    "    dkl = {}\n",
    "    for s, T in exact_data.keys():\n",
    "        p_exact = exact_data[(s, T)][\"p\"]\n",
    "        E_exact = exact_data[(s, T)][\"E\"]\n",
    "        E_samples = get_state_energies(states, E_exact)\n",
    "\n",
    "        dkl[int(T * 1000), s] = kl_divergence_(\n",
    "            p_exact, E_exact, E_samples, samples.record.num_occurrences\n",
    "        )\n",
    "\n",
    "    return pd.Series(dkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8645107-e3ab-4c64-aeb7-d13ad43ea6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 324 ms (started: 2022-02-23 14:23:39 +01:00)\n"
     ]
    }
   ],
   "source": [
    "compute_distributions = False\n",
    "compute_dkls = False\n",
    "\n",
    "embedding_id = 5\n",
    "s_pause = 0.55\n",
    "\n",
    "T_values = np.arange(0, 202, 2) / 1000\n",
    "T_values[0] = 1e-6\n",
    "s_values = np.arange(0, 101, 1) / 100\n",
    "pauli_kron = get_pauli_kron(n_visible, n_hidden)\n",
    "\n",
    "model_annealer = models_annealer[embedding_id][s_pause]\n",
    "h = model_annealer.h\n",
    "J = model_annealer.J\n",
    "\n",
    "distributions = {}\n",
    "if compute_distributions:\n",
    "    for s_value in s_values:\n",
    "        A = df_anneal.loc[s_value, \"A(s) (GHz)\"]\n",
    "        B = df_anneal.loc[s_value, \"B(s) (GHz)\"]\n",
    "        for T_value in T_values:\n",
    "            beta = 1 / k_B / T_value\n",
    "            H = compute_H(h, J, A, B, n_qubits, pauli_kron)\n",
    "            rho = compute_rho(H, beta, diagonal=(A == 0))\n",
    "            distributions[s_value, T_value] = {\n",
    "                \"E\": H.diagonal().copy(),\n",
    "                \"p\": rho.diagonal().copy(),\n",
    "            }\n",
    "\n",
    "    save_artifact(\n",
    "        distributions,\n",
    "        artifact_dir / f\"exact_distributions/distributions-s_pause={s_pause:.2f}.pkl\",\n",
    "    )\n",
    "else:\n",
    "    distributions = load_artifact(\n",
    "        artifact_dir / f\"exact_distributions/distributions-s_pause={s_pause:.2f}.pkl\"\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_dkls_sample(distribution, sample_energies, sample_id):\n",
    "    dkl = kl_divergence_exact(\n",
    "        distribution[\"p\"],\n",
    "        distribution[\"E\"],\n",
    "        E_samples=sample_energies[sample_id - 1],\n",
    "        counts_samples=np.ones(len(sample_energies[sample_id - 1])),\n",
    "    )\n",
    "\n",
    "    return dkl\n",
    "\n",
    "\n",
    "dkls = {}\n",
    "sample_ids = range(1, 11)\n",
    "if compute_dkls:\n",
    "    for (s_value, T_value), distribution in distributions.items():\n",
    "        sample_energies = []\n",
    "        for sample_id in sample_ids:\n",
    "            sample = samples_annealer[embedding_id][s_pause][sample_id]\n",
    "            states = np.array(\n",
    "                [\n",
    "                    convert_spin_vector_to_state_number(x)\n",
    "                    for x in model_annealer._binary_to_eigen(sample.record.sample)\n",
    "                ]\n",
    "            )\n",
    "            sample_energies.append(get_state_energies(states, distribution[\"E\"]))\n",
    "            \n",
    "        dkls_sT = Parallel(n_jobs=6)(\n",
    "            delayed(compute_dkls_sample)(distribution, sample_energies, sample_id)\n",
    "            for sample_id in sample_ids\n",
    "        )\n",
    "\n",
    "        dkls[s_value, T_value] = np.mean(dkls_sT)\n",
    "\n",
    "    save_artifact(\n",
    "        dkls, artifact_dir / f\"exact_distributions/dkls-s_pause={s_pause:.2f}.pkl\"\n",
    "    )\n",
    "else:\n",
    "    dkls = load_artifact(\n",
    "        artifact_dir / f\"exact_distributions/dkls-s_pause={s_pause:.2f}.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff872299-0bba-48e0-a728-98f2f32b2373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104\n",
      "0.0042004964503645345\n",
      "0.10737493894962012\n",
      "0.005111176054905317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x1800 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 747 ms (started: 2022-02-24 12:14:44 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "dkl = pd.DataFrame.from_dict(dkls, orient=\"index\")\n",
    "dkl.index = pd.MultiIndex.from_tuples(dkl.index)\n",
    "dkl = dkl.unstack(level=0)[0]\n",
    "\n",
    "xticks = np.arange(len(s_values))[::10]\n",
    "xticklabels = s_values[::10]\n",
    "yticks = np.arange(len(T_values))[::10]\n",
    "yticklabels = np.round(T_values[::10] * 1000).astype(np.int64)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "cbar_kws = {\"label\": r\"$D_{KL}(p_{exact} \\ || \\ p_{samples})$\"}\n",
    "cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "sns.heatmap(dkl, ax=ax, cmap=cmap, vmin=0, vmax=0.2, cbar_kws=cbar_kws)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(r\"$s$\")\n",
    "ax.set_ylabel(r\"$T$ [mK]\")\n",
    "ax.set_xticks(xticks + 0.5)\n",
    "ax.set_xticklabels(xticklabels, rotation=0)\n",
    "ax.set_yticks(yticks + 0.5)\n",
    "ax.set_yticklabels(yticklabels, rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "T_model = 1 / model_annealer.beta / k_B\n",
    "x_min = 1 * 100\n",
    "y_min = T_model / 2 * 1000\n",
    "ax.scatter(\n",
    "    [x_min],\n",
    "    [y_min],\n",
    "    marker=\"+\",\n",
    "    c=\"tab:blue\",\n",
    "    label=fr\"$T_{{learned}} = {round(T_model * 1000, 1)}$ mK\",\n",
    ")\n",
    "T_optimal = dkl.index[np.argmin(dkl[1.0])]\n",
    "x_min = 1 * 100\n",
    "y_min = T_optimal / 2 * 1000\n",
    "# ax.scatter(\n",
    "#     [x_min],\n",
    "#     [y_min],\n",
    "#     marker=\"x\",\n",
    "#     c=\"tab:red\",\n",
    "#     label=fr\"$T_{{effective}} = {round(T_optimal * 1000, 1)} \\pm 2.0$ mK\",\n",
    "# )\n",
    "T_DW = 16.4 / 2\n",
    "ax.axhline(T_DW, c=\"w\", label=r\"$T_{DW} = 16.4 \\pm 0.1$ mK\")\n",
    "\n",
    "s_mins = np.round(np.arange(50, 101, 1) / 100, 2)\n",
    "T_mins = []\n",
    "B_mins = []\n",
    "\u03b2B_mins = []\n",
    "for s in s_mins:\n",
    "    i = np.argmin(dkl.loc[:, s])\n",
    "    T_mins.append(dkl.index[i])\n",
    "    B_mins.append(df_anneal.loc[s, \"B(s) (GHz)\"])\n",
    "    \u03b2B_mins.append(B_mins[-1] / k_B / T_mins[-1])\n",
    "T_mins = 1 / k_B / np.mean(\u03b2B_mins) * np.array(B_mins)\n",
    "ax.plot(\n",
    "    s_mins * 100,\n",
    "    T_mins / 2 * 1000,\n",
    "    linestyle=\"--\",\n",
    "    color=\"k\",\n",
    "    label=fr\"$B(s) / T = {np.mean(\u03b2B_mins) * k_B:.1f}}}$\",\n",
    ")\n",
    "\n",
    "ax.legend(framealpha=0.9)\n",
    "\n",
    "plt.savefig(project_dir / \"results/plots/qbm/8x4/effective_temperature.png\")\n",
    "\n",
    "\n",
    "def round_(x, nearest, n):\n",
    "    return round(nearest * round(x / nearest), n)\n",
    "\n",
    "print(T_optimal)\n",
    "print(dkl.loc[T_optimal, s])\n",
    "print(T_model)\n",
    "print(dkl.loc[round_(T_model, 0.002, 3), s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b39f7-8a2c-404f-b59c-7a8b134cd104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}