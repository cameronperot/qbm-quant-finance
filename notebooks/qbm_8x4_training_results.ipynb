{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444cdef5-48f1-49a6-9b96-9b63a8ab2663",
   "metadata": {},
   "source": [
    "# QBM Comparison Exact vs. Annealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3e13aa-be77-4306-9a2e-8effc428a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.59 s (started: 2022-03-23 23:32:49 +01:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neptune.new as neptune\n",
    "from numba import njit\n",
    "from scipy.constants import k as k_B, h as h_P\n",
    "\n",
    "k_B /= h_P * 1e9\n",
    "matplotlib.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "from qbm.models import BQRBM\n",
    "from qbm.plotting import plot_qq\n",
    "from qbm.utils import (\n",
    "    binarize_df,\n",
    "    convert_bin_list_to_str,\n",
    "    get_binarization_params,\n",
    "    get_project_dir,\n",
    "    get_rng,\n",
    "    kl_divergence,\n",
    "    load_artifact,\n",
    "    lr_exp_decay,\n",
    "    prepare_training_data,\n",
    "    save_artifact,\n",
    "    unbinarize_df,\n",
    "    compute_stats_over_dfs,\n",
    ")\n",
    "from qbm.utils.exact_qbm import get_pauli_kron, compute_H, compute_rho\n",
    "\n",
    "# configure directories\n",
    "project_dir = get_project_dir()\n",
    "qpu_params = {\"region\": \"na-west-1\", \"solver\": \"Advantage_system4.1\"}\n",
    "artifact_dir = project_dir / f\"artifacts/qbm/8x4/{qpu_params['solver']}\"\n",
    "plot_dir = project_dir / f\"results/plots/qbm/8x4/{qpu_params['solver']}\"\n",
    "if not artifact_dir.exists():\n",
    "    artifact_dir.mkdir(parents=True)\n",
    "if not plot_dir.exists():\n",
    "    plot_dir.mkdir(parents=True)\n",
    "\n",
    "# load anneal schedule data\n",
    "if qpu_params[\"solver\"] == \"Advantage_system4.1\":\n",
    "    csv_name = \"09-1263A-A_Advantage_system4_1_annealing_schedule.csv\"\n",
    "elif qpu_params[\"solver\"] == \"Advantage_system5.1\":\n",
    "    csv_name = \"09-1265A-A_Advantage_system5_1_annealing_schedule.csv\"\n",
    "df_anneal = pd.read_csv(\n",
    "    project_dir / f\"data/anneal_schedules/csv/{csv_name}\", index_col=\"s\",\n",
    ")\n",
    "if 0.5 not in df_anneal.index:\n",
    "    df_anneal.loc[0.5] = (df_anneal.loc[0.499] + df_anneal.loc[0.501]) / 2\n",
    "df_anneal.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fdfc1-7d3c-41f9-b789-d89c818172ec",
   "metadata": {},
   "source": [
    "## Train Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f998341-610b-4900-ae94-c8cca34ec7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10 ms (started: 2022-03-23 23:32:51 +01:00)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "n_visible = 8\n",
    "n_hidden = 4\n",
    "n_qubits = n_visible + n_hidden\n",
    "\n",
    "rng = get_rng(seed)\n",
    "n_samples = 1500\n",
    "\u03b1 = 2 / 3\n",
    "N_1 = rng.normal(-2, 1, int(round(n_samples * \u03b1, 0)))\n",
    "N_2 = rng.normal(3, 1, int(round(n_samples * (1 - \u03b1), 0)))\n",
    "x = np.concatenate((N_1, N_2))\n",
    "\n",
    "df = pd.DataFrame.from_dict({\"x\": x})\n",
    "binarization_params = get_binarization_params(df, n_bits=n_visible)\n",
    "df_binarized = binarize_df(df, binarization_params)\n",
    "X_train = prepare_training_data(df_binarized)[\"X_train\"]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43251d5d-418f-47b1-ab9d-22466a4bf0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 240 ms (started: 2022-03-23 23:32:51 +01:00)\n"
     ]
    }
   ],
   "source": [
    "data = unbinarize_df(df_binarized, binarization_params)\n",
    "\n",
    "n_bins = 32\n",
    "fig, ax = plt.subplots(dpi=144, figsize=(10, 6))\n",
    "_, bins, _ = ax.hist(data, bins=n_bins, density=True, label=\"Data\")\n",
    "ax.grid(alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"hist_data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da319a69-0e5c-4b89-847f-3716253893b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 652 \u00b5s (started: 2022-03-23 23:32:51 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def callback(model, sample_state_vectors):\n",
    "    X_train = model.X_train\n",
    "    n_visible = model.X_train.shape[1]\n",
    "    train_states = (\n",
    "        model._eigen_to_binary(model.X_train) * 2.0 ** np.arange(n_visible - 1, -1, -1)\n",
    "    ).sum(axis=1)\n",
    "    sample_states = (\n",
    "        model._eigen_to_binary(sample_state_vectors[:, :n_visible])\n",
    "        * 2.0 ** np.arange(n_visible - 1, -1, -1)\n",
    "    ).sum(axis=1)\n",
    "\n",
    "    dkl = kl_divergence(train_states, sample_states, n_bins=32)\n",
    "\n",
    "    return {\"value\": dkl, \"print\": f\"D_KL = {dkl:.3f}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6216f-7998-42b0-ae52-78323311fc8a",
   "metadata": {},
   "source": [
    "## Model Analysis (Exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6bca6d-4486-4312-b849-1de7cefbd647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.7 ms (started: 2022-03-23 23:32:51 +01:00)\n"
     ]
    }
   ],
   "source": [
    "s_freeze = 1.0\n",
    "train_model = False\n",
    "if train_model:\n",
    "    # model params\n",
    "    embedding = None\n",
    "    beta_initial = 1\n",
    "    exact_params = {\"beta\": 0.5}\n",
    "\n",
    "    # training params\n",
    "    n_epochs = 100\n",
    "    n_samples = 10_000\n",
    "    learning_rate = 0.1\n",
    "    mini_batch_size = 10\n",
    "    decay_epoch = 50\n",
    "    decay_period = 10\n",
    "    epochs = np.arange(1, n_epochs + 1)\n",
    "    learning_rates = learning_rate * lr_exp_decay(epochs, decay_epoch=50, period=10)\n",
    "    learning_rates_beta = learning_rate * lr_exp_decay(\n",
    "        epochs, decay_epoch=50, period=20\n",
    "    )\n",
    "\n",
    "    anneal_params = {\n",
    "        \"s\": s_freeze,\n",
    "        \"A\": df_anneal.loc[s_freeze, \"A(s) (GHz)\"],\n",
    "        \"B\": df_anneal.loc[s_freeze, \"B(s) (GHz)\"],\n",
    "    }\n",
    "    # model init\n",
    "    model_exact = BQRBM(\n",
    "        X_train=X_train,\n",
    "        n_hidden=n_hidden,\n",
    "        embedding=embedding,\n",
    "        anneal_params=anneal_params,\n",
    "        beta_initial=beta_initial,\n",
    "        exact_params=exact_params,\n",
    "    )\n",
    "\n",
    "    # model train and save\n",
    "    model_exact.train(\n",
    "        n_epochs=n_epochs,\n",
    "        n_samples=n_samples,\n",
    "        learning_rate=learning_rates,\n",
    "        learning_rate_beta=learning_rates_beta,\n",
    "        mini_batch_size=mini_batch_size,\n",
    "        callback=callback,\n",
    "    )\n",
    "    model_exact.save(artifact_dir / f\"models/exact/model-s_freeze={s_freeze}.pkl\")\n",
    "    model_exact_metrics = {\n",
    "        \"A\": model_exact.A,\n",
    "        \"B\": model_exact.B,\n",
    "        \"a\": model_exact.a,\n",
    "        \"b\": model_exact.b,\n",
    "        \"W\": model_exact.W,\n",
    "        \"beta\": model_exact.beta,\n",
    "        \"embedding\": model_exact.embedding,\n",
    "        \"anneal_params\": model_exact.anneal_params,\n",
    "        \"exact_params\": model_exact.exact_params,\n",
    "        \"beta_history\": model_exact.beta_history,\n",
    "        \"callback_outputs\": [x for x in model_exact.callback_outputs],\n",
    "    }\n",
    "    save_artifact(\n",
    "        model_exact_metrics,\n",
    "        artifact_dir / f\"models/exact/model-s_freeze={s_freeze}-attributes.pkl\",\n",
    "    )\n",
    "else:\n",
    "    model_exact = BQRBM.load(\n",
    "        artifact_dir / f\"models/exact/model-s_freeze={s_freeze}.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17f7245-ce18-4845-9c30-a53084a34472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.89 s (started: 2022-03-23 23:32:51 +01:00)\n"
     ]
    }
   ],
   "source": [
    "samples_exact = model_exact.sample(10 ** 6, binary=True)\n",
    "state_vectors_exact = samples_exact[\"state_vectors\"][:, :n_visible]\n",
    "df_samples_exact = pd.DataFrame(\n",
    "    {\"x\": [convert_bin_list_to_str(x) for x in state_vectors_exact]}\n",
    ")\n",
    "samples_exact = unbinarize_df(df_samples_exact, binarization_params)\n",
    "data = unbinarize_df(df_binarized, binarization_params)\n",
    "\n",
    "n_bins = 32\n",
    "fig, ax = plt.subplots(dpi=144, figsize=(10, 6))\n",
    "_, bins, _ = ax.hist(data, bins=n_bins, density=True, label=\"Data\")\n",
    "ax.hist(\n",
    "    samples_exact,\n",
    "    bins=bins,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Model (Simulation)\",\n",
    ")\n",
    "ax.grid(alpha=0.7)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"hist_comparison_exact.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dcd5188-6e44-4db1-ac02-a0fb27d1fd67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 756 ms (started: 2022-03-23 23:32:56 +01:00)\n"
     ]
    }
   ],
   "source": [
    "dkls = [x[\"value\"] for x in model_exact.callback_outputs]\n",
    "epochs = np.arange(1, len(dkls) + 1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "ax[0].plot(epochs, dkls, linewidth=1.8)\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(r\"$D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax[0].set_yticks(np.arange(0, 22.5, 2.5) / 100)\n",
    "ax[1].set_yticks(np.arange(40, 110, 10))\n",
    "ax[0].set_ylim((0, 0.2))\n",
    "ax[1].set_ylim((40, 100))\n",
    "ax[0].grid(alpha=0.7)\n",
    "\n",
    "ax[1].plot(\n",
    "    range(len(model_exact.beta_history)),\n",
    "    1 / k_B / np.array(model_exact.beta_history) * 1000,\n",
    "    linewidth=1.8,\n",
    ")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(r\"$\\hat{T}$ [mK]\")\n",
    "ax[1].axhline(1 / k_B / 0.5 * 1000, color=\"k\", linestyle=\"--\", label=r\"$T_{effective}$\", linewidth=1.8)\n",
    "ax[1].grid(alpha=0.7)\n",
    "ax[1].legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"train_results_exact.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c845feb-ab7e-48e2-800f-e04df4430e53",
   "metadata": {},
   "source": [
    "## Model Analysis (Annealer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d90469-70eb-4a60-88ca-a35f4e49058d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.7 s (started: 2022-03-23 23:32:57 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# set the model params\n",
    "train_model = False\n",
    "embedding_id = 10\n",
    "s_pause = 0.55\n",
    "s_freeze = 1.0\n",
    "\n",
    "# load embedding\n",
    "embedding = load_artifact(artifact_dir / f\"embeddings/embedding_{embedding_id:02}.json\")\n",
    "embedding = {int(k): v for k, v in embedding.items()}\n",
    "\n",
    "# set anneal schedule\n",
    "t_r = 20\n",
    "\u03b1_quench = 2\n",
    "t_pause = round(s_pause * t_r, 3)\n",
    "\u0394_quench = round((1 - s_pause) / \u03b1_quench, 3)\n",
    "if s_pause == 1:\n",
    "    anneal_schedule = [(0, 0), (t_pause, s_pause)]\n",
    "else:\n",
    "    anneal_schedule = [\n",
    "        (0, 0),\n",
    "        (t_pause, s_pause),\n",
    "        (round(t_pause + \u0394_quench, 3), 1),\n",
    "    ]\n",
    "\n",
    "# set model name and path\n",
    "model_name = (\n",
    "    f\"model-s_pause={s_pause:.2f}-s_freeze={s_freeze:.2f}-embedding_{embedding_id:02}\"\n",
    ")\n",
    "model_path = artifact_dir / f\"models/annealer/{model_name}.pkl\"\n",
    "if train_model:\n",
    "    # model_annealer params\n",
    "    beta_initial = 0.5\n",
    "    exact_params = None\n",
    "\n",
    "    # training params\n",
    "    n_epochs = 100\n",
    "    n_samples = 10_000\n",
    "    learning_rate = 0.1\n",
    "    mini_batch_size = 10\n",
    "    epochs = np.arange(1, n_epochs + 1)\n",
    "    learning_rates = learning_rate * lr_exp_decay(epochs, decay_epoch=50, period=10)\n",
    "    learning_rates_beta = learning_rate * lr_exp_decay(\n",
    "        epochs, decay_epoch=50, period=20\n",
    "    )\n",
    "\n",
    "    # set the anneal params\n",
    "    anneal_params = {\n",
    "        \"s\": s_freeze,\n",
    "        \"A\": df_anneal.loc[s_freeze, \"A(s) (GHz)\"],\n",
    "        \"B\": df_anneal.loc[s_freeze, \"B(s) (GHz)\"],\n",
    "        \"schedule\": anneal_schedule,\n",
    "    }\n",
    "\n",
    "    # skip if model already exists\n",
    "    if model_path.exists():\n",
    "        raise Exception(\"Model already exists\")\n",
    "\n",
    "    # model init\n",
    "    model_annealer = BQRBM(\n",
    "        X_train=X_train,\n",
    "        n_hidden=n_hidden,\n",
    "        embedding=embedding,\n",
    "        anneal_params=anneal_params,\n",
    "        beta_initial=beta_initial,\n",
    "        exact_params=exact_params,\n",
    "        qpu_params=qpu_params,\n",
    "    )\n",
    "\n",
    "    # model train and save\n",
    "    model_annealer.train(\n",
    "        n_epochs=n_epochs,\n",
    "        n_samples=n_samples,\n",
    "        learning_rate=learning_rates,\n",
    "        learning_rate_beta=learning_rates_beta,\n",
    "        mini_batch_size=mini_batch_size,\n",
    "        callback=callback,\n",
    "    )\n",
    "    model_annealer.save(model_path)\n",
    "\n",
    "    # save attributes as dict in case of error loading old pickled object\n",
    "    model_annealer_attributes = {\n",
    "        \"A\": model_annealer.A,\n",
    "        \"B\": model_annealer.B,\n",
    "        \"a\": model_annealer.a,\n",
    "        \"b\": model_annealer.b,\n",
    "        \"W\": model_annealer.W,\n",
    "        \"beta\": model_annealer.beta,\n",
    "        \"embedding\": model_annealer.embedding,\n",
    "        \"qpu_params\": model_annealer.qpu_params,\n",
    "        \"anneal_params\": model_annealer.anneal_params,\n",
    "        \"exact_params\": model_annealer.exact_params,\n",
    "        \"beta_history\": model_annealer.beta_history,\n",
    "        \"callback_outputs\": [x for x in model_annealer.callback_outputs],\n",
    "    }\n",
    "    save_artifact(\n",
    "        model_annealer_attributes,\n",
    "        artifact_dir / f\"models/annealer/{model_name}-attributes.pkl\",\n",
    "    )\n",
    "else:\n",
    "    model_annealer = BQRBM.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5907474f-bc03-4d7a-8184-2992c27f27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.64 s (started: 2022-03-23 23:33:00 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# generate samples with the annealer trained model\n",
    "model = BQRBM.load(model_path)\n",
    "ensemble_size = 10\n",
    "samples_dir = artifact_dir / \"samples\"\n",
    "samples_annealer = {}\n",
    "for sample_id in range(1, ensemble_size + 1):\n",
    "    samples_path = samples_dir / model_name / f\"samples_{sample_id:02}.pkl\"\n",
    "    if samples_path.exists():\n",
    "        samples_annealer[sample_id] = load_artifact(samples_path)\n",
    "    else:\n",
    "        samples_annealer[sample_id] = model_annealer.sample(\n",
    "            n_samples=10_000, binary=True\n",
    "        )\n",
    "        save_artifact(samples_annealer[sample_id], samples_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e017e63a-cf90-449e-9e54-49a9c26bcae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 220 ms (started: 2022-03-23 23:33:01 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# train a classical RBM for comparison purposes\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "train_model = False\n",
    "if train_model:\n",
    "    rng = get_rng(42)\n",
    "    model_RBM = BernoulliRBM(\n",
    "        n_components=n_hidden,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=10,\n",
    "        n_iter=10_000,\n",
    "        random_state=rng,\n",
    "    )\n",
    "    model_RBM.fit(X_train)\n",
    "\n",
    "    samples_RBM = rng.choice([0, 1], (10 ** 6, n_visible))\n",
    "    for i in range(1_000):\n",
    "        samples_RBM = model_RBM.gibbs(samples_RBM)\n",
    "\n",
    "    save_artifact(model_RBM, artifact_dir / \"RBM/model.pkl\")\n",
    "    save_artifact(samples_RBM, artifact_dir / \"RBM/samples.pkl\")\n",
    "else:\n",
    "    model_RBM = load_artifact(artifact_dir / \"RBM/model.pkl\")\n",
    "    samples_RBM = load_artifact(artifact_dir / \"RBM/samples.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2de6d035-d9bf-4a53-b68a-7ebdcb50d171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 271 ms (started: 2022-03-23 23:33:02 +01:00)\n"
     ]
    }
   ],
   "source": [
    "train_states = (X_train * 2.0 ** np.arange(n_visible - 1, -1, -1)).sum(axis=1)\n",
    "dkls_annealer_ = {}\n",
    "for sample_id, sample_set in samples_annealer.items():\n",
    "    sample_states = (\n",
    "        sample_set.record.sample[:, :n_visible]\n",
    "        * 2.0 ** np.arange(n_visible - 1, -1, -1)\n",
    "    ).sum(axis=1)\n",
    "\n",
    "    dkls_annealer_[sample_id] = kl_divergence(train_states, sample_states, n_bins=32)\n",
    "\n",
    "dkls_annealer_stats = {\n",
    "    \"mean\": np.mean(list(dkls_annealer_.values())),\n",
    "    \"std\": np.std(list(dkls_annealer_.values())),\n",
    "    \"min\": np.min(list(dkls_annealer_.values())),\n",
    "    \"max\": np.min(list(dkls_annealer_.values())),\n",
    "}\n",
    "\n",
    "samples_exact_test = model_exact.sample(n_samples=10 ** 6, binary=True)[\n",
    "    \"state_vectors\"\n",
    "][:, :n_visible]\n",
    "samples_exact_test = (samples_exact_test * 2.0 ** np.arange(n_visible - 1, -1, -1)).sum(\n",
    "    axis=1\n",
    ")\n",
    "dkl_exact_test = kl_divergence(train_states, samples_exact_test, n_bins=32)\n",
    "\n",
    "samples_RBM_test = (samples_RBM * 2.0 ** np.arange(n_visible - 1, -1, -1)).sum(axis=1)\n",
    "dkl_RBM_test = kl_divergence(train_states, samples_RBM_test, n_bins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8932bb-03f8-46a5-ad8b-91d663ecb803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 51.3 ms (started: 2022-03-23 23:33:02 +01:00)\n"
     ]
    }
   ],
   "source": [
    "state_vectors = samples_annealer[1].record.sample[:, :n_visible]\n",
    "df_samples = pd.DataFrame({\"x\": [convert_bin_list_to_str(x) for x in state_vectors]})\n",
    "samples_annealer_df = unbinarize_df(df_samples, binarization_params)\n",
    "samples_annealer_df\n",
    "data = unbinarize_df(df_binarized, binarization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ebf361-7b8d-41a2-a4ac-9aaebe5ebdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 314 ms (started: 2022-03-23 23:33:02 +01:00)\n"
     ]
    }
   ],
   "source": [
    "n_bins = 32\n",
    "fig, ax = plt.subplots(dpi=144, figsize=(10, 6))\n",
    "_, bins, _ = ax.hist(data, bins=n_bins, density=True, label=\"Data\")\n",
    "ax.hist(\n",
    "    samples_annealer_df,\n",
    "    bins=bins,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=\"tab:orange\",\n",
    "    label=\"BQRBM Advantage 4.1\",\n",
    ")\n",
    "ax.grid(alpha=0.7)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"hist_comparison_annealer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8631a76-ec6b-45f6-b5ac-bb1d0d3e47c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 350 ms (started: 2022-03-23 23:33:02 +01:00)\n"
     ]
    }
   ],
   "source": [
    "qq_params = {\n",
    "    \"xlims\": (-6.5, 6.5),\n",
    "    \"ylims\": (-6.5, 6.5),\n",
    "    \"xticks\": np.arange(-6, 7, 2),\n",
    "    \"yticks\": np.arange(-6, 7, 2),\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, dpi=144, figsize=(10, 5))\n",
    "plot_qq(\n",
    "    axs[0],\n",
    "    data.to_numpy(),\n",
    "    samples_exact.to_numpy()[: len(data)],\n",
    "    title=r\"Simulation\",\n",
    "    params=qq_params,\n",
    ")\n",
    "plot_qq(\n",
    "    axs[1],\n",
    "    data.to_numpy(),\n",
    "    samples_annealer_df.to_numpy()[1000 : 1000 + len(data)],\n",
    "    title=\"Advantage 4.1\",\n",
    "    params=qq_params,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"qq_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e155249c-3907-4a4e-9ec9-c3b70ffa4418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 673 ms (started: 2022-03-23 23:33:03 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def smooth(x, k=1):\n",
    "    x_out = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        x_out[i] = np.mean(x[i - min((k - 1, i)) : i + 1])\n",
    "    return x_out\n",
    "\n",
    "\n",
    "markers = [\"o\", \"^\", \"v\", \"<\", \">\", \"s\", \"p\", \"*\", \"P\", \"X\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "dkls_exact = [d[\"value\"] for d in model_exact.callback_outputs]\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(r\"$D_{KL}(p_{data} \\ || \\ p_{model})$\")\n",
    "ax[0].set_yticks(np.arange(0, 22.5, 2.5) / 100)\n",
    "ax[1].set_yticks(np.arange(80, 110, 2))\n",
    "ax[0].set_ylim((0, 0.2))\n",
    "# ax[1].set_ylim((80, 120))\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(r\"$\\hat{T}$ [mK]\")\n",
    "# ax[1].set_ylim((0.45, 0.55))\n",
    "i = 0\n",
    "dkls_annealer = [d[\"value\"] for d in model_annealer.callback_outputs]\n",
    "\n",
    "epochs = np.arange(1, len(dkls_exact) + 1)\n",
    "ax[0].plot(\n",
    "    epochs, smooth(dkls_annealer), label=fr\"BQRBM Advantage 4.1\", color=colors[i], linewidth=1.8\n",
    ")\n",
    "ax[0].plot(\n",
    "    epochs, smooth(dkls_exact), label=r\"BQRBM Simulation\", color=\"k\", linestyle=\"--\", linewidth=1.8\n",
    ")\n",
    "ax[0].axhline(\n",
    "    dkl_RBM_test,\n",
    "    label=\"RBM (Final Result)\",\n",
    "    linestyle=\"dotted\",\n",
    "    c=\"tab:gray\",\n",
    "    linewidth=2.5,\n",
    ")\n",
    "\n",
    "ax[1].plot(\n",
    "    range(len(model_annealer.beta_history)),\n",
    "    smooth(1 / k_B / np.array(model_annealer.beta_history) * 1000),\n",
    "    color=colors[i],\n",
    "    linewidth=1.8\n",
    ")\n",
    "\n",
    "ax[0].grid(alpha=0.7)\n",
    "ax[0].legend()\n",
    "ax[1].grid(alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"train_results_annealer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a4984-23d2-47f8-b33b-3b0f22f75664",
   "metadata": {},
   "source": [
    "## Exact Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7d0a2b6-c020-4bf1-9d97-5a5361c7b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.5 ms (started: 2022-03-23 23:33:03 +01:00)\n"
     ]
    }
   ],
   "source": [
    "@njit(boundscheck=True)\n",
    "def kl_divergence_exact(\n",
    "    p_exact,\n",
    "    E_exact,\n",
    "    E_samples,\n",
    "    counts_samples,\n",
    "    n_bins=32,\n",
    "    prob_sum_tol=1e-6,\n",
    "    \u03f5_smooth=1e-6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the KL divergence of the theory w.r.t. the samples, i.e., \n",
    "    D_KL(p_exact || p_samples).\n",
    "    \n",
    "    :param p_exact: Exact computed probability vector, i.e., the diagonal of \u03c1.\n",
    "    :param E_exact: Exact computed energy vector, i.e., the diagonal of H.\n",
    "    :param E_samples: Energies of the samples.\n",
    "    :param n_bins: Number of bins to compute over.\n",
    "    :param prob_sum_tol: The tolerance for the probabilities to sum up to approx 1.\n",
    "    :param \u03f5_smooth: Smoothing parameter for the samples distribution.\n",
    "    \n",
    "    :returns: D_KL(p_exact || p_samples).\n",
    "    \"\"\"\n",
    "    p = np.zeros(n_bins)\n",
    "    q = np.zeros(n_bins)\n",
    "\n",
    "    # compute the bin edges\n",
    "    buffer = np.abs(E_exact).max() * 1e-15\n",
    "    bin_edges = np.linspace(E_exact.min() - buffer, E_exact.max() + buffer, n_bins + 1)\n",
    "\n",
    "    # check that bin edges include all possible E values\n",
    "    assert bin_edges.min() <= E_exact.min()\n",
    "    assert bin_edges.max() >= E_exact.max()\n",
    "\n",
    "    # bin the probabilities\n",
    "    sum_counts = counts_samples.sum()\n",
    "    for i, (a, b) in enumerate(zip(bin_edges[:-1], bin_edges[1:])):\n",
    "        if i < n_bins - 1:\n",
    "            p[i] = p_exact[np.logical_and(E_exact >= a, E_exact < b)].sum()\n",
    "            q[i] = (\n",
    "                counts_samples[np.logical_and(E_samples >= a, E_samples < b)].sum()\n",
    "                / sum_counts\n",
    "            )\n",
    "        else:\n",
    "            p[i] = p_exact[E_exact >= a].sum()\n",
    "            q[i] = counts_samples[E_samples >= a].sum() / sum_counts\n",
    "\n",
    "    # smoothing of sample data\n",
    "    smooth_mask = np.logical_and(p > 0, q == 0)\n",
    "    not_smooth_mask = np.logical_not(smooth_mask)\n",
    "    q[smooth_mask] = p[smooth_mask] * \u03f5_smooth\n",
    "    q[not_smooth_mask] -= q[smooth_mask].sum() / not_smooth_mask.sum()\n",
    "\n",
    "    # check that p and q sum up to approx 1\n",
    "    assert np.abs(p.sum() - 1) < prob_sum_tol\n",
    "    assert np.abs(q.sum() - 1) < prob_sum_tol\n",
    "\n",
    "    # take intersection of supports to avoid div zero errors\n",
    "    support_intersection = np.logical_and(p > 0, q > 0)\n",
    "    p = p[support_intersection]\n",
    "    q = q[support_intersection]\n",
    "\n",
    "    return (p * np.log(p / q)).sum()\n",
    "\n",
    "\n",
    "@njit(boundscheck=True)\n",
    "def get_state_energies(states, E_exact):\n",
    "    \"\"\"\n",
    "    Returns the (quantum + classical) energies of the provided states corresponding\n",
    "    to the provided exact calculated energies.\n",
    "    \n",
    "    :param states: Array of states. Must be a value in 0, 1, ..., 2 ** n_qubits - 1.\n",
    "    :param E_exact: Array of exact computed energies, corresponds to the diagonal of H.\n",
    "    \n",
    "    :returns: Array where entry i is the energy of states[i].\n",
    "    \"\"\"\n",
    "    E_samples = np.zeros(len(states))\n",
    "    for i, state in enumerate(states):\n",
    "        E_samples[i] = E_exact[state]\n",
    "\n",
    "    return E_samples\n",
    "\n",
    "\n",
    "def convert_spin_vector_to_state_number(spins):\n",
    "    \"\"\"\n",
    "    Converts the spins vector (e.g. all values \u00b11) to an integer corresponding to the state.\n",
    "    For example, the spin vector [1, 1, 1, 1] corresponds to the state |0000\u27e9 which is the\n",
    "    0th state. The spin vector [-1, -1, -1, -1] corresponds to the state |1111\u27e9 which is the\n",
    "    15th state.\n",
    "    \n",
    "    :param spins: Vector of spin values (\u00b11).\n",
    "    \n",
    "    :returns: Integer corresponding to the state. \n",
    "    \"\"\"\n",
    "    bit_vector = ((1 - spins) / 2).astype(np.int64)\n",
    "\n",
    "    return (bit_vector * 2 ** np.arange(len(bit_vector) - 1, -1, -1)).sum()\n",
    "\n",
    "\n",
    "def kl_divergence_df(exact_data, samples):\n",
    "    \"\"\"\n",
    "    Compares each exact computed data distribution against the provided samples instance.\n",
    "    \n",
    "    :param exact_data: Dictionary with keys of the form (s, T) with s being the relative\n",
    "        anneal time at which H and \u03c1 were computed, and T being the effective temperature.\n",
    "        Values are of the form {\"E\": [...], \"p\": [...]}\n",
    "    :param samples: Instance of Ocean SDK SampleSet.\n",
    "    \n",
    "    :returns: Dataframe of KL divergences, with T values as index and s values as columns.\n",
    "    \"\"\"\n",
    "    # convert spin vectors to state numbers\n",
    "    states = np.array(\n",
    "        [convert_spin_vector_to_state_number(x) for x in samples.record.sample]\n",
    "    )\n",
    "\n",
    "    dkl = {}\n",
    "    for s, T in exact_data.keys():\n",
    "        p_exact = exact_data[(s, T)][\"p\"]\n",
    "        E_exact = exact_data[(s, T)][\"E\"]\n",
    "        E_samples = get_state_energies(states, E_exact)\n",
    "\n",
    "        dkl[int(T * 1000), s] = kl_divergence_(\n",
    "            p_exact, E_exact, E_samples, samples.record.num_occurrences\n",
    "        )\n",
    "\n",
    "    return pd.Series(dkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8645107-e3ab-4c64-aeb7-d13ad43ea6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 272 ms (started: 2022-03-23 23:33:03 +01:00)\n"
     ]
    }
   ],
   "source": [
    "compute_distributions = False\n",
    "compute_dkls = False\n",
    "\n",
    "T_values = np.arange(0, 152, 2) / 1000\n",
    "T_values[0] = 1e-6\n",
    "s_values = np.arange(0, 101, 1) / 100\n",
    "pauli_kron = get_pauli_kron(n_visible, n_hidden)\n",
    "\n",
    "h = model_annealer.h\n",
    "J = model_annealer.J\n",
    "\n",
    "distributions = {}\n",
    "if compute_distributions:\n",
    "    for s_value in s_values:\n",
    "        A = df_anneal.loc[s_value, \"A(s) (GHz)\"]\n",
    "        B = df_anneal.loc[s_value, \"B(s) (GHz)\"]\n",
    "        for T_value in T_values:\n",
    "            beta = 1 / k_B / T_value\n",
    "            H = compute_H(h, J, A, B, n_qubits, pauli_kron)\n",
    "            rho = compute_rho(H, beta, diagonal=(A == 0))\n",
    "            distributions[s_value, T_value] = {\n",
    "                \"E\": H.diagonal().copy(),\n",
    "                \"p\": rho.diagonal().copy(),\n",
    "            }\n",
    "\n",
    "    save_artifact(\n",
    "        distributions,\n",
    "        artifact_dir / f\"exact_distributions/distributions-s_pause={s_pause:.2f}.pkl\",\n",
    "    )\n",
    "else:\n",
    "    distributions = load_artifact(\n",
    "        artifact_dir / f\"exact_distributions/distributions-s_pause={s_pause:.2f}.pkl\"\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_dkls_sample(distribution, sample_energies, sample_id):\n",
    "    dkl = kl_divergence_exact(\n",
    "        distribution[\"p\"],\n",
    "        distribution[\"E\"],\n",
    "        E_samples=sample_energies[sample_id - 1],\n",
    "        counts_samples=np.ones(len(sample_energies[sample_id - 1])),\n",
    "    )\n",
    "\n",
    "    return dkl\n",
    "\n",
    "\n",
    "dkls = {}\n",
    "sample_ids = range(1, 11)\n",
    "if compute_dkls:\n",
    "    for (s_value, T_value), distribution in distributions.items():\n",
    "        sample_energies = []\n",
    "        for sample_id in sample_ids:\n",
    "            sample = samples_annealer[sample_id]\n",
    "            states = np.array(\n",
    "                [\n",
    "                    convert_spin_vector_to_state_number(x)\n",
    "                    for x in model_annealer._binary_to_eigen(sample.record.sample)\n",
    "                ]\n",
    "            )\n",
    "            sample_energies.append(get_state_energies(states, distribution[\"E\"]))\n",
    "\n",
    "        dkls_sT = Parallel(n_jobs=6)(\n",
    "            delayed(compute_dkls_sample)(distribution, sample_energies, sample_id)\n",
    "            for sample_id in sample_ids\n",
    "        )\n",
    "\n",
    "        dkls[s_value, T_value] = np.mean(dkls_sT)\n",
    "\n",
    "    save_artifact(\n",
    "        dkls, artifact_dir / f\"exact_distributions/dkls-s_pause={s_pause:.2f}.pkl\"\n",
    "    )\n",
    "else:\n",
    "    dkls = load_artifact(\n",
    "        artifact_dir / f\"exact_distributions/dkls-s_pause={s_pause:.2f}.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff872299-0bba-48e0-a728-98f2f32b2373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal T = 95.7 mK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x1800 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 660 ms (started: 2022-03-23 23:33:04 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "dkl = pd.DataFrame.from_dict(dkls, orient=\"index\")\n",
    "dkl.index = pd.MultiIndex.from_tuples(dkl.index)\n",
    "dkl = dkl.unstack(level=0)[0]\n",
    "\n",
    "xticks = np.arange(len(s_values))[::20]\n",
    "xticklabels = s_values[::20]\n",
    "yticks = np.arange(len(T_values))[::10]\n",
    "yticklabels = np.round(T_values[::10] * 1000).astype(np.int64)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "cbar_kws = {\"label\": r\"$D_{KL}(p_{theory} \\ || \\ p_{samples})$\", \"ticks\": [0, 0.05, 0.1, 0.15, 0.2]}\n",
    "cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "sns.heatmap(dkl, ax=ax, cmap=cmap, vmin=0, vmax=0.2, cbar_kws=cbar_kws)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(r\"$s$\")\n",
    "ax.set_ylabel(r\"$T$ [mK]\")\n",
    "ax.set_xticks(xticks + 0.5)\n",
    "ax.set_xticklabels(xticklabels, rotation=0)\n",
    "ax.set_yticks(yticks + 0.5)\n",
    "ax.set_yticklabels(yticklabels, rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "T_model = 1 / model_annealer.beta / k_B\n",
    "x_min = 1 * 100\n",
    "y_min = T_model / 2 * 1000\n",
    "ax.scatter(\n",
    "    [x_min],\n",
    "    [y_min],\n",
    "    marker=\"x\",\n",
    "    s=64,\n",
    "    c=\"tab:blue\",\n",
    "    label=fr\"$\\hat{{T}} = {round(T_model * 1000, 1)}$ mK\",\n",
    ")\n",
    "T_optimal = dkl.index[np.argmin(dkl[1.0])]\n",
    "x_min = 1 * 100\n",
    "y_min = T_optimal / 2 * 1000\n",
    "# ax.scatter(\n",
    "#     [x_min],\n",
    "#     [y_min],\n",
    "#     marker=\"x\",\n",
    "#     c=\"tab:red\",\n",
    "#     label=fr\"$T_{{effective}} = {round(T_optimal * 1000, 1)} \\pm 2.0$ mK\",\n",
    "# )\n",
    "s_mins = np.round(np.arange(50, 101, 1) / 100, 2)\n",
    "T_mins = []\n",
    "B_mins = []\n",
    "\u03b2B_mins = []\n",
    "for s in s_mins:\n",
    "    i = np.argmin(dkl.loc[:, s])\n",
    "    T_mins.append(dkl.index[i])\n",
    "    B_mins.append(df_anneal.loc[s, \"B(s) (GHz)\"])\n",
    "    \u03b2B_mins.append(B_mins[-1] / k_B / T_mins[-1])\n",
    "T_mins = 1 / k_B / np.mean(\u03b2B_mins) * np.array(B_mins)\n",
    "ax.plot(\n",
    "    s_mins * 100,\n",
    "    T_mins / 2 * 1000,\n",
    "    linestyle=\"--\",\n",
    "    color=\"k\",\n",
    "    label=fr\"$B(s) / T = {np.mean(\u03b2B_mins) * k_B:.1f}}}$ GHz/K\",\n",
    ")\n",
    "T_DW = 15.4 / 2\n",
    "ax.axhline(T_DW, c=\"w\", label=r\"$T_{DW} = 15.4 \\pm 0.1$ mK\")\n",
    "\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig(plot_dir / \"effective_temperature.png\")\n",
    "\n",
    "\n",
    "def round_(x, nearest, n):\n",
    "    return round(nearest * round(x / nearest), n)\n",
    "\n",
    "\n",
    "print(f\"Optimal T = {df_anneal.loc[1, 'B(s) (GHz)'] / 88.6 * 1000:.1f} mK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323f912-f5a8-484c-993c-a6edb2c71c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}