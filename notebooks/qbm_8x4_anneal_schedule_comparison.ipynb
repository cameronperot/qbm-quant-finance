{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb62c48-2177-49aa-a2e0-e6ab4960fd30",
   "metadata": {},
   "source": [
    "# Sample Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5660c694-9943-4078-8345-64acd3cec43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.61 s (started: 2022-03-09 10:08:05 +01:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "%load_ext line_profiler\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dwave.system import DWaveSampler, FixedEmbeddingComposite\n",
    "from matplotlib.patches import Rectangle\n",
    "from numba import njit\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "from qbm.utils import (\n",
    "    compute_stats_over_dfs,\n",
    "    convert_bin_list_to_str,\n",
    "    get_project_dir,\n",
    "    get_rng,\n",
    "    load_artifact,\n",
    "    save_artifact,\n",
    ")\n",
    "\n",
    "project_dir = get_project_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549de356-cbf7-4300-bff5-5a1d61107eab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016dfb81-ea40-4a8d-972b-21997e1c825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.7 ms (started: 2022-03-09 10:08:07 +01:00)\n"
     ]
    }
   ],
   "source": [
    "@njit(boundscheck=True)\n",
    "def kl_divergence(\n",
    "    p_exact,\n",
    "    E_exact,\n",
    "    E_samples,\n",
    "    counts_samples,\n",
    "    n_bins=32,\n",
    "    prob_sum_tol=1e-6,\n",
    "    \u03f5_smooth=1e-6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the KL divergence of the theory w.r.t. the samples, i.e., \n",
    "    D_KL(p_exact || p_samples).\n",
    "    \n",
    "    :param p_exact: Exact computed probability vector, i.e., the diagonal of \u03c1.\n",
    "    :param E_exact: Exact computed energy vector, i.e., the diagonal of H.\n",
    "    :param E_samples: Energies of the samples.\n",
    "    :param n_bins: Number of bins to compute over.\n",
    "    :param prob_sum_tol: The tolerance for the probabilities to sum up to approx 1.\n",
    "    :param \u03f5_smooth: Smoothing parameter for the samples distribution.\n",
    "    \n",
    "    :returns: D_KL(p_exact || p_samples).\n",
    "    \"\"\"\n",
    "    p = np.zeros(n_bins)\n",
    "    q = np.zeros(n_bins)\n",
    "\n",
    "    # compute the bin edges\n",
    "    buffer = np.abs(E_exact).max() * 1e-15\n",
    "    bin_edges = np.linspace(E_exact.min() - buffer, E_exact.max() + buffer, n_bins + 1)\n",
    "\n",
    "    # check that bin edges include all possible E values\n",
    "    assert bin_edges.min() <= E_exact.min()\n",
    "    assert bin_edges.max() >= E_exact.max()\n",
    "\n",
    "    # bin the probabilities\n",
    "    sum_counts = counts_samples.sum()\n",
    "    for i, (a, b) in enumerate(zip(bin_edges[:-1], bin_edges[1:])):\n",
    "        if i < n_bins - 1:\n",
    "            p[i] = p_exact[np.logical_and(E_exact >= a, E_exact < b)].sum()\n",
    "            q[i] = (\n",
    "                counts_samples[np.logical_and(E_samples >= a, E_samples < b)].sum()\n",
    "                / sum_counts\n",
    "            )\n",
    "        else:\n",
    "            p[i] = p_exact[E_exact >= a].sum()\n",
    "            q[i] = counts_samples[E_samples >= a].sum() / sum_counts\n",
    "\n",
    "    # smoothing of sample data\n",
    "    smooth_mask = np.logical_and(p > 0, q == 0)\n",
    "    not_smooth_mask = np.logical_not(smooth_mask)\n",
    "    q[smooth_mask] = p[smooth_mask] * \u03f5_smooth\n",
    "    q[not_smooth_mask] -= q[smooth_mask].sum() / not_smooth_mask.sum()\n",
    "\n",
    "    # check that p and q sum up to approx 1\n",
    "    assert np.abs(p.sum() - 1) < prob_sum_tol\n",
    "    assert np.abs(q.sum() - 1) < prob_sum_tol\n",
    "\n",
    "    # take intersection of supports to avoid div zero errors\n",
    "    support_intersection = np.logical_and(p > 0, q > 0)\n",
    "    p = p[support_intersection]\n",
    "    q = q[support_intersection]\n",
    "\n",
    "    return (p * np.log(p / q)).sum()\n",
    "\n",
    "\n",
    "@njit(boundscheck=True)\n",
    "def get_state_energies(states, E_exact):\n",
    "    \"\"\"\n",
    "    Returns the (quantum + classical) energies of the provided states corresponding\n",
    "    to the provided exact calculated energies.\n",
    "    \n",
    "    :param states: Array of states. Must be a value in 0, 1, ..., 2 ** n_qubits - 1.\n",
    "    :param E_exact: Array of exact computed energies, corresponds to the diagonal of H.\n",
    "    \n",
    "    :returns: Array where entry i is the energy of states[i].\n",
    "    \"\"\"\n",
    "    E_samples = np.zeros(len(states))\n",
    "    for i, state in enumerate(states):\n",
    "        E_samples[i] = E_exact[state]\n",
    "\n",
    "    return E_samples\n",
    "\n",
    "\n",
    "def convert_spin_vector_to_state_number(spins):\n",
    "    \"\"\"\n",
    "    Converts the spins vector (e.g. all values \u00b11) to an integer corresponding to the state.\n",
    "    For example, the spin vector [1, 1, 1, 1] corresponds to the state |0000\u27e9 which is the\n",
    "    0th state. The spin vector [-1, -1, -1, -1] corresponds to the state |1111\u27e9 which is the\n",
    "    15th state.\n",
    "    \n",
    "    :param spins: Vector of spin values (\u00b11).\n",
    "    \n",
    "    :returns: Integer corresponding to the state. \n",
    "    \"\"\"\n",
    "    bit_vector = ((1 - spins) / 2).astype(np.int64)\n",
    "\n",
    "    return (bit_vector * 2 ** np.arange(len(spins) - 1, -1, -1)).sum()\n",
    "\n",
    "\n",
    "def kl_divergence_df(exact_data, samples):\n",
    "    \"\"\"\n",
    "    Compares each exact computed data distribution against the provided samples instance.\n",
    "    \n",
    "    :param exact_data: Dictionary with keys of the form (s, T) with s being the relative\n",
    "        anneal time at which H and \u03c1 were computed, and T being the effective temperature.\n",
    "        Values are of the form {\"E\": [...], \"p\": [...]}\n",
    "    :param samples: Instance of Ocean SDK SampleSet.\n",
    "    \n",
    "    :returns: Dataframe of KL divergences, with T values as index and s values as columns.\n",
    "    \"\"\"\n",
    "    # convert spin vectors to state numbers\n",
    "    states = np.array(\n",
    "        [convert_spin_vector_to_state_number(x) for x in samples.record.sample]\n",
    "    )\n",
    "\n",
    "    dkl = {}\n",
    "    for s, T in exact_data.keys():\n",
    "        p_exact = exact_data[(s, T)][\"p\"]\n",
    "        E_exact = exact_data[(s, T)][\"E\"]\n",
    "        E_samples = get_state_energies(states, E_exact)\n",
    "\n",
    "        dkl[int(T * 1000), s] = kl_divergence(\n",
    "            p_exact, E_exact, E_samples, samples.record.num_occurrences\n",
    "        )\n",
    "\n",
    "    return pd.Series(dkl)\n",
    "\n",
    "\n",
    "def process_run_gauge_dir(run, gauge_dir, exact_data):\n",
    "    \"\"\"\n",
    "    Helper function for processing the runs and computing the KL divergences\n",
    "    in parallel.\n",
    "    \n",
    "    :param run: Name of the run.\n",
    "    :param gauge_dir: Directory of the gauge data.\n",
    "    :param exact_data: Exact computed data to compare against.\n",
    "    \n",
    "    :returns: KL divergence dataframe.\n",
    "    \"\"\"\n",
    "    samples = load_artifact(gauge_dir / f\"{run}.pkl\")\n",
    "    dkl_df = kl_divergence_df(exact_data, samples)\n",
    "\n",
    "    return dkl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37ec7b-41dc-49f4-8420-3948259849b4",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f26312-e6bb-498d-a1e6-054814a23813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 383 ms (started: 2022-03-09 10:08:07 +01:00)\n"
     ]
    }
   ],
   "source": [
    "config_id = 5\n",
    "embedding_id = 10\n",
    "n_jobs = 6\n",
    "\n",
    "config_dir = project_dir / f\"artifacts/exact_analysis/{config_id:02}/\"\n",
    "embedding_dir = config_dir / f\"samples/embedding_{embedding_id:02}\"\n",
    "\n",
    "config = load_artifact(config_dir / \"config.json\")\n",
    "exact_data = load_artifact(config_dir / \"exact_data.pkl\")\n",
    "\n",
    "gauge_dirs = sorted([x for x in embedding_dir.iterdir() if x.name.startswith(\"gauge_\")])\n",
    "run_names = sorted([x.stem for x in gauge_dirs[0].iterdir() if x.name != \"gauge.pkl\"])\n",
    "\n",
    "run_infos = {}\n",
    "t_as = []\n",
    "s_pauses = []\n",
    "anneal_durations = []\n",
    "pause_durations = []\n",
    "for run_name in run_names:\n",
    "    run_info = {x.split(\"=\")[0]: x.split(\"=\")[1] for x in run_name.split(\"-\")}\n",
    "    for k, v in run_info.items():\n",
    "        if k in (\"t_pause\", \"s_pause\", \"pause_duration\", \"quench_slope\"):\n",
    "            run_info[k] = float(v)\n",
    "    for k, v in run_info.items():\n",
    "        if k in (\"reverse\", \"reinit\") and v == \"True\":\n",
    "            run_info[k] = True\n",
    "        elif k in (\"reverse\", \"reinit\") and v == \"False\":\n",
    "            run_info[k] = False\n",
    "\n",
    "    if \"reverse\" in run_info:\n",
    "        run_info[\"t_a\"] = round(run_info[\"t_pause\"] / (1 - run_info[\"s_pause\"]), 1)\n",
    "    else:\n",
    "        run_info[\"reverse\"] = False\n",
    "        run_info[\"reinit\"] = True\n",
    "        run_info[\"t_a\"] = round(run_info[\"t_pause\"] / run_info[\"s_pause\"], 1)\n",
    "    run_infos[run_name] = run_info\n",
    "\n",
    "    if run_info[\"t_a\"] not in t_as:\n",
    "        t_as.append(run_info[\"t_a\"])\n",
    "\n",
    "    if run_info[\"s_pause\"] not in s_pauses:\n",
    "        s_pauses.append(run_info[\"s_pause\"])\n",
    "\n",
    "    if run_info[\"pause_duration\"] not in pause_durations:\n",
    "        pause_durations.append(run_info[\"pause_duration\"])\n",
    "\n",
    "t_as = sorted(t_as)\n",
    "pause_durations = sorted(pause_durations)\n",
    "anneal_durations = sorted(anneal_durations)\n",
    "\n",
    "t_as = [x for x in t_as if x != 10]\n",
    "run_names = sorted(run_names, key=lambda run_name: run_infos[run_name][\"s_pause\"])\n",
    "\n",
    "run_names_ = []\n",
    "for run_name in run_names:\n",
    "    run_info = run_infos[run_name]\n",
    "    if (\n",
    "        round(run_info[\"s_pause\"] * 100) % 5 == 0\n",
    "        and run_info[\"pause_duration\"] != 1000\n",
    "        and not run_info[\"reverse\"]\n",
    "    ):\n",
    "        run_names_.append(run_name)\n",
    "run_names = sorted(run_names_, key=lambda x: run_infos[x][\"s_pause\"])\n",
    "run_infos = {k: v for k, v in run_infos.items() if k in run_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac237732-ca63-46f2-b919-8ce27b30757a",
   "metadata": {},
   "source": [
    "## KL Divergence Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5bafaff-ca1d-4cb0-9740-12e6fa964ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 292 ms (started: 2022-03-09 10:08:07 +01:00)\n"
     ]
    }
   ],
   "source": [
    "compute_kl_divergences = False\n",
    "if not (embedding_dir / \"kl_divergences.pkl\").exists() or compute_kl_divergences:\n",
    "    dkls = {}\n",
    "    for run_name in run_names:\n",
    "        dkl_dfs = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(process_run_gauge_dir)(run_name, gauge_dir, exact_data)\n",
    "            for gauge_dir in gauge_dirs\n",
    "        )\n",
    "        dkls[run_name] = compute_stats_over_dfs(dkl_dfs)\n",
    "    save_artifact(dkls, embedding_dir / \"kl_divergences.pkl\")\n",
    "else:\n",
    "    dkls = load_artifact(embedding_dir / \"kl_divergences.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61efbe2-5706-47f3-99d3-3b73fca147c9",
   "metadata": {},
   "source": [
    "## KL Divergence Min Value Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042febcf-464b-4dcb-82ba-60c1657ad0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.11 s (started: 2022-03-09 10:17:12 +01:00)\n"
     ]
    }
   ],
   "source": [
    "plot_dir = project_dir / f\"results/plots/qbm/8x4/exact_analysis/config_{config_id:02}/embedding_{embedding_id:02}\"\n",
    "if not plot_dir.exists():\n",
    "    plot_dir.mkdir(parents=True)\n",
    "\n",
    "markers = [\"o\", \"^\", \"v\", \"<\", \">\", \"s\", \"p\", \"*\", \"P\", \"X\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "\u03b1_quench = 2.0\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "# if config_id == 2:\n",
    "#     ax.set_title(fr\"Embedding {embedding_id}, $h_i, J_{{ij}} \\sim \\mathcal{{N}}(0, 0.1)$\")\n",
    "# elif config_id == 3:\n",
    "#     ax.set_title(fr\"Embedding {embedding_id}, $h_i, J_{{ij}} \\sim \\mathcal{{N}}(0, 1)$\")\n",
    "    \n",
    "ax.set_xlabel(r\"$s_{{quench}}$\")\n",
    "ax.set_ylabel(r\"$\\min_{s,T}\\{D_{KL}(p_{exact} \\ || \\ p_{samples})\\}$\")\n",
    "i = 0\n",
    "for t_a in sorted(t_as):\n",
    "    if config_id == 1:\n",
    "        ax.set_xticks(np.arange(0.25, 0.8, 0.05))\n",
    "        ax.set_yticks(np.arange(0, 0.07, 0.01))\n",
    "        ax.set_ylim(0, 0.06)\n",
    "    elif config_id in (2, 3, 5):\n",
    "        ax.set_xticks(np.arange(0.2, 1.1, 0.1))\n",
    "        ax.set_yticks(np.arange(0, 0.045, 0.005))\n",
    "        ax.set_ylim(0, 0.025)\n",
    "\n",
    "    run_names_plot = [\n",
    "        run_name for run_name, run_info in run_infos.items() if run_info[\"t_a\"] == t_a\n",
    "    ]\n",
    "    for pause_duration in pause_durations:\n",
    "        x = []\n",
    "        y = []\n",
    "        y_err = []\n",
    "        for run_name in run_names_plot:\n",
    "            run_info = run_infos[run_name]\n",
    "            if (\n",
    "                run_info[\"pause_duration\"] == pause_duration\n",
    "                and run_info[\"reverse\"] == False\n",
    "                and round(run_info[\"s_pause\"] * 100) % 5 == 0\n",
    "            ):\n",
    "                dkls_run = dkls[run_name]\n",
    "\n",
    "                means = dkls_run[\"means\"]\n",
    "                argmin = np.argmin(means)\n",
    "                stds = dkls_run[\"stds\"]\n",
    "                \n",
    "                x.append(run_infos[run_name][\"s_pause\"])\n",
    "                y.append(means.iloc[argmin])\n",
    "                y_err.append(stds.iloc[argmin])\n",
    "\n",
    "        if x and y:\n",
    "            sort_indices = np.argsort(x)\n",
    "            x = np.array(x)[sort_indices]\n",
    "            y = np.array(y)[sort_indices]\n",
    "            y_err = np.array(y_err)[sort_indices]\n",
    "            label = fr\"$t_a = {int(t_a)}$ \u03bcs, $\\Delta_{{pause}} = {int(pause_duration)}$ \u03bcs\"\n",
    "            ax.fill_between(x, y - y_err, y + y_err, interpolate=True, color=colors[i], alpha=0.10)\n",
    "            ax.plot(\n",
    "                x,\n",
    "                y,\n",
    "                marker=markers[i],\n",
    "                markersize=10,\n",
    "                linewidth=1.2,\n",
    "                label=label,\n",
    "                color=colors[i],\n",
    "            )\n",
    "            i += 1\n",
    "\n",
    "ax.grid(True, alpha=0.7)\n",
    "ax.legend(ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / f\"kl_divergence_mins.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ae0a1-c315-42aa-9a6e-fcced47512be",
   "metadata": {},
   "source": [
    "## Anneal Schedule Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa3a7981-7adf-4665-9fb2-2171aebb680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.21 ms (started: 2022-03-04 18:00:53 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# load anneal schedule\n",
    "qpu_params = config[\"qpu_params\"]\n",
    "if qpu_params[\"solver\"] == \"Advantage_system4.1\":\n",
    "    artifacts_dir = project_dir / \"artifacts/qbm/log_returns/Advantage_4.1\"\n",
    "    csv_name = \"09-1263A-A_Advantage_system4_1_annealing_schedule.csv\"\n",
    "elif qpu_params[\"solver\"] == \"Advantage_system5.1\":\n",
    "    artifacts_dir = project_dir / \"artifacts/qbm/log_returns/Advantage_5.1\"\n",
    "    csv_name = \"09-1265A-A_Advantage_system5_1_annealing_schedule.csv\"\n",
    "df_anneal = pd.read_csv(\n",
    "    project_dir\n",
    "    / f\"data/anneal_schedules/csv/{csv_name}\",\n",
    "    index_col=\"s\",\n",
    ")\n",
    "if 0.5 not in df_anneal.index:\n",
    "    df_anneal.loc[0.5] = (df_anneal.loc[0.499] + df_anneal.loc[0.501]) / 2\n",
    "df_anneal.sort_index(inplace=True)\n",
    "df_anneal[\"Q(s)\"] = df_anneal[\"A(s) (GHz)\"] / df_anneal[\"B(s) (GHz)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c34255-ce49-486c-9325-63274af562df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.19 s (started: 2022-03-04 23:08:36 +01:00)\n"
     ]
    }
   ],
   "source": [
    "plot_dir = project_dir / f\"results/plots/qbm/anneal_schedules/\"\n",
    "if not plot_dir.exists():\n",
    "    plot_dir.mkdir(parents=True)\n",
    "    \n",
    "for s_pause in [0.55, 1.0]:\n",
    "    t_a = 20\n",
    "    t_pause = s_pause * t_a\n",
    "    pause_duration = 0\n",
    "    \u03b1_quench = 2 # Advantage systems\n",
    "    quench_duration = (1 - s_pause) / \u03b1_quench\n",
    "\n",
    "    s_left = np.arange(0, s_pause + 1e-3, 1e-3)\n",
    "    s_right = np.arange(s_pause + 1e-3, 1 + 1e-3, 1e-3)\n",
    "    s = np.round(np.concatenate((s_left, s_right)), 3)\n",
    "    t_left = np.linspace(0, t_pause, len(s_left))\n",
    "    t_right = np.linspace(\n",
    "        t_pause + pause_duration,\n",
    "        t_pause + pause_duration + quench_duration,\n",
    "        len(s_right),\n",
    "    )\n",
    "    t = np.round(np.concatenate((t_left, t_right)), 3)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "\n",
    "    if s_pause == 1:\n",
    "        ax.set_xticks(np.arange(0, 22, 2))\n",
    "    ax.plot(\n",
    "        t,\n",
    "        df_anneal[\"A(s) (GHz)\"],\n",
    "        color=\"tab:blue\",\n",
    "        linewidth=2,\n",
    "        label=\"A(s)\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        t,\n",
    "        df_anneal[\"B(s) (GHz)\"],\n",
    "        color=\"tab:red\",\n",
    "        linewidth=2,\n",
    "        label=\"B(s)\",\n",
    "    )\n",
    "    ax.set_xlabel(r\"$t$ [\u03bcs]\")\n",
    "    ax.set_ylabel(r\"$E$ [GHz]\")\n",
    "    ax.grid(alpha=0.7)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_dir / f\"{qpu_params['solver']}-s_pause={s_pause:.2f}-pause_duration={pause_duration}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}