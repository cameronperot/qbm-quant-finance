{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb62c48-2177-49aa-a2e0-e6ab4960fd30",
   "metadata": {},
   "source": [
    "# Sample Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5660c694-9943-4078-8345-64acd3cec43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.49 s (started: 2022-01-10 14:32:02 +01:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "%load_ext line_profiler\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dwave.system import DWaveSampler, FixedEmbeddingComposite\n",
    "from matplotlib.patches import Rectangle\n",
    "from numba import njit\n",
    "\n",
    "from qbm.utils import (\n",
    "    compute_stats_over_dfs,\n",
    "    convert_bin_list_to_str,\n",
    "    get_project_dir,\n",
    "    get_rng,\n",
    "    load_artifact,\n",
    "    save_artifact,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f1940b-200b-428b-b893-fb2cac0c3c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 525 \u00b5s (started: 2022-01-10 14:32:04 +01:00)\n"
     ]
    }
   ],
   "source": [
    "project_dir = get_project_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549de356-cbf7-4300-bff5-5a1d61107eab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016dfb81-ea40-4a8d-972b-21997e1c825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.7 ms (started: 2022-01-10 14:32:04 +01:00)\n"
     ]
    }
   ],
   "source": [
    "@njit(boundscheck=True)\n",
    "def compute_KL_divergence(\n",
    "    p_exact,\n",
    "    E_exact,\n",
    "    E_samples,\n",
    "    counts_samples,\n",
    "    n_bins=32,\n",
    "    normalize=False,\n",
    "    swap=False,\n",
    "    prob_sum_tol=1e-2,\n",
    "    \u03f5_smooth=1e-6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the KL divergence of the theory w.r.t. the samples, i.e., \n",
    "    D_KL(p_exact || p_samples).\n",
    "    \n",
    "    :param p_exact: Exact computed probability vector, i.e., the diagonal of \u03c1.\n",
    "    :param E_exact: Exact computed energy vector, i.e., the diagonal of H.\n",
    "    :param E_samples: Energies of the samples.\n",
    "    :param n_bins: Number of bins to compute over.\n",
    "    :param normalize: If True will normalize the bin probabilities.\n",
    "    :param swap: If True will compute D_KL(p_samples || p_exact) rather than \n",
    "        D_KL(p_exact || p_samples).\n",
    "    :param prob_sum_tol: The tolerance for the probabilities to sum up to approx 1.\n",
    "    \n",
    "    :returns: D_KL(p_exact || p_samples).\n",
    "    \"\"\"\n",
    "    p = np.zeros(n_bins)\n",
    "    q = np.zeros(n_bins)\n",
    "\n",
    "    # return NaN if exact data isn't a proper probability distribution\n",
    "    if np.isnan(p_exact).any() or np.abs(p_exact.sum() - 1) > prob_sum_tol:\n",
    "        return np.nan\n",
    "\n",
    "    # bin the probabilities\n",
    "    bin_edges = np.linspace(E_exact.min(), E_exact.max(), n_bins + 1)\n",
    "    sum_counts = counts_samples.sum()\n",
    "    for i, (a, b) in enumerate(zip(bin_edges[:-1], bin_edges[1:])):\n",
    "        if i < n_bins - 1:\n",
    "            p[i] = p_exact[np.logical_and(E_exact >= a, E_exact < b)].sum()\n",
    "            q[i] = (\n",
    "                counts_samples[np.logical_and(E_samples >= a, E_samples < b)].sum()\n",
    "                / sum_counts\n",
    "            )\n",
    "        else:\n",
    "            p[i] = p_exact[E_exact >= a].sum()\n",
    "            q[i] = counts_samples[E_samples >= a].sum() / sum_counts\n",
    "    \n",
    "    # smoothing of sample data\n",
    "    if \u03f5_smooth:\n",
    "        smooth_mask = np.logical_and(p > \u03f5_smooth, q == 0)\n",
    "        not_smooth_mask = np.logical_not(smooth_mask)\n",
    "        q[smooth_mask] = \u03f5_smooth\n",
    "        q[not_smooth_mask] -= \u03f5_smooth * smooth_mask.sum() / not_smooth_mask.sum()\n",
    "\n",
    "    # assert that p and q sum up to approx 1\n",
    "    assert np.abs(p.sum() - 1) < prob_sum_tol\n",
    "    assert np.abs(q.sum() - 1) < prob_sum_tol\n",
    "\n",
    "    # take intersection of supports to avoid div zero errors\n",
    "    support_intersection = np.logical_and(p > 0, q > 0)\n",
    "    p = p[support_intersection]\n",
    "    q = q[support_intersection]\n",
    "\n",
    "    # re-normalize the p and q if True\n",
    "    if normalize:\n",
    "        p /= p.sum()\n",
    "        q /= q.sum()\n",
    "\n",
    "    # swap p and q if True\n",
    "    if swap:\n",
    "        p, q = q, p\n",
    "\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "\n",
    "@njit(boundscheck=True)\n",
    "def get_state_energies(states, E_exact):\n",
    "    \"\"\"\n",
    "    Returns the (quantum + classical) energies of the provided states corresponding\n",
    "    to the provided exact calculated energies.\n",
    "    \n",
    "    :param states: Array of states. Must be a value in 0, 1, ..., 2 ** n_qubits - 1.\n",
    "    :param E_exact: Array of exact computed energies, corresponds to the diagonal of H.\n",
    "    \n",
    "    :returns: Array where entry i is the energy of states[i].\n",
    "    \"\"\"\n",
    "    E_samples = np.zeros(len(states))\n",
    "    for i, state in enumerate(states):\n",
    "        E_samples[i] = E_exact[state]\n",
    "\n",
    "    return E_samples\n",
    "\n",
    "\n",
    "def convert_spin_vector_to_state_number(spins):\n",
    "    \"\"\"\n",
    "    Converts the spins vector (e.g. all values \u00b11) to an integer corresponding to the state.\n",
    "    For example, the spin vector [1, 1, 1, 1] corresponds to the state |0000\u27e9 which is the\n",
    "    0th state. The spin vector [-1, -1, -1, -1] corresponds to the state |1111\u27e9 which is the\n",
    "    15th state.\n",
    "    \n",
    "    :param spins: Vector of spin values (\u00b11).\n",
    "    \n",
    "    :returns: Integer corresponding to the state. \n",
    "    \"\"\"\n",
    "    bit_vector = ((1 - spins) / 2).astype(np.int64)\n",
    "\n",
    "    return (bit_vector * 2 ** np.arange(len(spins) - 1, -1, -1)).sum()\n",
    "\n",
    "\n",
    "def compute_KL_divergence_df(exact_data, samples, swap):\n",
    "    \"\"\"\n",
    "    Compares each exact computed data distribution against the provided samples instance.\n",
    "    \n",
    "    :param exact_data: Dictionary with keys of the form (s, T) with s being the relative\n",
    "        anneal time at which H and \u03c1 were computed, and T being the effective temperature.\n",
    "        Values are of the form {\"E\": [...], \"p\": [...]}\n",
    "    :param samples: Instance of Ocean SDK SampleSet.\n",
    "    :param swap: If True will compute D_KL(p_samples || p_exact) rather than \n",
    "        D_KL(p_exact || p_samples).\n",
    "    \n",
    "    :returns: Dataframe of KL divergences, with T values as index and s values as columns.\n",
    "    \"\"\"\n",
    "    # convert spin vectors to state numbers\n",
    "    states = np.array(\n",
    "        [convert_spin_vector_to_state_number(x) for x in samples.record.sample]\n",
    "    )\n",
    "\n",
    "    KL_divergence = {}\n",
    "    for s, T in exact_data.keys():\n",
    "        p_exact = exact_data[(s, T)][\"p\"]\n",
    "        E_exact = exact_data[(s, T)][\"E\"]\n",
    "        E_samples = get_state_energies(states, E_exact)\n",
    "        KL_divergence[int(T * 1000), s] = compute_KL_divergence(\n",
    "            p_exact, E_exact, E_samples, samples.record.num_occurrences, swap=swap\n",
    "        )\n",
    "\n",
    "    return pd.Series(KL_divergence)\n",
    "\n",
    "\n",
    "def process_run_gauge_dir(run, gauge_dir, exact_data, swap):\n",
    "    \"\"\"\n",
    "    Helper function for processing the runs and computing the KL divergences\n",
    "    in parallel.\n",
    "    \n",
    "    :param run: Name of the run.\n",
    "    :param gauge_dir: Directory of the gauge data.\n",
    "    :param exact_data: Exact computed data to compare against.\n",
    "    :param swap: If True will compute D_KL(p_samples || p_exact) rather than \n",
    "        D_KL(p_exact || p_samples).\n",
    "    \n",
    "    :returns: KL divergence dataframe.\n",
    "    \"\"\"\n",
    "    samples = load_artifact(gauge_dir / f\"{run}.pkl\")\n",
    "    KL_divergence_df = compute_KL_divergence_df(exact_data, samples, swap)\n",
    "\n",
    "    return KL_divergence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6cb35-66ee-4252-aa93-f25566e0c8c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8565ba8b-bca8-4c80-b4c3-4388d2f9bf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.13 ms (started: 2022-01-10 14:54:44 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def plot_heat_map(KL_divergence, title, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots the KL divergence heat map.\n",
    "    \n",
    "    :param KL_divergence: KL divergence dataframe.\n",
    "    :param title: Title of the plot.\n",
    "    :param suptitle: Suptitle of the plot.\n",
    "    :param **kwargs: Additional kwargs for sns.heatmap().\n",
    "    \n",
    "    :returns: Matplotlib fig, ax.\n",
    "    \"\"\"\n",
    "    KL_divergence = KL_divergence.copy()\n",
    "    KL_divergence.index = pd.MultiIndex.from_tuples(KL_divergence.index)\n",
    "    KL_divergence = KL_divergence.unstack(level=-1)\n",
    "    \n",
    "    cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "    s_values = KL_divergence.columns.to_numpy()\n",
    "    T_values = KL_divergence.index.to_numpy()\n",
    "    xticks = np.arange(len(s_values))[::10]\n",
    "    xticklabels = s_values[::10]\n",
    "    yticks = np.arange(len(T_values))[::2]\n",
    "    yticklabels = T_values[::2]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "#     fig.suptitle(suptitle)\n",
    "    sns.heatmap(KL_divergence, ax=ax, cmap=cmap, **kwargs)\n",
    "    ax.set_title(title)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(r\"$s$\")\n",
    "    ax.set_ylabel(r\"$T$ [mK]\")\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels, rotation=0)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(yticklabels, rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_histogram(E, title, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots a histogram.\n",
    "    \n",
    "    :param E: Energy array.\n",
    "    :param title: Title of the plot.\n",
    "    :param **kwargs: Additional kwargs for ax.hist().\n",
    "    \n",
    "    :returns: Matplotlib fig, ax.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=144)\n",
    "    ax.hist(E, bins=32, **kwargs)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(r\"$E$\")\n",
    "    ax.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37ec7b-41dc-49f4-8420-3948259849b4",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02f26312-e6bb-498d-a1e6-054814a23813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 98.7 ms (started: 2022-01-10 15:15:11 +01:00)\n"
     ]
    }
   ],
   "source": [
    "config_id = 3\n",
    "embedding_id = 1\n",
    "n_jobs = 6\n",
    "\n",
    "config_dir = project_dir / f\"artifacts/exact_analysis/{config_id:02}/\"\n",
    "embedding_dir = config_dir / f\"samples/embedding_{embedding_id:02}\"\n",
    "\n",
    "config = load_artifact(config_dir / \"config.json\")\n",
    "exact_data = load_artifact(config_dir / \"exact_data.pkl\")\n",
    "\n",
    "gauge_dirs = sorted([x for x in embedding_dir.iterdir() if x.name.startswith(\"gauge_\")])\n",
    "run_names = sorted([x.stem for x in gauge_dirs[0].iterdir() if x.name != \"gauge.pkl\"])\n",
    "\n",
    "run_infos = {}\n",
    "t_as = []\n",
    "pause_durations = []\n",
    "for run_name in run_names:\n",
    "    run_info = {x.split(\"=\")[0]: float(x.split(\"=\")[1]) for x in run_name.split(\",\")}\n",
    "    run_info[\"t_a\"] = round(run_info[\"t_pause\"] / run_info[\"s_pause\"], 1)\n",
    "    run_infos[run_name] = run_info\n",
    "    \n",
    "    if run_info[\"t_a\"] not in t_as:\n",
    "        t_as.append(run_info[\"t_a\"])\n",
    "\n",
    "    if run_info[\"pause_duration\"] not in pause_durations:\n",
    "        pause_durations.append(run_info[\"pause_duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac237732-ca63-46f2-b919-8ce27b30757a",
   "metadata": {},
   "source": [
    "## KL Divergence Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5bafaff-ca1d-4cb0-9740-12e6fa964ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9min 39s (started: 2022-01-10 15:15:12 +01:00)\n"
     ]
    }
   ],
   "source": [
    "compute_DKL = True\n",
    "if not (embedding_dir / \"KL_divergences.pkl\").exists() or compute_DKL:\n",
    "    KL_divergences = {}\n",
    "    for run_name in run_names:\n",
    "        KL_divergence_dfs = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(process_run_gauge_dir)(run_name, gauge_dir, exact_data, swap=False)\n",
    "            for gauge_dir in gauge_dirs\n",
    "        )\n",
    "        KL_divergences[run_name] = compute_stats_over_dfs(KL_divergence_dfs)\n",
    "    save_artifact(KL_divergences, embedding_dir / \"KL_divergences.pkl\")\n",
    "else:\n",
    "    KL_divergences = load_artifact(embedding_dir / \"KL_divergences.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61efbe2-5706-47f3-99d3-3b73fca147c9",
   "metadata": {},
   "source": [
    "## KL Divergence Min Value Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "509bc57f-f4ce-4567-bbac-05965915e761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.38 s (started: 2022-01-10 15:24:51 +01:00)\n"
     ]
    }
   ],
   "source": [
    "plot_dir_DKL_mins = config_dir / f\"plots/DKL_mins/embedding_{embedding_id:02}\"\n",
    "if not plot_dir_DKL_mins.exists():\n",
    "    plot_dir_DKL_mins.mkdir(parents=True)\n",
    "\n",
    "color_map = {0: \"tab:red\", 10: \"tab:blue\", 100: \"tab:orange\", 1000: \"tab:green\"}\n",
    "\n",
    "\u03b1_quench = 2.0\n",
    "for t_a in t_as:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "    ax.set_title(fr\"$t_a = {t_a:.0f}$ \u03bcs, $\u03b1_{{quench}} = {\u03b1_quench:.0f}$\")\n",
    "    ax.set_xlabel(r\"$s_{{pause}}$\")\n",
    "    ax.set_ylabel(r\"$\\min_{s,T}\\{D_{KL}(p_{exact}(s,T) \\ || \\ p_{samples})\\}$\")\n",
    "\n",
    "    if config_id == 1:\n",
    "        ax.set_xticks(np.arange(0.25, 0.8, 0.05))\n",
    "        ax.set_yticks(np.arange(0, 0.07, 0.01))\n",
    "        ax.set_ylim(0, 0.06)\n",
    "    elif config_id == 2:\n",
    "        ax.set_xticks(np.arange(0.25, 0.8, 0.05))\n",
    "        ax.set_yticks(np.arange(0, 0.14, 0.02))\n",
    "        ax.set_ylim(0, 0.12)\n",
    "    elif config_id == 3:\n",
    "        ax.set_xticks(np.arange(0.25, 0.8, 0.05))\n",
    "        ax.set_yticks(np.arange(0, 0.14, 0.02))\n",
    "        ax.set_ylim(0, 0.12)\n",
    "    elif config_id == 4:\n",
    "        ax.set_xticks(np.arange(0.55, 0.675, 0.025))\n",
    "        ax.set_ylim(0, 0.25)\n",
    "\n",
    "    run_names_plot = [\n",
    "        run_name\n",
    "        for run_name, run_info in run_infos.items()\n",
    "        if run_info[\"t_a\"] == t_a\n",
    "    ]\n",
    "    for pause_duration in pause_durations:\n",
    "        x = []\n",
    "        y = []\n",
    "        y_err = []\n",
    "        for run_name in run_names_plot:\n",
    "            if run_infos[run_name][\"pause_duration\"] == pause_duration:\n",
    "                KL_divergences_run = KL_divergences[run_name]\n",
    "                y_min_index = KL_divergences_run[\"means\"].argmin()\n",
    "\n",
    "                x.append(run_infos[run_name][\"s_pause\"])\n",
    "                y.append(KL_divergences_run[\"means\"].iloc[y_min_index])\n",
    "                y_err.append(KL_divergences_run[\"stds\"].iloc[y_min_index])\n",
    "\n",
    "        if x and y:\n",
    "            label = fr\"$\\Delta_{{pause}} = {int(pause_duration)}$\"\n",
    "            ax.errorbar(\n",
    "                x,\n",
    "                y,\n",
    "                color=color_map[pause_duration],\n",
    "                yerr=y_err,\n",
    "                fmt=\"o\",\n",
    "                markersize=5,\n",
    "                linewidth=1.8,\n",
    "                capsize=10,\n",
    "                capthick=1.8,\n",
    "                label=label,\n",
    "            )\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_dir_DKL_mins / f\"t_a={t_a},quench_slope={\u03b1_quench}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b073d8-98ee-4e0a-b6a1-5b3359df007b",
   "metadata": {},
   "source": [
    "### KL Divergence Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec53029-7a4a-49ab-9a74-b7e4adc097df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.5 s (started: 2022-01-10 15:24:53 +01:00)\n"
     ]
    }
   ],
   "source": [
    "for run_name, KL_divergence_dict in KL_divergences.items():\n",
    "    KL_divergence_means = KL_divergence_dict[\"means\"]\n",
    "\n",
    "    plot_dir_heatmaps = (\n",
    "        config_dir / f\"plots/heatmaps/embedding_{embedding_id:02}\"\n",
    "    )\n",
    "    if not plot_dir_heatmaps.exists():\n",
    "        plot_dir_heatmaps.mkdir(parents=True)\n",
    "\n",
    "\n",
    "    run_info = run_infos[run_name]\n",
    "    t_pause = run_info[\"t_pause\"]\n",
    "    s_pause = run_info[\"s_pause\"]\n",
    "    pause_duration = run_info[\"pause_duration\"]\n",
    "    \u03b1_quench = run_info[\"quench_slope\"]\n",
    "    title = fr\"$t_{{pause}} = {t_pause:.0f}$ \u03bcs, $s_{{pause}} = {s_pause}$, $\\Delta_{{pause}} = {pause_duration:.0f}$ \u03bcs, $\\alpha_{{quench}} = {\u03b1_quench:.0f}$\"\n",
    "    cbar_kws={'label': r\"$D_{KL}(p_{exact}(s,T) \\ || \\ p_{samples})$\"}\n",
    "\n",
    "    fig, ax = plot_heat_map(KL_divergence_means, title, vmin=0, vmax=0.20, cbar_kws=cbar_kws)\n",
    "#     T_min, s_min = KL_divergence_means.index[KL_divergence_means.argmin()]\n",
    "#     x_min = s_min * 100 - 20\n",
    "#     y_min = T_min / 2 - 1\n",
    "#     ax.add_patch(\n",
    "#         Rectangle((x_min, y_min), 1, 1, fill=False, edgecolor=\"tab:blue\", lw=2)\n",
    "#     )\n",
    "    plt.savefig(plot_dir_heatmaps / f\"{run_name}.png\")\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ae0a1-c315-42aa-9a6e-fcced47512be",
   "metadata": {},
   "source": [
    "## Anneal Schedule Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57535b92-f4fc-46dd-828b-14db6b7869ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.1 s (started: 2022-01-07 13:37:09 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# load the anneal schedule data\n",
    "anneal_schedule_data = pd.read_csv(\n",
    "    project_dir\n",
    "    / \"data/anneal_schedules/csv/09-1265A-A_Advantage_system5_1_annealing_schedule.csv\",\n",
    "    index_col=\"s\",\n",
    ")\n",
    "# for some reason 0.5 is missing for Advantage_system5.1 so we need to interpolate\n",
    "if 0.5 not in anneal_schedule_data.index:\n",
    "    anneal_schedule_data.loc[0.5] = (\n",
    "        anneal_schedule_data.loc[0.499] + anneal_schedule_data.loc[0.501]\n",
    "    ) / 2\n",
    "anneal_schedule_data.sort_index(inplace=True)\n",
    "\n",
    "plot_dir_anneal_schedules = project_dir / f\"artifacts/plots/anneal_schedules\"\n",
    "if not plot_dir_anneal_schedules.exists():\n",
    "    plot_dir_anneal_schedules.mkdir(parents=True)\n",
    "\n",
    "for run_name, run_info in run_infos.items():\n",
    "    t_pause = run_info[\"t_pause\"]\n",
    "    s_pause = run_info[\"s_pause\"]\n",
    "    pause_duration = run_info[\"pause_duration\"]\n",
    "    \u03b1_quench = run_info[\"quench_slope\"]\n",
    "    quench_duration = (1 - s_pause) / \u03b1_quench\n",
    "    anneal_schedule = [\n",
    "        (0, 0),\n",
    "        (t_pause, s_pause),\n",
    "        (t_pause + pause_duration, s_pause),\n",
    "        (t_pause + pause_duration + quench_duration, 1),\n",
    "    ]\n",
    "    title = fr\"$t_{{pause}} = {t_pause:.0f}$ \u03bcs, $s_{{pause}} = {s_pause}$, $\\Delta_{{pause}} = {pause_duration:.0f}$ \u03bcs, $\\alpha_{{quench}} = {\u03b1_quench:.0f}$\"\n",
    "\n",
    "    s_left = np.arange(0, s_pause + 1e-3, 1e-3)\n",
    "    s_right = np.arange(s_pause + 1e-3, 1 + 1e-3, 1e-3)\n",
    "    s = np.round(np.concatenate((s_left, s_right)), 3)\n",
    "    t_left = np.linspace(0, t_pause, len(s_left))\n",
    "    t_right = np.linspace(\n",
    "        t_pause + pause_duration,\n",
    "        t_pause + pause_duration + quench_duration,\n",
    "        len(s_right),\n",
    "    )\n",
    "    t = np.round(np.concatenate((t_left, t_right)), 3)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 12), dpi=300)\n",
    "    fig.suptitle(\"Anneal Schedule\")\n",
    "\n",
    "    axs[0].set_title(title)\n",
    "    axs[0].plot(\n",
    "        t,\n",
    "        anneal_schedule_data[\"A(s) (GHz)\"],\n",
    "        color=\"tab:blue\",\n",
    "        linewidth=2,\n",
    "        label=\"A(s)\",\n",
    "    )\n",
    "    axs[0].plot(\n",
    "        t,\n",
    "        anneal_schedule_data[\"B(s) (GHz)\"],\n",
    "        color=\"tab:red\",\n",
    "        linewidth=2,\n",
    "        label=\"B(s)\",\n",
    "    )\n",
    "    axs[0].set_xlabel(r\"$t$ [\u03bcs]\")\n",
    "    axs[0].set_ylabel(r\"$E$ [GHz]\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(t, s, color=\"tab:blue\", linewidth=2)\n",
    "    axs[1].set_xlabel(r\"$t$ [\u03bcs]\")\n",
    "    axs[1].set_ylabel(r\"$s$\")\n",
    "    axs[1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_dir_anneal_schedules / f\"{run_name}.png\")\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8b28d-2b87-49c8-a0d3-cb46f33d994d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc1ab76f-ca2b-4252-b813-6fa16fbbc567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8min 39s (started: 2022-01-04 23:01:28 +01:00)\n"
     ]
    }
   ],
   "source": [
    "plot_dir_histograms_exact = config_dir / f\"plots/histograms/exact\"\n",
    "if not plot_dir_histograms_exact.exists():\n",
    "    plot_dir_histograms_exact.mkdir(parents=True)\n",
    "    \n",
    "for (s, T), data in exact_data.items():\n",
    "    if np.isnan(data[\"p\"]).any() or abs(data[\"p\"].sum() - 1) > 1e-2:\n",
    "        continue\n",
    "    title = fr\"$s = {s}, \\ T = {T}$\"\n",
    "    fig, ax = plot_histogram(data[\"E\"], title, weights=data[\"p\"])\n",
    "    plt.savefig(plot_dir_histograms_exact / f\"s={s:.2f},T={T:.3f}.png\")\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07d1c4a-a5cf-438e-8148-ee8d08ed04e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.77 s (started: 2022-01-04 23:10:08 +01:00)\n"
     ]
    }
   ],
   "source": [
    "plot_dir_histograms_samples = (\n",
    "    config_dir / f\"plots/histograms/embedding_{embedding_id:02}\"\n",
    ")\n",
    "if not plot_dir_histograms_samples.exists():\n",
    "    plot_dir_histograms_samples.mkdir(parents=True)\n",
    "\n",
    "for run_name in run_names:\n",
    "    energy_densities = {}\n",
    "    for gauge_dir in gauge_dirs:\n",
    "        samples = load_artifact(gauge_dir / f\"{run_name}.pkl\")\n",
    "        for (energy, count) in zip(samples.record.energy, samples.record.num_occurrences):\n",
    "            density = count / samples.record.num_occurrences.sum() / len(gauge_dirs)\n",
    "            if energy in energy_densities:\n",
    "                energy_densities[energy] += density\n",
    "            else:\n",
    "                energy_densities[energy] = density\n",
    "\n",
    "    run_info = run_infos[run_name]\n",
    "    title = fr\"$t_{{a}} = {int(run_info['anneal_duration'])} \\ \u03bcs, \\ s_{{pause}} = {run_info['s_pause']}, \\ \\Delta_{{pause}} = {int(run_info['pause_duration'])} \\ \u03bcs, \\ \\alpha_{{quench}} = {int(run_info['max_slope'])}$\"\n",
    "\n",
    "    fig, ax = plot_histogram(\n",
    "        list(energy_densities.keys()), title, weights=list(energy_densities.values())\n",
    "    )\n",
    "    plt.savefig(plot_dir_histograms_samples / f\"{run_name}.png\")\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}